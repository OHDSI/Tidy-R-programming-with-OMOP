[
  {
    "objectID": "ch_6_working_with_cohorts.html",
    "href": "ch_6_working_with_cohorts.html",
    "title": "6  Working with cohorts",
    "section": "",
    "text": "PatientProfiles::addCohortIntersect()"
  },
  {
    "objectID": "ch_6_working_with_cohorts.html#intersection-between-two-cohorts",
    "href": "ch_6_working_with_cohorts.html#intersection-between-two-cohorts",
    "title": "6  Working with cohorts",
    "section": "6.2 Intersection between two cohorts",
    "text": "6.2 Intersection between two cohorts"
  },
  {
    "objectID": "ch_6_working_with_cohorts.html#set-up",
    "href": "ch_6_working_with_cohorts.html#set-up",
    "title": "6  Working with cohorts",
    "section": "6.3 Set up",
    "text": "6.3 Set up\n\nlibrary(CDMConnector)\nlibrary(dplyr)\nlibrary(PatientProfiles)\n        \ndb <- DBI::dbConnect(duckdb::duckdb(), eunomia_dir())\n\ncdm <- cdm_from_con(\n  con = db,\n  cdm_schema = \"main\",\n  write_schema = \"main\"\n)\n\ncdm <- cdm %>% \n  generate_concept_cohort_set(concept_set = list(\"gi_bleed\" = 192671), \n                            limit = \"all\", \n                            end = 30,\n                            name = \"gi_bleed\",\n                            overwrite = TRUE) %>% \n  generate_concept_cohort_set(concept_set = list(\"acetaminophen\" = c(1125315,\n                                                              1127078,\n                                                              1127433,\n                                                              40229134,\n                                                              40231925,\n                                                              40162522,\n                                                              19133768)), \n                              limit = \"all\", \n                            end = \"event_end_date\",\n                            name = \"acetaminophen\",\n                            overwrite = TRUE)\n\n\n6.3.1 Flag\n\ncdm$gi_bleed <- cdm$gi_bleed %>% \n  addCohortIntersectFlag(targetCohortTable = \"acetaminophen\",\n                         window = list(c(-Inf, -1), c(0,0), c(1, Inf)))\n\ncdm$gi_bleed %>% \n  summarise(acetaminophen_prior = sum(acetaminophen_minf_to_m1), \n            acetaminophen_index = sum(acetaminophen_0_to_0),\n            acetaminophen_post = sum(acetaminophen_1_to_inf)) %>% \n  collect()\n\n# A tibble: 1 × 3\n  acetaminophen_prior acetaminophen_index acetaminophen_post\n                <dbl>               <dbl>              <dbl>\n1                 467                   3                315\n\n\n\n\n6.3.2 Count\n\n\n6.3.3 Date and times"
  },
  {
    "objectID": "ch_6_working_with_cohorts.html#intersection-between-a-cohort-and-tables-with-patient-data",
    "href": "ch_6_working_with_cohorts.html#intersection-between-a-cohort-and-tables-with-patient-data",
    "title": "6  Working with cohorts",
    "section": "6.4 Intersection between a cohort and tables with patient data",
    "text": "6.4 Intersection between a cohort and tables with patient data"
  },
  {
    "objectID": "ch_1_getting_started.html",
    "href": "ch_1_getting_started.html",
    "title": "1  Getting started",
    "section": "",
    "text": "Artwork by @allison_horst\nBefore we start thinking about working with health care data spread across a database using the OMOP common data model, let’s first do a quick data analysis from R using a simpler dataset held in a database. For this we’ll use data from palmerpenguins package, which contains data on penguins collected from the Palmer Station in Antarctica."
  },
  {
    "objectID": "ch_1_getting_started.html#getting-set-up",
    "href": "ch_1_getting_started.html#getting-set-up",
    "title": "1  Getting started",
    "section": "1.2 Getting set up",
    "text": "1.2 Getting set up\nAssuming that you have R and RStudio already set up, first we need to install a few packages not included in base R if we don´t already have them.\n\ninstall.packages(\"dplyr\")\ninstall.packages(\"ggplot2\")\ninstall.packages(\"DBI\")\ninstall.packages(\"duckdb\")\ninstall.packages(\"palmerpenguins\")\n\nOnce installed, we can load them like so.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(DBI)\nlibrary(duckdb)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "ch_1_getting_started.html#taking-a-peek-at-the-data",
    "href": "ch_1_getting_started.html#taking-a-peek-at-the-data",
    "title": "1  Getting started",
    "section": "1.3 Taking a peek at the data",
    "text": "1.3 Taking a peek at the data\nWe can get an overview of the data using the glimpse() command.\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nOr we could take a look at the first rows of the data using head()\n\nhead(penguins, 5)\n\n# A tibble: 5 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 2 more variables: sex <fct>, year <int>"
  },
  {
    "objectID": "ch_1_getting_started.html#inserting-data-into-a-database",
    "href": "ch_1_getting_started.html#inserting-data-into-a-database",
    "title": "1  Getting started",
    "section": "1.4 Inserting data into a database",
    "text": "1.4 Inserting data into a database\nLet’s put our penguins data into a duckdb database. We create the duckdb database, add the penguins data, and then create a reference to the table containing the data.\n\ndb <- dbConnect(duckdb::duckdb(), dbdir = \":memory:\")\ndbWriteTable(db, \"penguins\", penguins)\npenguins_db <- tbl(db, \"penguins\")\n\nWe can see that our database now has one table\n\nDBI::dbListTables(db)\n\n[1] \"penguins\"\n\n\nAnd now that the data is in a database we could use SQL to get the first rows that we saw before\n\ndbGetQuery(db, \"SELECT * FROM penguins LIMIT 5\")\n\n  species    island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n1  Adelie Torgersen           39.1          18.7               181        3750\n2  Adelie Torgersen           39.5          17.4               186        3800\n3  Adelie Torgersen           40.3          18.0               195        3250\n4  Adelie Torgersen             NA            NA                NA          NA\n5  Adelie Torgersen           36.7          19.3               193        3450\n     sex year\n1   male 2007\n2 female 2007\n3 female 2007\n4   <NA> 2007\n5 female 2007\n\n\nBut we could also use the same R code as before\n\nhead(penguins_db, 5)\n\n# Source:   SQL [5 x 8]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/:memory:]\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 2 more variables: sex <fct>, year <int>"
  },
  {
    "objectID": "ch_1_getting_started.html#translation-from-r-to-sql",
    "href": "ch_1_getting_started.html#translation-from-r-to-sql",
    "title": "1  Getting started",
    "section": "1.5 Translation from R to SQL",
    "text": "1.5 Translation from R to SQL\nThe magic here is provided by the dbplyr which takes the R code and converts it into SQL, which in this case looks like\n\nhead(penguins_db, 1) %>% \n  show_query()\n\n<SQL>\nSELECT *\nFROM penguins\nLIMIT 1\n\n\nMore complicated SQL can also be generated by using familiar dplyr code, for example\n\npenguins_db %>%\n  group_by(species) %>%\n  summarise(\n    min_bill_length_mm = min(bill_length_mm),\n    median_bill_length_mm = median(bill_length_mm),\n    max_bill_length_mm = max(bill_length_mm)\n  ) %>%\n  mutate(min_max_bill_length_mm = paste0(\n    min_bill_length_mm,\n    \" to \",\n    max_bill_length_mm\n  )) %>%\n  select(\n    \"species\",\n    \"median_bill_length_mm\",\n    \"min_max_bill_length_mm\"\n  )\n\n# Source:   SQL [3 x 3]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/:memory:]\n  species   median_bill_length_mm min_max_bill_length_mm\n  <fct>                     <dbl> <chr>                 \n1 Adelie                     38.8 32.1 to 46.0          \n2 Gentoo                     47.3 40.9 to 59.6          \n3 Chinstrap                  49.6 40.9 to 58.0          \n\n\nIn this case the corresponding SQL looks like\n\npenguins_db %>%\n  group_by(species) %>%\n  summarise(\n    min_bill_length_mm = min(bill_length_mm),\n    median_bill_length_mm = median(bill_length_mm),\n    max_bill_length_mm = max(bill_length_mm)\n  ) %>%\n  mutate(min_max_bill_length_mm = paste0(min, \" to \", max)) %>%\n  select(\n    \"species\",\n    \"median_bill_length_mm\",\n    \"min_max_bill_length_mm\"\n  ) %>%\n  show_query()\n\n<SQL>\nSELECT\n  species,\n  median_bill_length_mm,\n  CONCAT_WS('', .Primitive(\"min\"), ' to ', .Primitive(\"max\")) AS min_max_bill_length_mm\nFROM (\n  SELECT\n    species,\n    MIN(bill_length_mm) AS min_bill_length_mm,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY bill_length_mm) AS median_bill_length_mm,\n    MAX(bill_length_mm) AS max_bill_length_mm\n  FROM penguins\n  GROUP BY species\n) q01"
  },
  {
    "objectID": "ch_1_getting_started.html#different-sql-for-different-database-management-systems",
    "href": "ch_1_getting_started.html#different-sql-for-different-database-management-systems",
    "title": "1  Getting started",
    "section": "1.6 Different SQL for different database management systems",
    "text": "1.6 Different SQL for different database management systems\nOne important benefit of using this approach is that the SQL generated will be specific to that of the database management system in use.\nAs we can see below the SQL can vary depending on the database management system being used.\n\npenguins %>%\n  dbplyr::lazy_frame(con = duckdb::simulate_duckdb()) %>%\n  mutate(\n    category = if_else(bill_length_mm > 40 & bill_depth_mm > 18,\n      \"big\", \"small\"\n    ),\n    date = as.Date(paste0(\"01-01-\", year))\n  ) %>%\n  show_query()\n\n<SQL>\nSELECT\n  *,\n  CASE WHEN (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'big' WHEN NOT (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'small' END AS `category`,\n  CAST(CONCAT_WS('', '01-01-', `year`) AS DATE) AS `date`\nFROM `df`\n\npenguins %>%\n  dbplyr::lazy_frame(con = dbplyr::simulate_postgres()) %>%\n  mutate(\n    category = if_else(bill_length_mm > 40 & bill_depth_mm > 18,\n      \"big\", \"small\"\n    ),\n    date = as.Date(paste0(\"01-01-\", year))\n  ) %>%\n  show_query()\n\n<SQL>\nSELECT\n  *,\n  CASE WHEN (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'big' WHEN NOT (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'small' END AS `category`,\n  CAST(CONCAT_WS('', '01-01-', `year`) AS DATE) AS `date`\nFROM `df`\n\npenguins %>%\n  dbplyr::lazy_frame(con = dbplyr::simulate_redshift()) %>%\n  mutate(\n    category = if_else(bill_length_mm > 40 & bill_depth_mm > 18,\n      \"big\", \"small\"\n    ),\n    date = as.Date(paste0(\"01-01-\", year))\n  ) %>%\n  show_query()\n\n<SQL>\nSELECT\n  *,\n  CASE WHEN (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'big' WHEN NOT (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'small' END AS `category`,\n  CAST('01-01-' || `year` AS DATE) AS `date`\nFROM `df`\n\npenguins %>%\n  dbplyr::lazy_frame(con = dbplyr::simulate_oracle()) %>%\n  mutate(\n    category = if_else(bill_length_mm > 40 & bill_depth_mm > 18,\n      \"big\", \"small\"\n    ),\n    date = as.Date(paste0(\"01-01-\", year))\n  ) %>%\n  show_query()\n\n<SQL>\nSELECT\n  `species`,\n  `island`,\n  `bill_length_mm`,\n  `bill_depth_mm`,\n  `flipper_length_mm`,\n  `body_mass_g`,\n  `sex`,\n  `year`,\n  CASE WHEN (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'big' WHEN NOT (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'small' END AS `category`,\n  DATE '01-01-' || `year` AS `date`\nFROM (`df`) \n\npenguins %>%\n  dbplyr::lazy_frame(con = dbplyr::simulate_snowflake()) %>%\n  mutate(\n    category = if_else(bill_length_mm > 40 & bill_depth_mm > 18,\n      \"big\", \"small\"\n    ),\n    date = as.Date(paste0(\"01-01-\", year))\n  ) %>%\n  show_query()\n\n<SQL>\nSELECT\n  *,\n  CASE WHEN (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'big' WHEN NOT (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'small' END AS `category`,\n  CAST(ARRAY_TO_STRING(ARRAY_CONSTRUCT_COMPACT('01-01-', `year`), '') AS DATE) AS `date`\nFROM `df`"
  },
  {
    "objectID": "ch_1_getting_started.html#example-analysis",
    "href": "ch_1_getting_started.html#example-analysis",
    "title": "1  Getting started",
    "section": "1.7 Example analysis",
    "text": "1.7 Example analysis\nLet´s start by getting a count by species\n\npenguins_db %>% \n  group_by(species) %>% \n  count()\n\n# Source:   SQL [3 x 2]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/:memory:]\n# Groups:   species\n  species       n\n  <fct>     <dbl>\n1 Adelie      152\n2 Gentoo      124\n3 Chinstrap    68\n\n\nNow suppose we are particularly interested in the body mass variable. We can first notice that there are a couple of missing records for this.\n\npenguins_db %>%\n  mutate(missing_body_mass_g = if_else(\n    is.na(body_mass_g), 1, 0\n  )) %>%\n  group_by(species, missing_body_mass_g) %>%\n  tally()\n\n# Source:   SQL [5 x 3]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/:memory:]\n  species   missing_body_mass_g     n\n  <fct>                   <dbl> <dbl>\n1 Adelie                      0   151\n2 Adelie                      1     1\n3 Gentoo                      0   123\n4 Gentoo                      1     1\n5 Chinstrap                   0    68\n\n\nWe can get the mean for each of the species (dropping those two missing records).\n\npenguins_db %>%\n  group_by(species) %>%\n  summarise(mean_body_mass_g = round(mean(body_mass_g, na.rm = TRUE), 0))\n\n# Source:   SQL [3 x 2]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/:memory:]\n  species   mean_body_mass_g\n  <fct>                <dbl>\n1 Adelie                3701\n2 Gentoo                5076\n3 Chinstrap             3733\n\n\nWe can then also do a histogram for each of the species.\n\npenguins_db %>%\n  collect() %>%\n  ggplot(aes(group = species, fill = species)) +\n  facet_grid(species ~ .) +\n  geom_histogram(aes(body_mass_g), colour = \"black\", binwidth = 100) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nChoosing the right time to collect\n\n\n\n\n\ncollect() brings data out of the database and into R. Above we use it to bring the entire penguins data back into R so that we can then use ggplot() to make our histogram.\nGenerally speaking we want to keep as much computation as possible on the database side, up until the point we need to bring the data out for further analysis steps that are not possible using SQL. This could be like the case above for plotting, but could also be for other analytic steps like fitting statistical models. In such cases it is important that we only bring out the required data.\n\n\n\nHow about the relationship between body mass and bill depth?\n\npenguins %>%\n  collect() %>%\n  ggplot(aes(x = bill_depth_mm, y = body_mass_g)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\nSo a negative correlation between body mass and bill depth - that seems rather unexpected. But what about if we stratify by species?\n\npenguins %>%\n  collect() %>%\n  ggplot(aes(x = bill_depth_mm, y = body_mass_g)) +\n  facet_grid(species ~ .) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\nAs well as having an example of working with data in database from R, you also have an example of Simpson´s paradox! And now we’ve reached the end of this example, we can close our connection to the database.\n\ndbDisconnect(db)"
  },
  {
    "objectID": "ch_1_getting_started.html#further-reading",
    "href": "ch_1_getting_started.html#further-reading",
    "title": "1  Getting started",
    "section": "1.8 Further reading",
    "text": "1.8 Further reading\n\nR for Data Science (Chapter 13: Relational data)\nWriting SQL with dbplyr\nData Carpentry: SQL databases and R"
  },
  {
    "objectID": "ch_2_cdm_reference.html",
    "href": "ch_2_cdm_reference.html",
    "title": "2  Creating a reference to the OMOP common data model",
    "section": "",
    "text": "Database connections from R can be made using the DBI package. The back-end for DBI is facilitated by database specific driver packages. As an example, lets say we want to work with a local duckdb from R. In this case the we can use the duckdb R package as the driver, connecting to a database with the OMOP CDM for a synthetic population of 200,000 people.\n\nlibrary(DBI)\nlibrary(here)\n\n\ndb<-dbConnect(duckdb::duckdb(), \n              dbdir= Sys.getenv(\"DUCKDB\"))\n\nIf we instead wanted to connect to other database management systems, these connections would be supported by the associated back-end packages. For example a connection to a Postgres database would look something like:\n\n# Postgres\ndb <- DBI::dbConnect(RPostgres::Postgres(),\n                      dbname = Sys.getenv(\"CDM5_POSTGRESQL_DBNAME\"),\n                      host = Sys.getenv(\"CDM5_POSTGRESQL_HOST\"),\n                      user = Sys.getenv(\"CDM5_POSTGRESQL_USER\"),\n                      password = Sys.getenv(\"CDM5_POSTGRESQL_PASSWORD\"))"
  },
  {
    "objectID": "ch_2_cdm_reference.html#creating-a-reference-to-the-omop-common-data-model",
    "href": "ch_2_cdm_reference.html#creating-a-reference-to-the-omop-common-data-model",
    "title": "2  Creating a reference to the OMOP common data model",
    "section": "2.2 Creating a reference to the OMOP common data model",
    "text": "2.2 Creating a reference to the OMOP common data model\nAs seen in the previous chapter, once a connection to the database has been created we could then create references to the various tables in the database and build queries using in a familiar dplyr style. However, as we the structure of the OMOP CDM is already known, we can avoid the overhead of creating individual references to the OMOP CDM tables by using the CDMConnector package. CDMConnector will do the work for us and quickly create a joint reference for all the tables in the OMOP CDM.\nIf you don’t already have it installed, the first step would be to install CDMConnector from CRAN.\n\ninstall.packages(\"CDMConnector\")\n\nFor this example, we’ll use an example dataset (synthea-covid19-10k) provided by CDMConnector. First let’s load packages and then download the example data.\n\nlibrary(DBI)\nlibrary(CDMConnector)\nlibrary(here)\n\n\ndownloadEunomiaData(\n  datasetName = \"synthea-covid19-10k\",\n  cdmVersion = \"5.3\",\n  pathToData = here(),\n  overwrite = FALSE\n)\n\nAfter connecting to the database containing the OMOP CDM, we use CDMConnector to create our cdm reference.\n\ndb<-dbConnect(duckdb::duckdb(), \n              dbdir = eunomiaDir(datasetName = \"synthea-covid19-10k\"))\ncdm <- cdm_from_con(con = db, \n                    cdm_schema = \"main\")\ncdm\n\n# OMOP CDM reference (tbl_duckdb_connection)\n\nTables: person, observation_period, visit_occurrence, visit_detail, condition_occurrence, drug_exposure, procedure_occurrence, device_exposure, measurement, observation, death, note, note_nlp, specimen, fact_relationship, location, care_site, provider, payer_plan_period, cost, drug_era, dose_era, condition_era, metadata, cdm_source, concept, vocabulary, domain, concept_class, concept_relationship, relationship, concept_synonym, concept_ancestor, source_to_concept_map, drug_strength, cohort_definition, attribute_definition\n\n\nOnce we have created the our reference to the overall OMOP CDM, we can reference specific tables using the “$” operator.\n\ncdm$observation_period\n\n# Source:   table<main.observation_period> [?? x 5]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp4qxVqZ\\file741c562069a2.duckdb]\n   observation_period_id person_id observation_period_s…¹ observation_period_e…²\n                   <int>     <int> <date>                 <date>                \n 1                     1         1 2014-05-09             2023-05-12            \n 2                     2         2 1977-04-11             1986-09-15            \n 3                     3         3 2014-04-19             2023-04-22            \n 4                     4         4 2014-03-22             2023-04-08            \n 5                     5         5 2013-11-13             2023-01-04            \n 6                     6         6 2013-07-17             2021-08-04            \n 7                     7         7 2013-06-26             2022-08-17            \n 8                     8         8 2018-08-20             2022-07-25            \n 9                     9         9 2013-08-03             2022-09-24            \n10                    10        10 2013-08-11             2023-04-02            \n# ℹ more rows\n# ℹ abbreviated names: ¹​observation_period_start_date,\n#   ²​observation_period_end_date\n# ℹ 1 more variable: period_type_concept_id <int>\n\n\nAlternatively, you could also access a specific table reference like so\n\ncdm[[\"observation_period\"]]\n\n# Source:   table<main.observation_period> [?? x 5]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp4qxVqZ\\file741c562069a2.duckdb]\n   observation_period_id person_id observation_period_s…¹ observation_period_e…²\n                   <int>     <int> <date>                 <date>                \n 1                     1         1 2014-05-09             2023-05-12            \n 2                     2         2 1977-04-11             1986-09-15            \n 3                     3         3 2014-04-19             2023-04-22            \n 4                     4         4 2014-03-22             2023-04-08            \n 5                     5         5 2013-11-13             2023-01-04            \n 6                     6         6 2013-07-17             2021-08-04            \n 7                     7         7 2013-06-26             2022-08-17            \n 8                     8         8 2018-08-20             2022-07-25            \n 9                     9         9 2013-08-03             2022-09-24            \n10                    10        10 2013-08-11             2023-04-02            \n# ℹ more rows\n# ℹ abbreviated names: ¹​observation_period_start_date,\n#   ²​observation_period_end_date\n# ℹ 1 more variable: period_type_concept_id <int>\n\n\nWhen creating our cdm reference we can also specify a write schema. This would be a schema in which we have permission to create tables (as we’re unlikely to have that permission for the schema containing the tables with the patient-level data).\n\ncdm <- cdm_from_con(db,\n  cdm_schema = \"main\",\n  write_schema = \"results\")\n\n\n\n\n\n\n\nSetting a write prefix\n\n\n\n\n\nWe can set a prefix that to use when permanent tables are created the write schema. This can be useful when we’re sharing our write schema with others and want to avoid table name conflicts.\n\ncdm <- cdm_from_con(db,\n  cdm_schema = \"main\",\n  write_schema = c(schema=\"main\", prefix = \"example_\"))"
  },
  {
    "objectID": "ch_2_cdm_reference.html#cdm-name",
    "href": "ch_2_cdm_reference.html#cdm-name",
    "title": "2  Creating a reference to the OMOP common data model",
    "section": "2.3 CDM name",
    "text": "2.3 CDM name\nOur cdm reference will be associated with a name. By default this name will be taken from the cdm source name field from the cdm source table. We can though set this to a different name when creating our cdm reference. This cdm name attribute of our reference is particularly useful in the context of network studies to keep track of which results are associated with which database.\n\ncdm <- cdm_from_con(db,\n  cdm_schema = \"main\")\ncdm$cdm_source\n\n# Source:   table<main.cdm_source> [1 x 10]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp4qxVqZ\\file741c562069a2.duckdb]\n  cdm_source_name cdm_source_abbreviation cdm_holder source_description    \n  <chr>           <chr>                   <chr>      <chr>                 \n1 Synthea         Synthea                 \"\"         Synthea Synthetic Data\n# ℹ 6 more variables: source_documentation_reference <chr>,\n#   cdm_etl_reference <chr>, source_release_date <date>,\n#   cdm_release_date <date>, cdm_version <chr>, vocabulary_version <chr>\n\nattr(cdm, \"cdm_name\")\n\n[1] \"Synthea\"\n\ncdm <- cdm_from_con(db,\n  cdm_schema = \"main\", \n  cdm_name = \"my_cdm\")\nattr(cdm, \"cdm_name\")\n\n[1] \"my_cdm\""
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html",
    "href": "ch_3_exploring_the_cdm.html",
    "title": "3  Exploring the CDM",
    "section": "",
    "text": "For this chapter, lets continue using our example COVID-19 dataset."
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#counting-people",
    "href": "ch_3_exploring_the_cdm.html#counting-people",
    "title": "3  Exploring the CDM",
    "section": "3.1 Counting people",
    "text": "3.1 Counting people\nThe OMOP CDM is person-centric, with the person table containing records to uniquely identify each person in the database. As each row refers to a unique person, we can quickly get a count of the number of individuals in the database like so\n\ncdm$person %>% \n  count() %>% \n  pull()\n\n[1] 10754\n\n\nThe person table also contains some demographic information, including a gender concept for each person. We can get a count grouped by this variable, but as this uses a concept we’ll also need to join to the concept table to get the corresponding concept name for each concept id.\n\ncdm$person %>% \n  group_by(gender_concept_id) %>% \n  count() %>% \n  left_join(cdm$concept, \n            by=c(\"gender_concept_id\" = \"concept_id\")) %>% \n              select(\"gender_concept_id\", \"concept_name\", \"n\") %>% \n  collect()\n\n# A tibble: 2 × 3\n# Groups:   gender_concept_id [2]\n  gender_concept_id concept_name     n\n              <int> <chr>        <dbl>\n1              8532 FEMALE        5165\n2              8507 MALE          5589\n\n\nThe observation period table contains records indicating spans of time over which clinical events can be reliably observed for the people in the person table. Someone can potentially have multiple observation periods. So say we wanted a count of people grouped by the year during which their first observation period started. We could do this like so:\n\nfirst_observation_period <- cdm$observation_period %>%\n    group_by(person_id) %>% \n    filter(row_number() == 1) %>% \n    computeQuery()\n\ncdm$person %>% \n  left_join(first_observation_period,\n            by = \"person_id\") %>% \n  mutate(observation_period_start_year=year(observation_period_start_date)) %>% \n  group_by(observation_period_start_year) %>% \n  count() %>% \n  collect() %>% \n  ggplot() +\n  geom_col(aes(observation_period_start_year, n)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nComputing intermediate queries\n\n\n\n\n\nThe computeQuery() function will force the computation of a query. In the example above we use it to split up two queries; the first to keep the first observation period record for each individual.\n\ncdm$observation_period %>%\n    group_by(person_id) %>% \n    filter(row_number() == 1) %>% \n    show_query()\n\n<SQL>\nSELECT\n  observation_period_id,\n  person_id,\n  observation_period_start_date,\n  observation_period_end_date,\n  period_type_concept_id\nFROM (\n  SELECT *, ROW_NUMBER() OVER (PARTITION BY person_id) AS q03\n  FROM main.observation_period\n) q01\nWHERE (q03 = 1.0)\n\n\nFollowed by a second query that left joins the person table with the result from the first (which is now in a temporary table), followed by extracted the year in which peoples first observation period starts and then, finally, a count by year.\n\ncdm$person %>% \n  left_join(first_observation_period,\n            by = \"person_id\") %>% \n  mutate(observation_period_start_year=year(observation_period_start_date)) %>% \n  group_by(observation_period_start_year) %>% \n  count() %>% \n  show_query()\n\n<SQL>\nSELECT observation_period_start_year, COUNT(*) AS n\nFROM (\n  SELECT\n    *,\n    EXTRACT(year FROM observation_period_start_date) AS observation_period_start_year\n  FROM (\n    SELECT\n      \"main.person\".*,\n      observation_period_id,\n      observation_period_start_date,\n      observation_period_end_date,\n      period_type_concept_id\n    FROM main.person AS \"main.person\"\n    LEFT JOIN dbplyr_001\n      ON (\"main.person\".person_id = dbplyr_001.person_id)\n  ) q01\n) q02\nGROUP BY observation_period_start_year\n\n\nWe could, however, have done this without compute, with instead the SQL being done all at once.\n\ncdm$person %>% \n  left_join(cdm$observation_period %>%\n    group_by(person_id) %>% \n    filter(row_number() == 1),\n            by = \"person_id\") %>% \n  mutate(observation_period_start_year=year(observation_period_start_date)) %>% \n  group_by(observation_period_start_year) %>% \n  count() %>% \n  show_query()\n\n<SQL>\nSELECT observation_period_start_year, COUNT(*) AS n\nFROM (\n  SELECT\n    *,\n    EXTRACT(year FROM observation_period_start_date) AS observation_period_start_year\n  FROM (\n    SELECT\n      \"main.person\".*,\n      observation_period_id,\n      observation_period_start_date,\n      observation_period_end_date,\n      period_type_concept_id\n    FROM main.person AS \"main.person\"\n    LEFT JOIN (\n      SELECT\n        observation_period_id,\n        person_id,\n        observation_period_start_date,\n        observation_period_end_date,\n        period_type_concept_id\n      FROM (\n        SELECT *, ROW_NUMBER() OVER (PARTITION BY person_id) AS q03\n        FROM main.observation_period\n      ) q01\n      WHERE (q03 = 1.0)\n    ) RHS\n      ON (\"main.person\".person_id = RHS.person_id)\n  ) q02\n) q03\nGROUP BY observation_period_start_year\n\n\nIn this case the SQL is not much more complicated than before. However, you can imagine that without forcing computation, the SQL associated with a series of data manipulations could quickly become unmanageable. So although we don’t want to overuse computation of intermediate queries, it is often a necessity when writing analysis scripts.\nAn advantage of computing a query, is that we can then use the result for multiple subsequent queries. For example, say we want a count of condition occurrence and drug exposure records for those born before 1970. We could get these counts independently:\n\ncdm$person %>% \n  filter(year_of_birth < \"1970\") %>% \n  select(\"person_id\") %>% \n  left_join(cdm$condition_occurrence,\n            by=\"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpcBAPun\\file7cc1702327.duckdb]\n      n\n  <dbl>\n1  9305\n\ncdm$person %>% \n  filter(year_of_birth < \"1970\") %>% \n  select(\"person_id\") %>% \n  left_join(cdm$drug_exposure,\n            by=\"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpcBAPun\\file7cc1702327.duckdb]\n       n\n   <dbl>\n1 165681\n\n\nBut we could have instead first subsetted the person table and then used the result for both queries.\n\ncdm$person_pre_1970 <- cdm$person %>% \n  filter(year_of_birth < \"1970\") %>% \n  computeQuery()\n\ncdm$person_pre_1970 %>% \n  select(\"person_id\") %>% \n  left_join(cdm$condition_occurrence,\n            by=\"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpcBAPun\\file7cc1702327.duckdb]\n      n\n  <dbl>\n1  9305\n\ncdm$person_pre_1970 %>% \n  select(\"person_id\") %>% \n  left_join(cdm$drug_exposure,\n            by=\"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpcBAPun\\file7cc1702327.duckdb]\n       n\n   <dbl>\n1 165681\n\n\nHere we’ve been using computeQuery() from the CDMConnector package. This function is an extension of the compute() function from dplyr, with computeQuery() providing greater consistency across its supported database management systems.\n\ncdm$person %>% \n  tally() %>% \n  computeQuery()\n\n# Source:   table<dbplyr_003> [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpcBAPun\\file7cc1702327.duckdb]\n      n\n  <dbl>\n1 10754"
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#counting-records",
    "href": "ch_3_exploring_the_cdm.html#counting-records",
    "title": "3  Exploring the CDM",
    "section": "3.2 Counting records",
    "text": "3.2 Counting records\nWhat’s the number of condition occurrence records per person in the database? We can find out like so\n\ncdm$person %>% \n  left_join(cdm$condition_occurrence %>% \n  group_by(person_id) %>% \n  count(name = \"condition_occurrence_records\"),\n  by=\"person_id\") %>% \n  mutate(condition_occurrence_records = if_else(\n    is.na(condition_occurrence_records), 0,\n    condition_occurrence_records)) %>% \n  group_by(condition_occurrence_records) %>%\n  count() %>% \n  collect() %>% \n  ggplot() +\n  geom_col(aes(condition_occurrence_records, n)) +\n  theme_bw()\n\n\n\n\nHow about we were interested in getting record counts for some specific concepts related to COVID-19 symptoms?\n\ncdm$condition_occurrence %>% \n  filter(condition_concept_id %in% c(437663,437390,31967,\n                                     4289517,4223659, 312437,\n                                     434490,254761,77074)) %>% \n  group_by(condition_concept_id) %>% \n  count() %>% \n  left_join(cdm$concept,\n            by=c(\"condition_concept_id\" = \"concept_id\")) %>% \n  collect() %>% \n  ggplot() +\n  geom_col(aes(concept_name, n)) +\n  theme_bw()+\n  xlab(\"\")\n\n\n\n\n\n\n\n\n\n\nVocabulary tables\n\n\n\n\n\nAbove we’ve got counts by specific concept IDs recorded in the condition occurrence table. What these IDs represent is described in the concept table. Here we have the name associate with the concept, along with other information such as it’s domain and vocabulary id.\n\ncdm$concept %>% \n  glimpse()\n\nRows: ??\nColumns: 10\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpcBAPun\\file7cc1702327.duckdb]\n$ concept_id       <int> 45756805, 45756804, 45756803, 45756802, 45756801, 457…\n$ concept_name     <chr> \"Pediatric Cardiology\", \"Pediatric Anesthesiology\", \"…\n$ domain_id        <chr> \"Provider\", \"Provider\", \"Provider\", \"Provider\", \"Prov…\n$ vocabulary_id    <chr> \"ABMS\", \"ABMS\", \"ABMS\", \"ABMS\", \"ABMS\", \"ABMS\", \"ABMS…\n$ concept_class_id <chr> \"Physician Specialty\", \"Physician Specialty\", \"Physic…\n$ standard_concept <chr> \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\"…\n$ concept_code     <chr> \"OMOP4821938\", \"OMOP4821939\", \"OMOP4821940\", \"OMOP482…\n$ valid_start_date <date> 1970-01-01, 1970-01-01, 1970-01-01, 1970-01-01, 1970…\n$ valid_end_date   <date> 2099-12-31, 2099-12-31, 2099-12-31, 2099-12-31, 2099…\n$ invalid_reason   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\nOther vocabulary tables capture other information about concepts, such as the direct relationships between concepts (the concept relationship table) and hierarchical relationships between (the concept ancestor table).\n\ncdm$concept_relationship %>% \n  glimpse()\n\nRows: ??\nColumns: 6\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpcBAPun\\file7cc1702327.duckdb]\n$ concept_id_1     <int> 35804314, 35804314, 35804314, 35804327, 35804327, 358…\n$ concept_id_2     <int> 912065, 42542145, 42542145, 35803584, 42542145, 42542…\n$ relationship_id  <chr> \"Has modality\", \"Has accepted use\", \"Is current in\", …\n$ valid_start_date <date> 2021-01-26, 2019-08-29, 2019-08-29, 2019-05-27, 2019…\n$ valid_end_date   <date> 2099-12-31, 2099-12-31, 2099-12-31, 2099-12-31, 2099…\n$ invalid_reason   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\ncdm$concept_ancestor %>% \n  glimpse()\n\nRows: ??\nColumns: 4\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpcBAPun\\file7cc1702327.duckdb]\n$ ancestor_concept_id      <int> 375415, 727760, 735979, 438112, 529411, 14196…\n$ descendant_concept_id    <int> 4335743, 2056453, 41070383, 36566114, 4326940…\n$ min_levels_of_separation <int> 4, 1, 3, 2, 3, 3, 4, 3, 2, 5, 1, 3, 4, 2, 2, …\n$ max_levels_of_separation <int> 4, 1, 5, 3, 3, 6, 12, 3, 2, 10, 1, 3, 4, 2, 2…\n\n\nMore information on the vocabulary tables (as well as other tables in the OMOP CDM version 5.3) can be found at https://ohdsi.github.io/CommonDataModel/cdm53.html#Vocabulary_Tables."
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#working-with-dates",
    "href": "ch_3_exploring_the_cdm.html#working-with-dates",
    "title": "3  Exploring the CDM",
    "section": "3.3 Working with dates",
    "text": "3.3 Working with dates\nDates are supported somewhat inconsistently by dbplyr but, as with computeQuery(), CDMConnector also provides some date functions that are tested to work across supported databases. We can use the datediff() function for example to calculate the difference between two dates. We can use this below to get the number of years observation periods last for.\n\ncdm$observation_period %>%\n  dplyr::mutate(observation_years = \n                  !!CDMConnector::datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"year\"))  %>% \n  collect() %>% \n  ggplot() +\n  geom_histogram(aes(observation_years), \n                 binwidth=2, colour=\"grey\") +\n  theme_bw()"
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#statistical-summaries",
    "href": "ch_3_exploring_the_cdm.html#statistical-summaries",
    "title": "3  Exploring the CDM",
    "section": "3.4 Statistical summaries",
    "text": "3.4 Statistical summaries\nWe can also use summarise for various other calculations\n\ncdm$person %>% \n  summarise(min_year_of_birth = min(year_of_birth, na.rm=TRUE),\n            q05_year_of_birth = quantile(year_of_birth, 0.05, na.rm=TRUE),\n            mean_year_of_birth = round(mean(year_of_birth, na.rm=TRUE),0),\n            median_year_of_birth = median(year_of_birth, na.rm=TRUE),\n            q95_year_of_birth = quantile(year_of_birth, 0.95, na.rm=TRUE),\n            max_year_of_birth = max(year_of_birth, na.rm=TRUE)) %>%  \n  glimpse()\n\nRows: ??\nColumns: 6\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpcBAPun\\file7cc1702327.duckdb]\n$ min_year_of_birth    <int> 1923\n$ q05_year_of_birth    <dbl> 1927\n$ mean_year_of_birth   <dbl> 1971\n$ median_year_of_birth <dbl> 1970\n$ q95_year_of_birth    <dbl> 2018\n$ max_year_of_birth    <int> 2023\n\n\n\n\n\n\n\n\nPiping and SQL\n\n\n\n\n\nAlthough piping queries has little impact on performance when using R with data in memory, when working with a database the SQL generated will differ when using multiple function calls (with a separate operation specified in each) instead of multiple operations within a single function call.\nFor example, a single mutate function above would generate the below SQL.\n\ncdm$observation_period %>%\n  mutate(observation_days = !!datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"day\"),\n        observation_years = !!datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"year\")) %>% \n  select(\"observation_period_id\", \"person_id\", \n         \"observation_days\",\"observation_years\") %>% \n  show_query()\n\n<SQL>\nSELECT\n  observation_period_id,\n  person_id,\n  datediff('day', observation_period_start_date, observation_period_end_date) AS observation_days,\n  FLOOR((date_part('year', observation_period_end_date) * 10000 + date_part('month', observation_period_end_date) * 100 + date_part('day', observation_period_end_date) -\n(date_part('year', observation_period_start_date) * 10000 + date_part('month', observation_period_start_date) * 100 + date_part('day', observation_period_start_date))) / 10000) AS observation_years\nFROM main.observation_period\n\n\nWhereas the SQL will be different if using multiple mutate calls (now using a sub-query).\n\ncdm$observation_period %>%\n  mutate(observation_days = !!datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"day\")) %>% \n  mutate(observation_years = !!datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"year\")) %>% \n  select(\"observation_period_id\", \"person_id\", \n         \"observation_days\",\"observation_years\") %>% \n  show_query()\n\n<SQL>\nSELECT\n  observation_period_id,\n  person_id,\n  observation_days,\n  FLOOR((date_part('year', observation_period_end_date) * 10000 + date_part('month', observation_period_end_date) * 100 + date_part('day', observation_period_end_date) -\n(date_part('year', observation_period_start_date) * 10000 + date_part('month', observation_period_start_date) * 100 + date_part('day', observation_period_start_date))) / 10000) AS observation_years\nFROM (\n  SELECT\n    *,\n    datediff('day', observation_period_start_date, observation_period_end_date) AS observation_days\n  FROM main.observation_period\n) q01\n\n\n\n\n\nAs we’ve seen before, we can also quickly get results for various groupings or restrictions\n\ncdm$person %>% \n   group_by(gender_concept_id) %>% \n   summarise(min_year_of_birth = min(year_of_birth, na.rm=TRUE),\n            q25_year_of_birth = quantile(year_of_birth, 0.25, na.rm=TRUE),\n            median_year_of_birth = median(year_of_birth, na.rm=TRUE),\n            q75_year_of_birth = quantile(year_of_birth, 0.75, na.rm=TRUE),\n            max_year_of_birth = max(year_of_birth, na.rm=TRUE)) %>% \n  left_join(cdm$concept, \n            by=c(\"gender_concept_id\" = \"concept_id\")) %>% \n   collect() %>% \n  ggplot(aes(x = concept_name, group = concept_name,\n             fill = concept_name)) +\n  geom_boxplot(aes(\n    lower = q25_year_of_birth, \n    upper = q75_year_of_birth, \n    middle = median_year_of_birth, \n    ymin = min_year_of_birth, \n    ymax = max_year_of_birth),\n    stat = \"identity\", width = 0.5) + \n  theme_bw()+ \n  theme(legend.position = \"none\") +\n  xlab(\"\")"
  },
  {
    "objectID": "ch_4_adding_features.html",
    "href": "ch_4_adding_features.html",
    "title": "4  Identifying patient characteristics",
    "section": "",
    "text": "For this chapter, we’ll again use our example COVID-19 dataset.\nAs part of an analysis we almost always have a need to identify certain characteristics related to the individuals in our data. These characteristics might be time-invariant (ie a characteristic that does not change as time passes and a person ages) or time-varying. In various datasets, however, characteristics that could conceptually be considered as time-varying are encoded as time-invariant. One example for the latter is that in some cases an individual may be associated with a particular socioeconomic status or nationality that for the purposes of the data is treated as time-invariant."
  },
  {
    "objectID": "ch_4_adding_features.html#adding-specific-demographics",
    "href": "ch_4_adding_features.html#adding-specific-demographics",
    "title": "4  Identifying patient characteristics",
    "section": "4.1 Adding specific demographics",
    "text": "4.1 Adding specific demographics\nThe PatientProfiles package makes it easy for us to add demographic information to tables in the OMOP CDM. Say we are interested in individuals age and sex at time of diagnosis with COVID-19, we can add these variables to the table like so. Note that because age is time-varying, we have to specify the variable with the date for which we want to calculate age relative to.\n\ncdm$condition_occurrence <- cdm$condition_occurrence %>% \n  addSex() %>% \n  addAge(indexDate = \"condition_start_date\")\n\ncdm$condition_occurrence %>% \n  glimpse()\n\nRows: ??\nColumns: 18\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmpq4MXyf\\file6750276b2a60.duckdb]\n$ condition_occurrence_id       <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…\n$ person_id                     <int> 2, 6, 7, 8, 8, 8, 8, 16, 16, 18, 18, 25,…\n$ condition_concept_id          <int> 381316, 321042, 381316, 37311061, 437663…\n$ condition_start_date          <date> 1986-09-08, 2021-06-23, 2021-04-07, 202…\n$ condition_start_datetime      <dttm> 1986-09-08, 2021-06-23, 2021-04-07, 202…\n$ condition_end_date            <date> 1986-09-08, 2021-06-23, 2021-04-07, 202…\n$ condition_end_datetime        <dttm> 1986-09-08, 2021-06-23, 2021-04-07, 202…\n$ condition_type_concept_id     <int> 38000175, 38000175, 38000175, 38000175, …\n$ condition_status_concept_id   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ stop_reason                   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ provider_id                   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ visit_occurrence_id           <int> 19, 55, 67, 79, 79, 79, 79, 168, 171, 19…\n$ visit_detail_id               <int> 1000019, 1000055, 1000067, 1000079, 1000…\n$ condition_source_value        <chr> \"230690007\", \"410429000\", \"230690007\", \"…\n$ condition_source_concept_id   <int> 381316, 321042, 381316, 37311061, 437663…\n$ condition_status_source_value <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sex                           <chr> \"Female\", \"Male\", \"Male\", \"Male\", \"Male\"…\n$ age                           <dbl> 57, 25, 97, 2, 2, 2, 2, 75, 77, 57, 76, …\n\n\nWe now have two variables added containing values for age and sex.\n\ncdm$condition_occurrence %>% \n  glimpse()\n\nRows: ??\nColumns: 18\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmpq4MXyf\\file6750276b2a60.duckdb]\n$ condition_occurrence_id       <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…\n$ person_id                     <int> 2, 6, 7, 8, 8, 8, 8, 16, 16, 18, 18, 25,…\n$ condition_concept_id          <int> 381316, 321042, 381316, 37311061, 437663…\n$ condition_start_date          <date> 1986-09-08, 2021-06-23, 2021-04-07, 202…\n$ condition_start_datetime      <dttm> 1986-09-08, 2021-06-23, 2021-04-07, 202…\n$ condition_end_date            <date> 1986-09-08, 2021-06-23, 2021-04-07, 202…\n$ condition_end_datetime        <dttm> 1986-09-08, 2021-06-23, 2021-04-07, 202…\n$ condition_type_concept_id     <int> 38000175, 38000175, 38000175, 38000175, …\n$ condition_status_concept_id   <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ stop_reason                   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ provider_id                   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ visit_occurrence_id           <int> 19, 55, 67, 79, 79, 79, 79, 168, 171, 19…\n$ visit_detail_id               <int> 1000019, 1000055, 1000067, 1000079, 1000…\n$ condition_source_value        <chr> \"230690007\", \"410429000\", \"230690007\", \"…\n$ condition_source_concept_id   <int> 381316, 321042, 381316, 37311061, 437663…\n$ condition_status_source_value <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sex                           <chr> \"Female\", \"Male\", \"Male\", \"Male\", \"Male\"…\n$ age                           <dbl> 57, 25, 97, 2, 2, 2, 2, 75, 77, 57, 76, …\n\n\nAnd with these now added it is straightforward to calculate mean age at condition start date by sex.\n\ncdm$condition_occurrence %>%\n  summarise(mean_age = mean(age, na.rm=TRUE), .by = \"sex\")\n\n# Source:   SQL [2 x 2]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmpq4MXyf\\file6750276b2a60.duckdb]\n  sex    mean_age\n  <chr>     <dbl>\n1 Female     50.8\n2 Male       56.5"
  },
  {
    "objectID": "ch_4_adding_features.html#adding-multiple-demographics-simultaneously",
    "href": "ch_4_adding_features.html#adding-multiple-demographics-simultaneously",
    "title": "4  Identifying patient characteristics",
    "section": "4.2 Adding multiple demographics simultaneously",
    "text": "4.2 Adding multiple demographics simultaneously\nWe’ve now seen individual functions from PatientProfiles to add age and sex, and the package has others to add other characteristics like days of prior history in the database (PatientProfiles::addPriorObservation()). In additional to these individuals functions, the package also provides a more general function to get all of these characteristics at the same time (that is more time efficient that getting them one by one).\n\ncdm$drug_exposure <- cdm$drug_exposure %>% \n  addDemographics(indexDate = \"drug_exposure_start_date\")\n\ncdm$drug_exposure %>% \n  glimpse()\n\nRows: ??\nColumns: 27\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmpq4MXyf\\file6750276b2a60.duckdb]\n$ drug_exposure_id             <int> 245761, 245762, 245763, 245764, 245765, 2…\n$ person_id                    <int> 7764, 7764, 7764, 7764, 7764, 7764, 7764,…\n$ drug_concept_id              <int> 40213227, 40213201, 40213198, 40213154, 4…\n$ drug_exposure_start_date     <date> 2015-02-08, 2010-01-10, 2010-01-10, 2017…\n$ drug_exposure_start_datetime <dttm> 2015-02-08 22:40:04, 2010-01-10 22:40:04…\n$ drug_exposure_end_date       <date> 2015-02-08, 2010-01-10, 2010-01-10, 2017…\n$ drug_exposure_end_datetime   <dttm> 2015-02-08 22:40:04, 2010-01-10 22:40:04…\n$ verbatim_end_date            <date> 2015-02-08, 2010-01-10, 2010-01-10, 2017…\n$ drug_type_concept_id         <int> 32869, 32869, 32869, 32869, 32869, 32869,…\n$ stop_reason                  <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ refills                      <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ quantity                     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ days_supply                  <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ sig                          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ route_concept_id             <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lot_number                   <chr> \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"…\n$ provider_id                  <int> 14656, 14656, 14656, 14656, 14656, 14656,…\n$ visit_occurrence_id          <int> 80896, 80891, 80891, 80892, 80895, 80896,…\n$ visit_detail_id              <int> 1080896, 1080891, 1080891, 1080892, 10808…\n$ drug_source_value            <chr> \"113\", \"33\", \"133\", \"140\", \"140\", \"140\", …\n$ drug_source_concept_id       <int> 40213227, 40213201, 40213198, 40213154, 4…\n$ route_source_value           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ dose_unit_source_value       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ age                          <dbl> 71, 66, 66, 73, 72, 71, 69, 67, 70, 68, 6…\n$ sex                          <chr> \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"…\n$ prior_observation            <dbl> 2597, 742, 742, 3339, 2968, 2597, 1855, 1…\n$ future_observation           <dbl> 896, 2751, 2751, 154, 525, 896, 1638, 238…\n\n\nWith these characteristics now all added, we can now calculate mean age, prior observation (how many days have passed since the individual’s most recent observation start date), and future observation (how many days until the individual’s nearest observation end date) at drug exposure start date by sex.\n\ncdm$drug_exposure %>%\n  summarise(mean_age = mean(age, na.rm=TRUE),\n            mean_prior_observation = mean(prior_observation, na.rm=TRUE),\n            mean_future_observation = mean(future_observation, na.rm=TRUE),\n            .by = \"sex\")\n\n# Source:   SQL [2 x 4]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmpq4MXyf\\file6750276b2a60.duckdb]\n  sex    mean_age mean_prior_observation mean_future_observation\n  <chr>     <dbl>                  <dbl>                   <dbl>\n1 Female     39.4                  2096.                   1661.\n2 Male       43.0                  2455.                   1768."
  },
  {
    "objectID": "ch_4_adding_features.html#creating-categories",
    "href": "ch_4_adding_features.html#creating-categories",
    "title": "4  Identifying patient characteristics",
    "section": "4.3 Creating categories",
    "text": "4.3 Creating categories\nWhen we add age, either via addAge or addDemographics, we can also add another variable containing age groups. These age groups are specified in a list of vectors, each of which contain the lower and upper bounds.\n\ncdm$visit_occurrence <- cdm$visit_occurrence %>%\n  addAge(indexDate = \"visit_start_date\",\n    ageGroup = list(c(0,17), c(18, 64),\n                    c(65, 150)))\n\ncdm$visit_occurrence %>% \n  filter(age >= 0 & age <= 150) %>% \n  group_by(age_group) %>% \n  tally() %>% \n  collect() %>% \n  ggplot() + \n  geom_col(aes(x = age_group, y = n)) + \n  theme_bw()\n\n\n\n\nPatientProfiles also provides a more general function for adding categories. Can you guess it’s name? That’s right, we have PatientProfiles::addCategories() for this.\n\ncdm$condition_occurrence %>%\n  addPriorObservation(indexDate = \"condition_start_date\") %>%\n  addCategories(\n    variable = \"prior_observation\",\n    categories = list(\"prior_observation_group\" = list(\n      c(0, 364), c(365, 999999) # Inf not currently supported as an upper bound \n    ))\n  )\n\n# Source:   table<dbplyr_007> [?? x 20]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmpq4MXyf\\file6750276b2a60.duckdb]\n   condition_occurrence_id person_id condition_concept_id condition_start_date\n                     <int>     <int>                <int> <date>              \n 1                       1         2               381316 1986-09-08          \n 2                       2         6               321042 2021-06-23          \n 3                       3         7               381316 2021-04-07          \n 4                       4         8             37311061 2021-01-08          \n 5                       5         8               437663 2021-01-08          \n 6                       6         8              4089228 2021-01-08          \n 7                       7         8               254761 2021-01-08          \n 8                       8        16               381316 2020-02-11          \n 9                       9        16               313217 2021-10-05          \n10                      10        18               317576 1993-08-08          \n# ℹ more rows\n# ℹ 16 more variables: condition_start_datetime <dttm>,\n#   condition_end_date <date>, condition_end_datetime <dttm>,\n#   condition_type_concept_id <int>, condition_status_concept_id <int>,\n#   stop_reason <chr>, provider_id <int>, visit_occurrence_id <int>,\n#   visit_detail_id <int>, condition_source_value <chr>,\n#   condition_source_concept_id <int>, condition_status_source_value <chr>, …"
  },
  {
    "objectID": "ch_4_adding_features.html#adding-custom-variables",
    "href": "ch_4_adding_features.html#adding-custom-variables",
    "title": "4  Identifying patient characteristics",
    "section": "4.4 Adding custom variables",
    "text": "4.4 Adding custom variables\nWhile PatientProfiles provides a range of functions that can help add characteristics of interest, you may want to add other, custom features. Obviously we can’t cover here all possible custom characteristics you may wish to add. However, custom features do generally come in two forms.\nThe first is where we want to add a new variable derived from other variables in our table. Here we’ll be using dplyr::mutate(). For example, perhaps we just want to add a new variable to our observation period table containing the year of individuals’ observation period start date.\n\ncdm$observation_period <- cdm$observation_period %>% \n  mutate(observation_period_start_year = year(observation_period_start_date))\n\ncdm$observation_period %>% \n  glimpse()\n\nRows: ??\nColumns: 6\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmpq4MXyf\\file6750276b2a60.duckdb]\n$ observation_period_id         <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…\n$ person_id                     <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…\n$ observation_period_start_date <date> 2014-05-09, 1977-04-11, 2014-04-19, 201…\n$ observation_period_end_date   <date> 2023-05-12, 1986-09-15, 2023-04-22, 202…\n$ period_type_concept_id        <int> 44814724, 44814724, 44814724, 44814724, …\n$ observation_period_start_year <dbl> 2014, 1977, 2014, 2014, 2013, 2013, 2013…\n\n\nThe second, normally more complex task, is adding a new variable that involves joining to some other table. This table may well have been created by some intermediate query that we wrote to derive the variable of interest. For example, lets say we want to add each number of condition occurrence records for each individual to the person table (remember that we saw how to calculate this in the previous chapter). Here we’ll also create this as a new table containing just the information we’re interested in and compute to a temporary table.\n\ncondition_summary <- cdm$person %>% \n  left_join(cdm$condition_occurrence %>% \n  group_by(person_id) %>% \n  count(name = \"condition_occurrence_records\"),\n  by=\"person_id\") %>% \n  select(\"person_id\", \"condition_occurrence_records\") %>% \n  mutate(condition_occurrence_records = if_else(\n    is.na(condition_occurrence_records), \n    0, condition_occurrence_records)) %>% \n  computeQuery()\n\ncondition_summary %>% \n  glimpse()\n\nRows: ??\nColumns: 2\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmpq4MXyf\\file6750276b2a60.duckdb]\n$ person_id                    <int> 2, 6, 7, 8, 16, 18, 25, 36, 40, 44, 47, 5…\n$ condition_occurrence_records <dbl> 1, 1, 1, 4, 2, 2, 1, 4, 1, 2, 5, 1, 3, 2,…\n\n\n\n\n\n\n\n\nTaking care with joins\n\n\n\n\n\nWhen adding variables through joins we need to pay particular attention to the dimensions of the resulting table. While sometimes we may want to have additional rows added as well as new columns, this is often not desired. If we, for example, have a table with one row per person then a left join to a table with multiple rows per person will result in a table with f we, for example, have a table with one row per person then a left join to a table with multiple rows per person (unless those people with more than record are only in the second table).\nExamples where to be careful include when joining to the observation period table, as individuals can have multiple observation periods, and when working with cohorts (Which are the focus of the next chapter), as individuals can also enter the same study cohort multiple times.\nJust to underline how problematic joins can become if we don’t take care, here we join the condition occurrence table and the drug exposure table both of which have multiple records per person. Remember this is just with our small synthetic data, so when working with real patient data which is oftentimes much, much larger this would be extremely problematic (and would unlikely be needed to answer any research question). In other words, don’t try this at home!\n\ncdm$condition_occurrence %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmpq4MXyf\\file6750276b2a60.duckdb]\n      n\n  <dbl>\n1  9967\n\ncdm$drug_exposure %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmpq4MXyf\\file6750276b2a60.duckdb]\n       n\n   <dbl>\n1 337509\n\ncdm$condition_occurrence %>% \n  select(person_id, condition_start_date) %>% \n  left_join(cdm$drug_exposure %>% \n  select(person_id, drug_exposure_start_date), \n  by = \"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmpq4MXyf\\file6750276b2a60.duckdb]\n       n\n   <dbl>\n1 410683"
  },
  {
    "objectID": "ch_5_creating_cohorts.html",
    "href": "ch_5_creating_cohorts.html",
    "title": "5  Adding cohorts to the CDM",
    "section": "",
    "text": "When performing research with the OMOP common data model we often want to identify groups of individuals who share some set of characteristics. The criteria for including individuals can range from the seemingly simple (e.g. people diagnosed with asthma) to the much more complicated (e.g. adults diagnosed with asthma who had a year of prior observation time in the database prior to their diagnosis, had no prior history of chronic obstructive pulmonary disease, and no history of use of short-acting beta-antagonists).\nThe set of people we identify are cohorts, and the OMOP CDM has a specific structure by which they can be represented, with a cohort table having four required fields: 1) cohort definition id (a unique identifier for each cohort), 2) subject id (a foreign key to the subject in the cohort - typically referring to records in the person table), 3) cohort start date, and 4) cohort end date. Individuals can enter a cohort multiple times, but the time in which they are in the cohort cannot overlap."
  },
  {
    "objectID": "ch_5_creating_cohorts.html#set-up",
    "href": "ch_5_creating_cohorts.html#set-up",
    "title": "5  Adding cohorts to the CDM",
    "section": "5.2 Set up",
    "text": "5.2 Set up\n\nlibrary(CDMConnector)\nlibrary(dplyr)\nlibrary(PatientProfiles)\nlibrary(CodelistGenerator)\nlibrary(IncidencePrevalence)\nlibrary(DrugUtilisation)\n        \ndb <- DBI::dbConnect(duckdb::duckdb(), eunomia_dir())\n\ncdm <- cdm_from_con(\n  con = db,\n  cdm_schema = \"main\",\n  write_schema = \"main\"\n)"
  },
  {
    "objectID": "ch_5_creating_cohorts.html#creating-a-base-cohort",
    "href": "ch_5_creating_cohorts.html#creating-a-base-cohort",
    "title": "5  Adding cohorts to the CDM",
    "section": "5.3 Creating a base cohort",
    "text": "5.3 Creating a base cohort\nWe can create a set of base cohorts using a code lists or concept set\n\n5.3.1 General concept based cohort\n\ncdm <- generate_concept_cohort_set(cdm, \n                            concept_set = list(\"gi_bleed\" = 192671), \n                            limit = \"all\", \n                            end = 30,\n                            name = \"gi_bleed\",\n                            overwrite = TRUE)\ncdm$gi_bleed %>% \n  glimpse()\n\nRows: ??\nColumns: 4\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpwVtT0O\\file4cdc479d4b12.duckdb]\n$ cohort_definition_id <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ subject_id           <int> 260, 549, 787, 795, 962, 1076, 1099, 1112, 1158, …\n$ cohort_start_date    <date> 2010-04-04, 1987-12-28, 2017-04-02, 1982-09-03, …\n$ cohort_end_date      <date> 2010-05-04, 1988-01-27, 2017-05-02, 1982-10-03, …\n\n\n\n\n5.3.2 Characteristic cohorts\nWe can use IncidencePrevalence ….\nHere for example we’ll generate a cohort of people aged between 18 and 50. Individuals will enter the cohort once they are in database and satisfy the age requirement.\n\ncdm <- generateDenominatorCohortSet(cdm = cdm, \n                             name = \"age_cohorts\", \n                             ageGroup = list(c(18, 50)))\n\n\n\n5.3.3 Drug-specific cohorts\nMeanwhile, if we are interested in defining a drug cohort we can use the We can use DrugUtilisation package, where we have additional parameters related to defining cohorts for drug utilisation studies. Below, for example, we create a cohort of acetaminophen users where we combine any combine any two exposures with the less than 7 days between them into the same cohort record.\n\ncdm <- generateDrugUtilisationCohortSet(cdm, \n                                 name = \"acetaminophen\", \n                                 conceptSetList = list(\"acetaminophen\" = \n                                                         c(1125315,\n                                                              1127078,\n                                                              1127433,\n                                                              40229134,\n                                                              40231925,\n                                                              40162522,\n                                                              19133768)), \n                                 gapEra = 7)\n\n\n\n\n\n\n\nFinding appropriate codes\n\n\n\n\n\nIn the defining the cohorts above we have needed to provide concept IDs to define our cohort. But, where do these come from?\nWe can search for codes of interest using the CodelistGenerator package. This can be done using a text search with the function CodelistGenerator::getCandidateCodes(). For example, we can find the GI code we use above like so:\n\ngetCandidateCodes(cdm = cdm, \n                  keywords = \"Gastrointestinal hemorrhage\",\n                  domains = \"condition\",\n                  includeDescendants = TRUE)\n\n# A tibble: 1 × 6\n  concept_id concept_name    domain_id concept_class_id vocabulary_id found_from\n       <int> <chr>           <chr>     <chr>            <chr>         <chr>     \n1     192671 Gastrointestin… condition clinical finding snomed        From init…\n\n\nWe can also do automated searches that make use of the hierarchies in the vocabularies. Here, for example, we find the code for the drug ingredient Acetaminophen and all of it’s descendants.\n\nCodelistGenerator::getDrugIngredientCodes(cdm = cdm, \n                                          name = \"acetaminophen\")\n\n$`Ingredient: Acetaminophen (1125315)`\n[1]  1125315  1127433 40229134 19133768 40231925 40162522  1127078\n\n\nNote that the data we’re using just has a subset of the full OMOP CDM vocabularies. In practice, these searches would return many more codes. And in the case of the former in particular, clinical expertise would then be required to decide which of the codes were in line with the clinical idea at hand.\n\n\n\n\n\n\n\n\n\nApplying the appropriate logic when creating a cohort\n\n\n\n\n\nAs well as including appropriate concepts, we also face various other choices when defining our cohort. Decisions are required as to whether to include only the first event or the all events for an individual. We’ll also need to make decisions cohort end dates, which could range from the same day as cohort entry to the end of an individual’s observation period. For a drug utilisation cohort we then have even more decisions, such whether to combine cohorts with less than some specified days gap between one ending and the next starting.\nThese decisions for cohort logic will often reflect the way the cohort is being used in answering the study question. Like with including the right concepts, careful consideration will need to be taken when deciding on these parameters.\n\n# To add"
  },
  {
    "objectID": "ch_5_creating_cohorts.html#cohort-attributes",
    "href": "ch_5_creating_cohorts.html#cohort-attributes",
    "title": "5  Adding cohorts to the CDM",
    "section": "5.4 Cohort attributes",
    "text": "5.4 Cohort attributes\nThe set of cohorts we create will be associated with various attributes. The cohort set attribute contains information on the cohorts that we’ve generated.\n\ncohortSet(cdm$gi_bleed) %>% \n  glimpse()\n\nRows: 1\nColumns: 2\n$ cohort_definition_id <int> 1\n$ cohort_name          <chr> \"gi_bleed\"\n\n\nAnother attribute contains counts of the cohorts we’ve created.\n\ncohortCount(cdm$gi_bleed) %>% \n  glimpse()\n\nRows: 1\nColumns: 3\n$ cohort_definition_id <int> 1\n$ number_records       <dbl> 479\n$ number_subjects      <dbl> 479\n\n\nAnd we can also see attrition related to the cohort. We’ll see below how any addition inclusion criteria that we apply can be recorded using this attrition attribute.\n\ncohortAttrition(cdm$gi_bleed) %>% \n  glimpse()\n\nRows: 1\nColumns: 7\n$ cohort_definition_id <int> 1\n$ number_records       <dbl> 479\n$ number_subjects      <dbl> 479\n$ reason_id            <dbl> 1\n$ reason               <chr> \"Qualifying initial records\"\n$ excluded_records     <dbl> 0\n$ excluded_subjects    <dbl> 0"
  },
  {
    "objectID": "ch_5_creating_cohorts.html#applying-inclusion-criteria",
    "href": "ch_5_creating_cohorts.html#applying-inclusion-criteria",
    "title": "5  Adding cohorts to the CDM",
    "section": "5.5 Applying inclusion criteria",
    "text": "5.5 Applying inclusion criteria\n\n5.5.1 Applying demographic inclusion criteria\nSay for our study we want to include people with a GI bleed who were aged 40 or over at the time. We can use the add variables with these characteristics as seen in chapter 4 and then filter accordingly. The function CDMConnector::record_cohort_attrition() will then update our cohort attributes as we can see below.\n\ncdm$gi_bleed <- cdm$gi_bleed %>% \n  addDemographics(indexDate = \"cohort_start_date\") %>% \n  filter(age >= 40) %>% \n  record_cohort_attrition(\"Age 18 or older\") %>% \n  filter(sex == \"Male\") %>% \n  record_cohort_attrition(\"Male\")\n\n\ncohortCount(cdm$gi_bleed)\n\n# A tibble: 1 × 3\n  cohort_definition_id number_records number_subjects\n                 <int>          <dbl>           <dbl>\n1                    1             94              94\n\ncohortAttrition(cdm$gi_bleed)\n\n# A tibble: 3 × 7\n  cohort_definition_id number_records number_subjects reason_id reason          \n                 <int>          <dbl>           <dbl>     <dbl> <chr>           \n1                    1            479             479         1 Qualifying init…\n2                    1            183             183         2 Age 18 or older \n3                    1             94              94         3 Male            \n# ℹ 2 more variables: excluded_records <dbl>, excluded_subjects <dbl>\n\n\n\n\n5.5.2 Applying cohort-based inclusion criteria\nAs well as requirements about specific demographics, we may also want to use another cohort for inclusion criteria. Let’s say we want to exclude anyone with rheumatoid arthritis diagnosed before their GI bleed. We can first generate this cohort and then apply this additional exclusion criteria like so.\n\ncdm$gi_bleed <- cdm$gi_bleed %>% \n  addCohortIntersectFlag(targetCohortTable = \"acetaminophen\", \n                         indexDate = \"cohort_start_date\", \n                         window =c(-Inf, -1), \n                         nameStyle = \"acetaminophen_excl\") %>% \n  filter(acetaminophen_excl == 1) %>% \n  record_cohort_attrition(\"Prior use of acetaminophen\")"
  },
  {
    "objectID": "ch_5_creating_cohorts.html#creating-multiple-derived-cohorts",
    "href": "ch_5_creating_cohorts.html#creating-multiple-derived-cohorts",
    "title": "5  Adding cohorts to the CDM",
    "section": "5.6 Creating multiple derived cohorts",
    "text": "5.6 Creating multiple derived cohorts\nTO BE DONE"
  },
  {
    "objectID": "ch_4_adding_features.html#large-scale-characterisation",
    "href": "ch_4_adding_features.html#large-scale-characterisation",
    "title": "4  Identifying patient characteristics",
    "section": "4.5 Large scale characterisation",
    "text": "4.5 Large scale characterisation\nTO ADD"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tidy R programming with the OMOP common data model",
    "section": "",
    "text": "We’ve written this book for anyone interested in a working with databases mapped to the OMOP Common Data Model (CDM) in a tidyverse inspired approach. That is, human centered, consistent, composable, and inclusive (see https://design.tidyverse.org/unifying.html for more details on these principles).\nNew to the OMOP CDM? We’d recommend you pare this book with The Book of OHDSI\nNew to R? We recommend you compliment the book with R for data science\n\n\n\nTO ADD\n\n\n\n This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n\n\n\nThe source code for the book can be found at this Github repository"
  }
]