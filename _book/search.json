[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "An introduction to tidy R programming with the OMOP common data model",
    "section": "",
    "text": "The source code for the book can be found at this Github repository Please open an issue there if you have a question or suggestion. Pull requests with suggested changes and additions are also most welcome."
  },
  {
    "objectID": "ch_1_getting_started.html",
    "href": "ch_1_getting_started.html",
    "title": "1  Getting started",
    "section": "",
    "text": "Artwork by @allison_horst\nBefore we start thinking about working with health care data spread across a database using the OMOP common data model, let’s first do a quick data analysis from R using a simpler dataset held in a database. For this we’ll use data from palmerpenguins package, which contains data on penguins collected from the Palmer Station in Antarctica."
  },
  {
    "objectID": "ch_1_getting_started.html#getting-set-up",
    "href": "ch_1_getting_started.html#getting-set-up",
    "title": "1  Getting started",
    "section": "1.2 Getting set up",
    "text": "1.2 Getting set up\nAssuming that you have R and RStudio already set up, first we need to install a few packages not included in base R if we don´t already have them.\n\ninstall.packages(\"dplyr\")\ninstall.packages(\"ggplot2\")\ninstall.packages(\"DBI\")\ninstall.packages(\"duckdb\")\ninstall.packages(\"palmerpenguins\")\n\nOnce installed, we can load them like so.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(DBI)\nlibrary(duckdb)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "ch_1_getting_started.html#taking-a-peek-at-the-data",
    "href": "ch_1_getting_started.html#taking-a-peek-at-the-data",
    "title": "1  Getting started",
    "section": "1.3 Taking a peek at the data",
    "text": "1.3 Taking a peek at the data\nWe can get an overview of the data using the glimpse() command.\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nOr we could take a look at the first rows of the data using head()\n\nhead(penguins, 5)\n\n# A tibble: 5 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 2 more variables: sex <fct>, year <int>"
  },
  {
    "objectID": "ch_1_getting_started.html#inserting-data-into-a-database",
    "href": "ch_1_getting_started.html#inserting-data-into-a-database",
    "title": "1  Getting started",
    "section": "1.4 Inserting data into a database",
    "text": "1.4 Inserting data into a database\nLet’s put our penguins data into a duckdb database. We create the duckdb database, add the penguins data, and then create a reference to the table containing the data.\n\ndb <- dbConnect(duckdb::duckdb(), dbdir = \":memory:\")\ndbWriteTable(db, \"penguins\", penguins)\npenguins_db <- tbl(db, \"penguins\")\n\nWe can see that our database now has one table\n\nDBI::dbListTables(db)\n\n[1] \"penguins\"\n\n\nAnd now that the data is in a database we could use SQL to get the first rows that we saw before\n\ndbGetQuery(db, \"SELECT * FROM penguins LIMIT 5\")\n\n  species    island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n1  Adelie Torgersen           39.1          18.7               181        3750\n2  Adelie Torgersen           39.5          17.4               186        3800\n3  Adelie Torgersen           40.3          18.0               195        3250\n4  Adelie Torgersen             NA            NA                NA          NA\n5  Adelie Torgersen           36.7          19.3               193        3450\n     sex year\n1   male 2007\n2 female 2007\n3 female 2007\n4   <NA> 2007\n5 female 2007\n\n\nBut we could also use the same R code as before\n\nhead(penguins_db, 5)\n\n# Source:   SQL [5 x 8]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/:memory:]\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 2 more variables: sex <fct>, year <int>"
  },
  {
    "objectID": "ch_1_getting_started.html#translation-from-r-to-sql",
    "href": "ch_1_getting_started.html#translation-from-r-to-sql",
    "title": "1  Getting started",
    "section": "1.5 Translation from R to SQL",
    "text": "1.5 Translation from R to SQL\nThe magic here is provided by the dbplyr which takes the R code and converts it into SQL, which in this case looks like\n\nhead(penguins_db, 1) %>% \n  show_query()\n\n<SQL>\nSELECT *\nFROM penguins\nLIMIT 1\n\n\nMore complicated SQL can also be generated by using familiar dplyr code, for example\n\npenguins_db %>%\n  group_by(species) %>%\n  summarise(\n    min_bill_length_mm = min(bill_length_mm),\n    median_bill_length_mm = median(bill_length_mm),\n    max_bill_length_mm = max(bill_length_mm)\n  ) %>%\n  mutate(min_max_bill_length_mm = paste0(\n    min_bill_length_mm,\n    \" to \",\n    max_bill_length_mm\n  )) %>%\n  select(\n    \"species\",\n    \"median_bill_length_mm\",\n    \"min_max_bill_length_mm\"\n  )\n\n# Source:   SQL [3 x 3]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/:memory:]\n  species   median_bill_length_mm min_max_bill_length_mm\n  <fct>                     <dbl> <chr>                 \n1 Adelie                     38.8 32.1 to 46.0          \n2 Gentoo                     47.3 40.9 to 59.6          \n3 Chinstrap                  49.6 40.9 to 58.0          \n\n\nIn this case the corresponding SQL looks like\n\npenguins_db %>%\n  group_by(species) %>%\n  summarise(\n    min_bill_length_mm = min(bill_length_mm),\n    median_bill_length_mm = median(bill_length_mm),\n    max_bill_length_mm = max(bill_length_mm)\n  ) %>%\n  mutate(min_max_bill_length_mm = paste0(min, \" to \", max)) %>%\n  select(\n    \"species\",\n    \"median_bill_length_mm\",\n    \"min_max_bill_length_mm\"\n  ) %>%\n  show_query()\n\n<SQL>\nSELECT\n  species,\n  median_bill_length_mm,\n  CONCAT_WS('', .Primitive(\"min\"), ' to ', .Primitive(\"max\")) AS min_max_bill_length_mm\nFROM (\n  SELECT\n    species,\n    MIN(bill_length_mm) AS min_bill_length_mm,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY bill_length_mm) AS median_bill_length_mm,\n    MAX(bill_length_mm) AS max_bill_length_mm\n  FROM penguins\n  GROUP BY species\n) q01"
  },
  {
    "objectID": "ch_1_getting_started.html#different-sql-for-different-database-management-systems",
    "href": "ch_1_getting_started.html#different-sql-for-different-database-management-systems",
    "title": "1  Getting started",
    "section": "1.6 Different SQL for different database management systems",
    "text": "1.6 Different SQL for different database management systems\nOne important benefit of using this approach is that the SQL generated will be specific to that of the database management system in use.\nAs we can see below the SQL can vary depending on the database management system being used.\n\npenguins %>%\n  dbplyr::lazy_frame(con = duckdb::simulate_duckdb()) %>%\n  mutate(\n    category = if_else(bill_length_mm > 40 & bill_depth_mm > 18,\n      \"big\", \"small\"\n    ),\n    date = as.Date(paste0(\"01-01-\", year))\n  ) %>%\n  show_query()\n\n<SQL>\nSELECT\n  *,\n  CASE WHEN (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'big' WHEN NOT (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'small' END AS `category`,\n  CAST(CONCAT_WS('', '01-01-', `year`) AS DATE) AS `date`\nFROM `df`\n\npenguins %>%\n  dbplyr::lazy_frame(con = dbplyr::simulate_postgres()) %>%\n  mutate(\n    category = if_else(bill_length_mm > 40 & bill_depth_mm > 18,\n      \"big\", \"small\"\n    ),\n    date = as.Date(paste0(\"01-01-\", year))\n  ) %>%\n  show_query()\n\n<SQL>\nSELECT\n  *,\n  CASE WHEN (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'big' WHEN NOT (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'small' END AS `category`,\n  CAST(CONCAT_WS('', '01-01-', `year`) AS DATE) AS `date`\nFROM `df`\n\npenguins %>%\n  dbplyr::lazy_frame(con = dbplyr::simulate_redshift()) %>%\n  mutate(\n    category = if_else(bill_length_mm > 40 & bill_depth_mm > 18,\n      \"big\", \"small\"\n    ),\n    date = as.Date(paste0(\"01-01-\", year))\n  ) %>%\n  show_query()\n\n<SQL>\nSELECT\n  *,\n  CASE WHEN (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'big' WHEN NOT (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'small' END AS `category`,\n  CAST('01-01-' || `year` AS DATE) AS `date`\nFROM `df`\n\npenguins %>%\n  dbplyr::lazy_frame(con = dbplyr::simulate_oracle()) %>%\n  mutate(\n    category = if_else(bill_length_mm > 40 & bill_depth_mm > 18,\n      \"big\", \"small\"\n    ),\n    date = as.Date(paste0(\"01-01-\", year))\n  ) %>%\n  show_query()\n\n<SQL>\nSELECT\n  `species`,\n  `island`,\n  `bill_length_mm`,\n  `bill_depth_mm`,\n  `flipper_length_mm`,\n  `body_mass_g`,\n  `sex`,\n  `year`,\n  CASE WHEN (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'big' WHEN NOT (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'small' END AS `category`,\n  DATE '01-01-' || `year` AS `date`\nFROM (`df`) \n\npenguins %>%\n  dbplyr::lazy_frame(con = dbplyr::simulate_snowflake()) %>%\n  mutate(\n    category = if_else(bill_length_mm > 40 & bill_depth_mm > 18,\n      \"big\", \"small\"\n    ),\n    date = as.Date(paste0(\"01-01-\", year))\n  ) %>%\n  show_query()\n\n<SQL>\nSELECT\n  *,\n  CASE WHEN (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'big' WHEN NOT (`bill_length_mm` > 40.0 AND `bill_depth_mm` > 18.0) THEN 'small' END AS `category`,\n  CAST(ARRAY_TO_STRING(ARRAY_CONSTRUCT_COMPACT('01-01-', `year`), '') AS DATE) AS `date`\nFROM `df`"
  },
  {
    "objectID": "ch_1_getting_started.html#example-analysis",
    "href": "ch_1_getting_started.html#example-analysis",
    "title": "1  Getting started",
    "section": "1.7 Example analysis",
    "text": "1.7 Example analysis\nLet´s start by getting a count by species\n\npenguins_db %>% \n  group_by(species) %>% \n  count()\n\n# Source:   SQL [3 x 2]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/:memory:]\n# Groups:   species\n  species       n\n  <fct>     <dbl>\n1 Adelie      152\n2 Gentoo      124\n3 Chinstrap    68\n\n\nNow suppose we are particularly interested in the body mass variable. We can first notice that there are a couple of missing records for this.\n\npenguins_db %>%\n  mutate(missing_body_mass_g = if_else(\n    is.na(body_mass_g), 1, 0\n  )) %>%\n  group_by(species, missing_body_mass_g) %>%\n  tally()\n\n# Source:   SQL [5 x 3]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/:memory:]\n  species   missing_body_mass_g     n\n  <fct>                   <dbl> <dbl>\n1 Adelie                      0   151\n2 Adelie                      1     1\n3 Gentoo                      0   123\n4 Gentoo                      1     1\n5 Chinstrap                   0    68\n\n\nWe can get the mean for each of the species (dropping those two missing records).\n\npenguins_db %>%\n  group_by(species) %>%\n  summarise(mean_body_mass_g = round(mean(body_mass_g, na.rm = TRUE), 0))\n\n# Source:   SQL [3 x 2]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/:memory:]\n  species   mean_body_mass_g\n  <fct>                <dbl>\n1 Adelie                3701\n2 Gentoo                5076\n3 Chinstrap             3733\n\n\nWe can then also do a histogram for each of the species.\n\npenguins_db %>%\n  collect() %>%\n  ggplot(aes(group = species, fill = species)) +\n  facet_grid(species ~ .) +\n  geom_histogram(aes(body_mass_g), colour = \"black\", binwidth = 100) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\nChoosing the right time to collect\n\n\n\n\n\ncollect() brings data out of the database and into R. Above we use it to bring the entire penguins data back into R so that we can then use ggplot() to make our histogram.\nGenerally speaking we want to keep as much computation as possible on the database side, up until the point we need to bring the data out for further analysis steps that are not possible using SQL. This could be like the case above for plotting, but could also be for other analytic steps like fitting statistical models. In such cases it is important that we only bring out the required data.\n\n\n\nHow about the relationship between body mass and bill depth?\n\npenguins %>%\n  collect() %>%\n  ggplot(aes(x = bill_depth_mm, y = body_mass_g)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\nSo a negative correlation between body mass and bill depth - that seems rather unexpected. But what about if we stratify by species?\n\npenguins %>%\n  collect() %>%\n  ggplot(aes(x = bill_depth_mm, y = body_mass_g)) +\n  facet_grid(species ~ .) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\nAs well as having an example of working with data in database from R, you also have an example of Simpson´s paradox! And now we’ve reached the end of this example, we can close our connection to the database.\n\ndbDisconnect(db)"
  },
  {
    "objectID": "ch_1_getting_started.html#further-reading",
    "href": "ch_1_getting_started.html#further-reading",
    "title": "1  Getting started",
    "section": "1.8 Further reading",
    "text": "1.8 Further reading\n\nR for Data Science (Chapter 13: Relational data)\nWriting SQL with dbplyr\nData Carpentry: SQL databases and R"
  },
  {
    "objectID": "ch_2_cdm_reference.html",
    "href": "ch_2_cdm_reference.html",
    "title": "2  Creating a reference to the OMOP common data model",
    "section": "",
    "text": "Database connections from R can be made using the DBI package. The back-end for DBI is facilitated by database specific driver packages. As an example, lets say we want to work with a local duckdb from R. In this case the we can use the duckdb R package as the driver, connecting to a database with the OMOP CDM for a synthetic population of 200,000 people.\n\nlibrary(DBI)\nlibrary(here)\n\n\ndb<-dbConnect(duckdb::duckdb(), \n              dbdir= Sys.getenv(\"DUCKDB\"))\n\nIf we instead wanted to connect to other database management systems, these connections would be supported by the associated back-end packages. For example a connection to a Postgres database would look something like:\n\n# Postgres\ndb <- DBI::dbConnect(RPostgres::Postgres(),\n                      dbname = Sys.getenv(\"CDM5_POSTGRESQL_DBNAME\"),\n                      host = Sys.getenv(\"CDM5_POSTGRESQL_HOST\"),\n                      user = Sys.getenv(\"CDM5_POSTGRESQL_USER\"),\n                      password = Sys.getenv(\"CDM5_POSTGRESQL_PASSWORD\"))"
  },
  {
    "objectID": "ch_2_cdm_reference.html#creating-a-reference-to-the-omop-common-data-model",
    "href": "ch_2_cdm_reference.html#creating-a-reference-to-the-omop-common-data-model",
    "title": "2  Creating a reference to the OMOP common data model",
    "section": "2.2 Creating a reference to the OMOP common data model",
    "text": "2.2 Creating a reference to the OMOP common data model\nAs seen in the previous chapter, once a connection to the database has been created we could then create references to the various tables in the database and build queries using in a familiar dplyr style. However, as we the structure of the OMOP CDM is already known, we can avoid the overhead of creating individual references to the OMOP CDM tables by using the CDMConnector package. CDMConnector will do the work for us and quickly create a joint reference for all the tables in the OMOP CDM.\nIf you don’t already have it installed, the first step would be to install CDMConnector from CRAN.\n\ninstall.packages(\"CDMConnector\")\n\nFor this example, we’ll use an example dataset (synthea-covid19-10k) provided by CDMConnector. First let’s load packages and then download the example data.\n\nlibrary(DBI)\nlibrary(CDMConnector)\nlibrary(here)\n\n\ndownloadEunomiaData(\n  datasetName = \"synthea-covid19-10k\",\n  cdmVersion = \"5.3\",\n  pathToData = here(),\n  overwrite = FALSE\n)\n\nAfter connecting to the database containing the OMOP CDM, we use CDMConnector to create our cdm reference.\n\ndb<-dbConnect(duckdb::duckdb(), \n              dbdir = eunomiaDir(datasetName = \"synthea-covid19-10k\"))\ncdm <- cdm_from_con(con = db, \n                    cdm_schema = \"main\")\ncdm\n\n# OMOP CDM reference (tbl_duckdb_connection)\n\nTables: person, observation_period, visit_occurrence, visit_detail, condition_occurrence, drug_exposure, procedure_occurrence, device_exposure, measurement, observation, death, note, note_nlp, specimen, fact_relationship, location, care_site, provider, payer_plan_period, cost, drug_era, dose_era, condition_era, metadata, cdm_source, concept, vocabulary, domain, concept_class, concept_relationship, relationship, concept_synonym, concept_ancestor, source_to_concept_map, drug_strength, cohort_definition, attribute_definition\n\n\nOnce we have created the our reference to the overall OMOP CDM, we can reference specific tables using the “$” operator.\n\ncdm$observation_period\n\n# Source:   table<main.observation_period> [?? x 5]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp4qxVqZ\\file741c562069a2.duckdb]\n   observation_period_id person_id observation_period_s…¹ observation_period_e…²\n                   <int>     <int> <date>                 <date>                \n 1                     1         1 2014-05-09             2023-05-12            \n 2                     2         2 1977-04-11             1986-09-15            \n 3                     3         3 2014-04-19             2023-04-22            \n 4                     4         4 2014-03-22             2023-04-08            \n 5                     5         5 2013-11-13             2023-01-04            \n 6                     6         6 2013-07-17             2021-08-04            \n 7                     7         7 2013-06-26             2022-08-17            \n 8                     8         8 2018-08-20             2022-07-25            \n 9                     9         9 2013-08-03             2022-09-24            \n10                    10        10 2013-08-11             2023-04-02            \n# ℹ more rows\n# ℹ abbreviated names: ¹​observation_period_start_date,\n#   ²​observation_period_end_date\n# ℹ 1 more variable: period_type_concept_id <int>\n\n\nAlternatively, you could also access a specific table reference like so\n\ncdm[[\"observation_period\"]]\n\n# Source:   table<main.observation_period> [?? x 5]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp4qxVqZ\\file741c562069a2.duckdb]\n   observation_period_id person_id observation_period_s…¹ observation_period_e…²\n                   <int>     <int> <date>                 <date>                \n 1                     1         1 2014-05-09             2023-05-12            \n 2                     2         2 1977-04-11             1986-09-15            \n 3                     3         3 2014-04-19             2023-04-22            \n 4                     4         4 2014-03-22             2023-04-08            \n 5                     5         5 2013-11-13             2023-01-04            \n 6                     6         6 2013-07-17             2021-08-04            \n 7                     7         7 2013-06-26             2022-08-17            \n 8                     8         8 2018-08-20             2022-07-25            \n 9                     9         9 2013-08-03             2022-09-24            \n10                    10        10 2013-08-11             2023-04-02            \n# ℹ more rows\n# ℹ abbreviated names: ¹​observation_period_start_date,\n#   ²​observation_period_end_date\n# ℹ 1 more variable: period_type_concept_id <int>\n\n\nWhen creating our cdm reference we can also specify a write schema. This would be a schema in which we have permission to create tables (as we’re unlikely to have that permission for the schema containing the tables with the patient-level data).\n\ncdm <- cdm_from_con(db,\n  cdm_schema = \"main\",\n  write_schema = \"results\")\n\n\n\n\n\n\n\nSetting a write prefix\n\n\n\n\n\nWe can set a prefix that to use when permanent tables are created the write schema. This can be useful when we’re sharing our write schema with others and want to avoid table name conflicts.\n\ncdm <- cdm_from_con(db,\n  cdm_schema = \"main\",\n  write_schema = c(schema=\"main\", prefix = \"example_\"))"
  },
  {
    "objectID": "ch_2_cdm_reference.html#cdm-name",
    "href": "ch_2_cdm_reference.html#cdm-name",
    "title": "2  Creating a reference to the OMOP common data model",
    "section": "2.3 CDM name",
    "text": "2.3 CDM name\nOur cdm reference will be associated with a name. By default this name will be taken from the cdm source name field from the cdm source table. We can though set this to a different name when creating our cdm reference. This cdm name attribute of our reference is particularly useful in the context of network studies to keep track of which results are associated with which database.\n\ncdm <- cdm_from_con(db,\n  cdm_schema = \"main\")\ncdm$cdm_source\n\n# Source:   table<main.cdm_source> [1 x 10]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp4qxVqZ\\file741c562069a2.duckdb]\n  cdm_source_name cdm_source_abbreviation cdm_holder source_description    \n  <chr>           <chr>                   <chr>      <chr>                 \n1 Synthea         Synthea                 \"\"         Synthea Synthetic Data\n# ℹ 6 more variables: source_documentation_reference <chr>,\n#   cdm_etl_reference <chr>, source_release_date <date>,\n#   cdm_release_date <date>, cdm_version <chr>, vocabulary_version <chr>\n\nattr(cdm, \"cdm_name\")\n\n[1] \"Synthea\"\n\ncdm <- cdm_from_con(db,\n  cdm_schema = \"main\", \n  cdm_name = \"my_cdm\")\nattr(cdm, \"cdm_name\")\n\n[1] \"my_cdm\""
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html",
    "href": "ch_3_exploring_the_cdm.html",
    "title": "3  Exploring the CDM",
    "section": "",
    "text": "For this chapter, lets continue using our example COVID-19 dataset."
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#counting-people",
    "href": "ch_3_exploring_the_cdm.html#counting-people",
    "title": "3  Exploring the CDM",
    "section": "3.1 Counting people",
    "text": "3.1 Counting people\nThe OMOP CDM is person-centric, with the person table containing records to uniquely identify each person in the database. As each row refers to a unique person, we can quickly get a count of the number of individuals in the database like so\n\ncdm$person %>% \n  count() %>% \n  pull()\n\n[1] 10754\n\n\nThe person table also contains some demographic information, including a gender concept for each person. We can get a count grouped by this variable, but as this uses a concept we’ll also need to join to the concept table to get the corresponding concept name for each concept id.\n\ncdm$person %>% \n  group_by(gender_concept_id) %>% \n  count() %>% \n  left_join(cdm$concept, \n            by=c(\"gender_concept_id\" = \"concept_id\")) %>% \n              select(\"gender_concept_id\", \"concept_name\", \"n\") %>% \n  collect()\n\n# A tibble: 2 × 3\n# Groups:   gender_concept_id [2]\n  gender_concept_id concept_name     n\n              <int> <chr>        <dbl>\n1              8532 FEMALE        5165\n2              8507 MALE          5589\n\n\nThe observation period table contains records indicating spans of time over which clinical events can be reliably observed for the people in the person table. Someone can potentially have multiple observation periods. So say we wanted a count of people grouped by the year during which their first observation period started. We could do this like so:\n\nfirst_observation_period <- cdm$observation_period %>%\n    group_by(person_id) %>% \n    filter(row_number() == 1) %>% \n    computeQuery()\n\ncdm$person %>% \n  left_join(first_observation_period,\n            by = \"person_id\") %>% \n  mutate(observation_period_start_year=year(observation_period_start_date)) %>% \n  group_by(observation_period_start_year) %>% \n  count() %>% \n  collect() %>% \n  ggplot() +\n  geom_col(aes(observation_period_start_year, n)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nComputing intermediate queries\n\n\n\n\n\nThe computeQuery() function will force the computation of a query. In the example above we use it to split up two queries; the first to keep the first observation period record for each individual.\n\ncdm$observation_period %>%\n    group_by(person_id) %>% \n    filter(row_number() == 1) %>% \n    show_query()\n\n<SQL>\nSELECT\n  observation_period_id,\n  person_id,\n  observation_period_start_date,\n  observation_period_end_date,\n  period_type_concept_id\nFROM (\n  SELECT *, ROW_NUMBER() OVER (PARTITION BY person_id) AS q03\n  FROM main.observation_period\n) q01\nWHERE (q03 = 1.0)\n\n\nFollowed by a second query that left joins the person table with the result from the first (which is now in a temporary table), followed by extracted the year in which peoples first observation period starts and then, finally, a count by year.\n\ncdm$person %>% \n  left_join(first_observation_period,\n            by = \"person_id\") %>% \n  mutate(observation_period_start_year=year(observation_period_start_date)) %>% \n  group_by(observation_period_start_year) %>% \n  count() %>% \n  show_query()\n\n<SQL>\nSELECT observation_period_start_year, COUNT(*) AS n\nFROM (\n  SELECT\n    *,\n    EXTRACT(year FROM observation_period_start_date) AS observation_period_start_year\n  FROM (\n    SELECT\n      \"main.person\".*,\n      observation_period_id,\n      observation_period_start_date,\n      observation_period_end_date,\n      period_type_concept_id\n    FROM main.person AS \"main.person\"\n    LEFT JOIN dbplyr_001\n      ON (\"main.person\".person_id = dbplyr_001.person_id)\n  ) q01\n) q02\nGROUP BY observation_period_start_year\n\n\nWe could, however, have done this without compute, with instead the SQL being done all at once.\n\ncdm$person %>% \n  left_join(cdm$observation_period %>%\n    group_by(person_id) %>% \n    filter(row_number() == 1),\n            by = \"person_id\") %>% \n  mutate(observation_period_start_year=year(observation_period_start_date)) %>% \n  group_by(observation_period_start_year) %>% \n  count() %>% \n  show_query()\n\n<SQL>\nSELECT observation_period_start_year, COUNT(*) AS n\nFROM (\n  SELECT\n    *,\n    EXTRACT(year FROM observation_period_start_date) AS observation_period_start_year\n  FROM (\n    SELECT\n      \"main.person\".*,\n      observation_period_id,\n      observation_period_start_date,\n      observation_period_end_date,\n      period_type_concept_id\n    FROM main.person AS \"main.person\"\n    LEFT JOIN (\n      SELECT\n        observation_period_id,\n        person_id,\n        observation_period_start_date,\n        observation_period_end_date,\n        period_type_concept_id\n      FROM (\n        SELECT *, ROW_NUMBER() OVER (PARTITION BY person_id) AS q03\n        FROM main.observation_period\n      ) q01\n      WHERE (q03 = 1.0)\n    ) RHS\n      ON (\"main.person\".person_id = RHS.person_id)\n  ) q02\n) q03\nGROUP BY observation_period_start_year\n\n\nIn this case the SQL is not much more complicated than before. However, you can imagine that without forcing computation, the SQL associated with a series of data manipulations could quickly become unmanageable. So although we don’t want to overuse computation of intermediate queries, it is often a necessity when writing analysis scripts.\nAn advantage of computing a query, is that we can then use the result for multiple subsequent queries. For example, say we want a count of condition occurrence and drug exposure records for those born before 1970. We could get these counts independently:\n\ncdm$person %>% \n  filter(year_of_birth < \"1970\") %>% \n  select(\"person_id\") %>% \n  left_join(cdm$condition_occurrence,\n            by=\"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMC78k\\file7682aec4f5a.duckdb]\n      n\n  <dbl>\n1  9305\n\ncdm$person %>% \n  filter(year_of_birth < \"1970\") %>% \n  select(\"person_id\") %>% \n  left_join(cdm$drug_exposure,\n            by=\"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMC78k\\file7682aec4f5a.duckdb]\n       n\n   <dbl>\n1 165681\n\n\nBut we could have instead first subsetted the person table and then used the result for both queries.\n\ncdm$person_pre_1970 <- cdm$person %>% \n  filter(year_of_birth < \"1970\") %>% \n  computeQuery()\n\ncdm$person_pre_1970 %>% \n  select(\"person_id\") %>% \n  left_join(cdm$condition_occurrence,\n            by=\"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMC78k\\file7682aec4f5a.duckdb]\n      n\n  <dbl>\n1  9305\n\ncdm$person_pre_1970 %>% \n  select(\"person_id\") %>% \n  left_join(cdm$drug_exposure,\n            by=\"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMC78k\\file7682aec4f5a.duckdb]\n       n\n   <dbl>\n1 165681\n\n\nHere we’ve been using computeQuery() from the CDMConnector package. This function is an extension of the compute() function from dplyr, with computeQuery() providing greater consistency across its supported database management systems.\n\ncdm$person %>% \n  tally() %>% \n  computeQuery()\n\n# Source:   table<dbplyr_003> [1 x 1]\n# Database: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMC78k\\file7682aec4f5a.duckdb]\n      n\n  <dbl>\n1 10754"
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#counting-records",
    "href": "ch_3_exploring_the_cdm.html#counting-records",
    "title": "3  Exploring the CDM",
    "section": "3.2 Counting records",
    "text": "3.2 Counting records\nWhat’s the number of condition occurrence records per person in the database? We can find out like so\n\ncdm$person %>% \n  left_join(cdm$condition_occurrence %>% \n  group_by(person_id) %>% \n  count(name = \"condition_occurrence_records\"),\n  by=\"person_id\") %>% \n  mutate(condition_occurrence_records = if_else(\n    is.na(condition_occurrence_records), 0,\n    condition_occurrence_records)) %>% \n  group_by(condition_occurrence_records) %>%\n  count() %>% \n  collect() %>% \n  ggplot() +\n  geom_col(aes(condition_occurrence_records, n)) +\n  theme_bw()\n\n\n\n\nHow about we were interested in getting record counts for some specific concepts related to COVID-19 symptoms?\n\ncdm$condition_occurrence %>% \n  filter(condition_concept_id %in% c(437663,437390,31967,\n                                     4289517,4223659, 312437,\n                                     434490,254761,77074)) %>% \n  group_by(condition_concept_id) %>% \n  count() %>% \n  left_join(cdm$concept,\n            by=c(\"condition_concept_id\" = \"concept_id\")) %>% \n  collect() %>% \n  ggplot() +\n  geom_col(aes(concept_name, n)) +\n  theme_bw()+\n  xlab(\"\")\n\n\n\n\n\n\n\n\n\n\nVocabulary tables\n\n\n\n\n\nAbove we’ve got counts by specific concept IDs recorded in the condition occurrence table. What these IDs represent is described in the concept table. Here we have the name associate with the concept, along with other information such as it’s domain and vocabulary id.\n\ncdm$concept %>% \n  glimpse()\n\nRows: ??\nColumns: 10\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMC78k\\file7682aec4f5a.duckdb]\n$ concept_id       <int> 45756805, 45756804, 45756803, 45756802, 45756801, 457…\n$ concept_name     <chr> \"Pediatric Cardiology\", \"Pediatric Anesthesiology\", \"…\n$ domain_id        <chr> \"Provider\", \"Provider\", \"Provider\", \"Provider\", \"Prov…\n$ vocabulary_id    <chr> \"ABMS\", \"ABMS\", \"ABMS\", \"ABMS\", \"ABMS\", \"ABMS\", \"ABMS…\n$ concept_class_id <chr> \"Physician Specialty\", \"Physician Specialty\", \"Physic…\n$ standard_concept <chr> \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\"…\n$ concept_code     <chr> \"OMOP4821938\", \"OMOP4821939\", \"OMOP4821940\", \"OMOP482…\n$ valid_start_date <date> 1970-01-01, 1970-01-01, 1970-01-01, 1970-01-01, 1970…\n$ valid_end_date   <date> 2099-12-31, 2099-12-31, 2099-12-31, 2099-12-31, 2099…\n$ invalid_reason   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\nOther vocabulary tables capture other information about concepts, such as the direct relationships between concepts (the concept relationship table) and hierarchical relationships between (the concept ancestor table).\n\ncdm$concept_relationship %>% \n  glimpse()\n\nRows: ??\nColumns: 6\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMC78k\\file7682aec4f5a.duckdb]\n$ concept_id_1     <int> 35804314, 35804314, 35804314, 35804327, 35804327, 358…\n$ concept_id_2     <int> 912065, 42542145, 42542145, 35803584, 42542145, 42542…\n$ relationship_id  <chr> \"Has modality\", \"Has accepted use\", \"Is current in\", …\n$ valid_start_date <date> 2021-01-26, 2019-08-29, 2019-08-29, 2019-05-27, 2019…\n$ valid_end_date   <date> 2099-12-31, 2099-12-31, 2099-12-31, 2099-12-31, 2099…\n$ invalid_reason   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\ncdm$concept_ancestor %>% \n  glimpse()\n\nRows: ??\nColumns: 4\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMC78k\\file7682aec4f5a.duckdb]\n$ ancestor_concept_id      <int> 375415, 727760, 735979, 438112, 529411, 14196…\n$ descendant_concept_id    <int> 4335743, 2056453, 41070383, 36566114, 4326940…\n$ min_levels_of_separation <int> 4, 1, 3, 2, 3, 3, 4, 3, 2, 5, 1, 3, 4, 2, 2, …\n$ max_levels_of_separation <int> 4, 1, 5, 3, 3, 6, 12, 3, 2, 10, 1, 3, 4, 2, 2…\n\n\nMore information on the vocabulary tables (as well as other tables in the OMOP CDM version 5.3) can be found at https://ohdsi.github.io/CommonDataModel/cdm53.html#Vocabulary_Tables."
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#working-with-dates",
    "href": "ch_3_exploring_the_cdm.html#working-with-dates",
    "title": "3  Exploring the CDM",
    "section": "3.3 Working with dates",
    "text": "3.3 Working with dates\nDates are supported somewhat inconsistently by dbplyr but, as with computeQuery(), CDMConnector also provides some date functions that are tested to work across supported databases. We can use the datediff() function for example to calculate the difference between two dates. We can use this below to get the number of years observation periods last for.\n\ncdm$observation_period %>%\n  dplyr::mutate(observation_years = \n                  !!CDMConnector::datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"year\"))  %>% \n  collect() %>% \n  ggplot() +\n  geom_histogram(aes(observation_years), \n                 binwidth=2, colour=\"grey\") +\n  theme_bw()"
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#statistical-summaries",
    "href": "ch_3_exploring_the_cdm.html#statistical-summaries",
    "title": "3  Exploring the CDM",
    "section": "3.4 Statistical summaries",
    "text": "3.4 Statistical summaries\nWe can also use summarise for various other calculations\n\ncdm$person %>% \n  summarise(min_year_of_birth = min(year_of_birth, na.rm=TRUE),\n            q05_year_of_birth = quantile(year_of_birth, 0.05, na.rm=TRUE),\n            mean_year_of_birth = round(mean(year_of_birth, na.rm=TRUE),0),\n            median_year_of_birth = median(year_of_birth, na.rm=TRUE),\n            q95_year_of_birth = quantile(year_of_birth, 0.95, na.rm=TRUE),\n            max_year_of_birth = max(year_of_birth, na.rm=TRUE)) %>%  \n  glimpse()\n\nRows: ??\nColumns: 6\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMC78k\\file7682aec4f5a.duckdb]\n$ min_year_of_birth    <int> 1923\n$ q05_year_of_birth    <dbl> 1927\n$ mean_year_of_birth   <dbl> 1971\n$ median_year_of_birth <dbl> 1970\n$ q95_year_of_birth    <dbl> 2018\n$ max_year_of_birth    <int> 2023\n\n\n\n\n\n\n\n\nPiping and SQL\n\n\n\n\n\nAlthough piping queries has little impact on performance when using R with data in memory, when working with a database the SQL generated will differ when using multiple function calls (with a separate operation specified in each) instead of multiple operations within a single function call.\nFor example, a single mutate function above would generate the below SQL.\n\ncdm$observation_period %>%\n  mutate(observation_days = !!datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"day\"),\n        observation_years = !!datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"year\")) %>% \n  select(\"observation_period_id\", \"person_id\", \n         \"observation_days\",\"observation_years\") %>% \n  show_query()\n\n<SQL>\nSELECT\n  observation_period_id,\n  person_id,\n  datediff('day', observation_period_start_date, observation_period_end_date) AS observation_days,\n  FLOOR((date_part('year', observation_period_end_date) * 10000 + date_part('month', observation_period_end_date) * 100 + date_part('day', observation_period_end_date) -\n(date_part('year', observation_period_start_date) * 10000 + date_part('month', observation_period_start_date) * 100 + date_part('day', observation_period_start_date))) / 10000) AS observation_years\nFROM main.observation_period\n\n\nWhereas the SQL will be different if using multiple mutate calls (now using a sub-query).\n\ncdm$observation_period %>%\n  mutate(observation_days = !!datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"day\")) %>% \n  mutate(observation_years = !!datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"year\")) %>% \n  select(\"observation_period_id\", \"person_id\", \n         \"observation_days\",\"observation_years\") %>% \n  show_query()\n\n<SQL>\nSELECT\n  observation_period_id,\n  person_id,\n  observation_days,\n  FLOOR((date_part('year', observation_period_end_date) * 10000 + date_part('month', observation_period_end_date) * 100 + date_part('day', observation_period_end_date) -\n(date_part('year', observation_period_start_date) * 10000 + date_part('month', observation_period_start_date) * 100 + date_part('day', observation_period_start_date))) / 10000) AS observation_years\nFROM (\n  SELECT\n    *,\n    datediff('day', observation_period_start_date, observation_period_end_date) AS observation_days\n  FROM main.observation_period\n) q01\n\n\n\n\n\nAs we’ve seen before, we can also quickly get results for various groupings or restrictions\n\ncdm$person %>% \n   group_by(gender_concept_id) %>% \n   summarise(min_year_of_birth = min(year_of_birth, na.rm=TRUE),\n            q25_year_of_birth = quantile(year_of_birth, 0.25, na.rm=TRUE),\n            median_year_of_birth = median(year_of_birth, na.rm=TRUE),\n            q75_year_of_birth = quantile(year_of_birth, 0.75, na.rm=TRUE),\n            max_year_of_birth = max(year_of_birth, na.rm=TRUE)) %>% \n  left_join(cdm$concept, \n            by=c(\"gender_concept_id\" = \"concept_id\")) %>% \n   collect() %>% \n  ggplot(aes(x = concept_name, group = concept_name,\n             fill = concept_name)) +\n  geom_boxplot(aes(\n    lower = q25_year_of_birth, \n    upper = q75_year_of_birth, \n    middle = median_year_of_birth, \n    ymin = min_year_of_birth, \n    ymax = max_year_of_birth),\n    stat = \"identity\", width = 0.5) + \n  theme_bw()+ \n  theme(legend.position = \"none\") +\n  xlab(\"\")"
  },
  {
    "objectID": "ch_4_building_a_cohort.html",
    "href": "ch_4_building_a_cohort.html",
    "title": "4  Adding cohorts to the CDM",
    "section": "",
    "text": "When performing research with the OMOP common data model we often want to identify groups of individuals who share some set of characteristics. The criteria for including individuals can range from the seemingly simple (e.g. people diagnosed with asthma) to the much more complicated (e.g. adults diagnosed with asthma who had a year of prior observation time in the database prior to their diagnosis, had no prior history of chronic obstructive pulmonary disease, and no history of use of short-acting beta-agonists). The set of people we identify are cohorts, and the OMOP CDM has a specific structure by which they can be represented, with a cohort table having four required fields: cohort_definition_id (a unique identifier for each cohort), subject_id (a foreign key to the subject in the cohort - typically referring to records in the person table), cohort_start_date, and cohort_end_date.\nCohorts can be defined using entirely bespoke code (so long as the output fits the cohort table specification). However because cohort definitions often follow a similar logic, tools have also be developed to facilitate cohort creation. In particular, ATLAS provides a graphical user interface which can be used to create cohort definitions that are expressed as JSON which can subsequently be rendered to SQL. The Capr R package, used below, provides a means of defining the JSON via R code instead."
  },
  {
    "objectID": "ch_4_building_a_cohort.html#defining-cohorts-programmatically",
    "href": "ch_4_building_a_cohort.html#defining-cohorts-programmatically",
    "title": "4  Adding cohorts to the CDM",
    "section": "4.2 Defining cohorts programmatically",
    "text": "4.2 Defining cohorts programmatically\nWe can define a cohort programmatically using the Capr package. In addition we the CodelistGenerator package can be used to help find the codes to use in our cohort definitions.\nLet´s load the required packages and connect to the Eunomia data again.\n\nlibrary(CDMConnector)\nlibrary(dplyr)\nlibrary(Capr)\nlibrary(CodelistGenerator)\n\ncon <- DBI::dbConnect(duckdb::duckdb(), eunomia_dir())\n\ncdm <- CDMConnector::cdm_from_con(\n  con = con,\n  cdm_schema = \"main\",\n  write_schema = \"main\"\n)\n\nSay we want to create a cohort of people with a gastrointestinal hemorrhage. We´ll start by getting the code that represents “gastrointestinal hemorrhage”\n\ngibleed_codes <- getCandidateCodes(cdm = cdm, \n                  keywords = \"gastrointestinal hemorrhage\",\n                  domains = \"condition\",\n                  exactMatch = TRUE,\n                  includeDescendants = FALSE)\ngibleed_codes %>% \n  glimpse()\n\nRows: 1\nColumns: 6\n$ concept_id       <int> 192671\n$ concept_name     <chr> \"Gastrointestinal hemorrhage\"\n$ domain_id        <chr> \"condition\"\n$ concept_class_id <chr> \"clinical finding\"\n$ vocabulary_id    <chr> \"snomed\"\n$ found_from       <chr> \"From initial search\"\n\ngibleed_concept_set <- cs(descendants(gibleed_codes$concept_id))\n\n\n\n\n\n\n\nFinding appropriate codes\n\n\n\n\n\nThe above gives the impression that identifying concepts that represent a particular clinical idea is straightforward. In practice, however, this is rarely the case. Identifying the codes that could represent a condition and then choosing which does though is typically a time consuming task …..\n\ngetCandidateCodes(cdm = cdm, \n                  keywords = \"fracture\",\n                  domains = \"condition\",\n                  includeDescendants = TRUE)\n\n# A tibble: 9 × 6\n  concept_id concept_name    domain_id concept_class_id vocabulary_id found_from\n       <int> <chr>           <chr>     <chr>            <chr>         <chr>     \n1    4048695 Fracture of ve… condition clinical finding snomed        From init…\n2    4142905 Fracture of rib condition clinical finding snomed        From init…\n3    4278672 Fracture of fo… condition clinical finding snomed        From init…\n4    4237458 Fracture of cl… condition clinical finding snomed        From init…\n5    4230399 Closed fractur… condition clinical finding snomed        From init…\n6   40480160 Pathological f… condition clinical finding snomed        From init…\n7    4066995 Fracture of ve… condition clinical finding snomed        From init…\n8    4059173 Fracture of an… condition clinical finding snomed        From init…\n9    4134304 Fracture sublu… condition clinical finding snomed        From init…\n\n\n\n\n\nOnce we´ve identified our codes we´ll create a concept set that includes this code or any of its descendants.\n\ngibleed_concept_set <- cs(descendants(gibleed_codes$concept_id))\n\nWe can now use this concept set in a cohort definition. We´ll look for anyone with a correspong record in the condition occurrence table. We´ll also require that this is their first such record.\n\nentry_criteria <- entry(\n    condition(gibleed_concept_set),\n    primaryCriteriaLimit = \"First\"\n  )\n\ngibleed_cohort_definition <- cohort(entry = entry_criteria)\n\nWe could though make things a little more complicated. What if we wanted to exclude anyone with rheumatoid arthritis (regardless of when they were diagnosed). To do this we´ll first need to create another concept set, this time for rheumatoid arthritis.\n\nrheumatoid_arthritis_codes <- getCandidateCodes(cdm = cdm, \n                  keywords = \"rheumatoid arthritis\",\n                  domains = \"condition\",\n                  exactMatch = TRUE,\n                  includeDescendants = FALSE)\nrheumatoid_arthritis_codes %>% \n  glimpse()\n\nRows: 1\nColumns: 6\n$ concept_id       <int> 80809\n$ concept_name     <chr> \"Rheumatoid arthritis\"\n$ domain_id        <chr> \"condition\"\n$ concept_class_id <chr> \"clinical finding\"\n$ vocabulary_id    <chr> \"snomed\"\n$ found_from       <chr> \"From initial search\"\n\nrheumatoid_arthritis_concept_set <- cs(descendants(\n  rheumatoid_arthritis_codes$concept_id))\n\n\n\n\n\n\n\nJSON representation of a concept set\n\n\n\n\n\n\ncat(as.json(gibleed_concept_set))\n\n{\n  \"items\": [\n    {\n      \"concept\": {\n        \"CONCEPT_ID\": 192671,\n        \"CONCEPT_NAME\": \"\",\n        \"STANDARD_CONCEPT\": \"\",\n        \"STANDARD_CONCEPT_CAPTION\": \"\",\n        \"INVALID_REASON\": \"\",\n        \"INVALID_REASON_CAPTION\": \"\",\n        \"CONCEPT_CODE\": \"\",\n        \"DOMAIN_ID\": \"\",\n        \"VOCABULARY_ID\": \"\",\n        \"CONCEPT_CLASS_ID\": \"\"\n      },\n      \"isExcluded\": false,\n      \"includeDescendants\": true,\n      \"includeMapped\": false\n    }\n  ]\n}\n\ncat(as.json(rheumatoid_arthritis_concept_set))\n\n{\n  \"items\": [\n    {\n      \"concept\": {\n        \"CONCEPT_ID\": 80809,\n        \"CONCEPT_NAME\": \"\",\n        \"STANDARD_CONCEPT\": \"\",\n        \"STANDARD_CONCEPT_CAPTION\": \"\",\n        \"INVALID_REASON\": \"\",\n        \"INVALID_REASON_CAPTION\": \"\",\n        \"CONCEPT_CODE\": \"\",\n        \"DOMAIN_ID\": \"\",\n        \"VOCABULARY_ID\": \"\",\n        \"CONCEPT_CLASS_ID\": \"\"\n      },\n      \"isExcluded\": false,\n      \"includeDescendants\": true,\n      \"includeMapped\": false\n    }\n  ]\n}\n\n\n\n\n\nAnd now we can add this excluision criteria to our cohort definition.\n\ngibleed_no_RA_cohort_definition <- cohort(\n  entry = entry_criteria,\n  attrition = attrition(\n    exactly(0, \n            condition(rheumatoid_arthritis_concept_set),\n            duringInterval(eventStarts(-Inf, Inf))))\n)\n\n\n\n\n\n\n\nJSON representation of a cohort\n\n\n\n\n\n\ncat(as.json((gibleed_cohort_definition)))\n\n{\n  \"ConceptSets\": [\n    {\n      \"id\": 0,\n      \"name\": \"\",\n      \"expression\": {\n        \"items\": [\n          {\n            \"concept\": {\n              \"CONCEPT_ID\": 192671,\n              \"CONCEPT_NAME\": \"\",\n              \"STANDARD_CONCEPT\": \"\",\n              \"STANDARD_CONCEPT_CAPTION\": \"\",\n              \"INVALID_REASON\": \"\",\n              \"INVALID_REASON_CAPTION\": \"\",\n              \"CONCEPT_CODE\": \"\",\n              \"DOMAIN_ID\": \"\",\n              \"VOCABULARY_ID\": \"\",\n              \"CONCEPT_CLASS_ID\": \"\"\n            },\n            \"isExcluded\": false,\n            \"includeDescendants\": true,\n            \"includeMapped\": false\n          }\n        ]\n      }\n    }\n  ],\n  \"PrimaryCriteria\": {\n    \"CriteriaList\": [\n      {\n        \"ConditionOccurrence\": {\n          \"CodesetId\": 0\n        }\n      }\n    ],\n    \"ObservationWindow\": {\n      \"PriorDays\": 0,\n      \"PostDays\": 0\n    },\n    \"PrimaryCriteriaLimit\": {\n      \"Type\": \"First\"\n    }\n  },\n  \"QualifiedLimit\": {\n    \"Type\": \"First\"\n  },\n  \"ExpressionLimit\": {\n    \"Type\": \"First\"\n  },\n  \"InclusionRules\": [],\n  \"CensoringCriteria\": [],\n  \"CollapseSettings\": {\n    \"CollapseType\": \"ERA\",\n    \"EraPad\": 0\n  },\n  \"CensorWindow\": {},\n  \"cdmVersionRange\": \">=5.0.0\"\n}\n\ncat(as.json((gibleed_no_RA_cohort_definition)))\n\n{\n  \"ConceptSets\": [\n    {\n      \"id\": 0,\n      \"name\": \"\",\n      \"expression\": {\n        \"items\": [\n          {\n            \"concept\": {\n              \"CONCEPT_ID\": 192671,\n              \"CONCEPT_NAME\": \"\",\n              \"STANDARD_CONCEPT\": \"\",\n              \"STANDARD_CONCEPT_CAPTION\": \"\",\n              \"INVALID_REASON\": \"\",\n              \"INVALID_REASON_CAPTION\": \"\",\n              \"CONCEPT_CODE\": \"\",\n              \"DOMAIN_ID\": \"\",\n              \"VOCABULARY_ID\": \"\",\n              \"CONCEPT_CLASS_ID\": \"\"\n            },\n            \"isExcluded\": false,\n            \"includeDescendants\": true,\n            \"includeMapped\": false\n          }\n        ]\n      }\n    },\n    {\n      \"id\": 1,\n      \"name\": \"\",\n      \"expression\": {\n        \"items\": [\n          {\n            \"concept\": {\n              \"CONCEPT_ID\": 80809,\n              \"CONCEPT_NAME\": \"\",\n              \"STANDARD_CONCEPT\": \"\",\n              \"STANDARD_CONCEPT_CAPTION\": \"\",\n              \"INVALID_REASON\": \"\",\n              \"INVALID_REASON_CAPTION\": \"\",\n              \"CONCEPT_CODE\": \"\",\n              \"DOMAIN_ID\": \"\",\n              \"VOCABULARY_ID\": \"\",\n              \"CONCEPT_CLASS_ID\": \"\"\n            },\n            \"isExcluded\": false,\n            \"includeDescendants\": true,\n            \"includeMapped\": false\n          }\n        ]\n      }\n    }\n  ],\n  \"PrimaryCriteria\": {\n    \"CriteriaList\": [\n      {\n        \"ConditionOccurrence\": {\n          \"CodesetId\": 0\n        }\n      }\n    ],\n    \"ObservationWindow\": {\n      \"PriorDays\": 0,\n      \"PostDays\": 0\n    },\n    \"PrimaryCriteriaLimit\": {\n      \"Type\": \"First\"\n    }\n  },\n  \"QualifiedLimit\": {\n    \"Type\": \"First\"\n  },\n  \"ExpressionLimit\": {\n    \"Type\": \"First\"\n  },\n  \"InclusionRules\": [\n    {\n      \"name\": \"rule1\",\n      \"expression\": {\n        \"Criteria\": {\n          \"ConditionOccurrence\": {\n            \"CodesetId\": 1\n          }\n        },\n        \"StartWindow\": {\n          \"Start\": {\n            \"Coeff\": -1\n          },\n          \"End\": {\n            \"Coeff\": 1\n          },\n          \"UseIndexEnd\": false,\n          \"UseEventEnd\": false\n        },\n        \"Occurrence\": {\n          \"Type\": 0,\n          \"Count\": 0\n        }\n      }\n    }\n  ],\n  \"CensoringCriteria\": [],\n  \"CollapseSettings\": {\n    \"CollapseType\": \"ERA\",\n    \"EraPad\": 0\n  },\n  \"CensorWindow\": {},\n  \"cdmVersionRange\": \">=5.0.0\"\n}"
  },
  {
    "objectID": "ch_4_building_a_cohort.html#adding-a-cohort-to-the-cdm",
    "href": "ch_4_building_a_cohort.html#adding-a-cohort-to-the-cdm",
    "title": "4  Adding cohorts to the CDM",
    "section": "4.3 Adding a cohort to the CDM",
    "text": "4.3 Adding a cohort to the CDM\n\ncdm <- generateCohortSet(\n  cdm,\n  list(gibleed = gibleed_cohort_definition,\n       gibleed_no_RA = gibleed_no_RA_cohort_definition\n       ),\n  name = \"gibleed\",\n  computeAttrition = TRUE,\n  overwrite = TRUE\n)\ncdm$gibleed %>% \n  glimpse()\n\nRows: ??\nColumns: 4\nDatabase: DuckDB 0.8.1 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpWEES5B/gaaffdak]\n$ cohort_definition_id <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ subject_id           <int> 264, 613, 757, 893, 1117, 1313, 1491, 1576, 1935,…\n$ cohort_start_date    <date> 1984-06-22, 1977-02-09, 1950-01-22, 1993-11-09, …\n$ cohort_end_date      <date> 2011-11-18, 2019-06-14, 1998-10-25, 2019-05-06, …"
  },
  {
    "objectID": "ch_4_building_a_cohort.html#cohort-attributes",
    "href": "ch_4_building_a_cohort.html#cohort-attributes",
    "title": "4  Adding cohorts to the CDM",
    "section": "4.4 Cohort attributes",
    "text": "4.4 Cohort attributes\n\ncohortSet(cdm$gibleed)\n\n# A tibble: 2 × 2\n  cohort_definition_id cohort_name  \n                 <int> <chr>        \n1                    1 gibleed      \n2                    2 gibleed_no_RA\n\n\n\ncohortCount(cdm$gibleed)\n\n# A tibble: 2 × 3\n  cohort_definition_id number_records number_subjects\n                 <int>          <dbl>           <dbl>\n1                    1            479             479\n2                    2            479             479\n\n\n\ncohortAttrition(cdm$gibleed)\n\n# A tibble: 3 × 7\n  cohort_definition_id number_records number_subjects reason_id reason          \n                 <int>          <dbl>           <dbl>     <dbl> <chr>           \n1                    1            479             479         1 Qualifying init…\n2                    2            479             479         1 Qualifying init…\n3                    2            479             479         2 rule1           \n# ℹ 2 more variables: excluded_records <dbl>, excluded_subjects <dbl>"
  },
  {
    "objectID": "ch_5_describing_a_cohort.html#section",
    "href": "ch_5_describing_a_cohort.html#section",
    "title": "5  Describing a cohort",
    "section": "5.2 ",
    "text": "5.2"
  },
  {
    "objectID": "ch_6_sampling_the_cdm.html",
    "href": "ch_6_sampling_the_cdm.html",
    "title": "6  Sampling the cdm",
    "section": "",
    "text": "Our cdm reference will include all of the OMOP CDM tables that could be found in our database. We may though only want a subset of these tables, in which case we can explicity specify those of interest:\n\n# cdm_1 <- cdm_from_con(db) %>% \n#   cdm_select_tbl(\"person\",\"observation_period\")\n# cdm_1\n\nWe can also select a group of tables, for example selecting only the vocabulary tables like so:\n\n# cdm_2 <- cdm  %>% \n#   cdm_select_tbl(tbl_group(\"vocab\"))\n# cdm"
  },
  {
    "objectID": "ch_6_sampling_the_cdm.html#sample-records-in-a-table",
    "href": "ch_6_sampling_the_cdm.html#sample-records-in-a-table",
    "title": "6  Sampling the cdm",
    "section": "6.2 Sample records in a table",
    "text": "6.2 Sample records in a table"
  },
  {
    "objectID": "ch_6_sampling_the_cdm.html#random-sample-of-the-cdm",
    "href": "ch_6_sampling_the_cdm.html#random-sample-of-the-cdm",
    "title": "6  Sampling the cdm",
    "section": "6.3 Random sample of the cdm",
    "text": "6.3 Random sample of the cdm"
  },
  {
    "objectID": "ch_6_sampling_the_cdm.html#cohort-based-subset-of-the-cdm",
    "href": "ch_6_sampling_the_cdm.html#cohort-based-subset-of-the-cdm",
    "title": "6  Sampling the cdm",
    "section": "6.4 Cohort-based subset of the cdm",
    "text": "6.4 Cohort-based subset of the cdm"
  },
  {
    "objectID": "ch_7_cdm_locations.html",
    "href": "ch_7_cdm_locations.html",
    "title": "7  Bringing data into memory",
    "section": "",
    "text": "Stow - local duck db and/ or arrow …."
  }
]