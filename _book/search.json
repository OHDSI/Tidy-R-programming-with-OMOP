[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "An introduction to tidy R programming with the OMOP common data model",
    "section": "",
    "text": "The source code for the book can be found at this Github repository Please open an issue there if you have a question or suggestion. Pull requests with suggested changes and additions are also most welcome."
  },
  {
    "objectID": "ch_1_getting_started.html",
    "href": "ch_1_getting_started.html",
    "title": "1  Getting started",
    "section": "",
    "text": "Artwork by @allison_horst\nBefore we start thinking about working with health care data spread across the OMOP common data model, let’s first do a quick data analysis using a simpler dataset. For this we’ll use data data from palmerpenguins package, which contains data on penguins collected from the Palmer Station in Antarctica."
  },
  {
    "objectID": "ch_1_getting_started.html#getting-set-up",
    "href": "ch_1_getting_started.html#getting-set-up",
    "title": "1  Getting started",
    "section": "1.2 Getting set up",
    "text": "1.2 Getting set up\nAssuming that you have R and RStudio already set up, first we need to install a few packages not included in base R if we don´t already have them.\n\ninstall.packages(\"dplyr\")\ninstall.packages(\"ggplot2\")\ninstall.packages(\"DBI\")\ninstall.packages(\"duckdb\")\ninstall.packages(\"palmerpenguins\")\n\nOnce installed, we can load them like so.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(DBI)\nlibrary(duckdb)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "ch_1_getting_started.html#taking-a-peek-at-the-data",
    "href": "ch_1_getting_started.html#taking-a-peek-at-the-data",
    "title": "1  Getting started",
    "section": "1.3 Taking a peek at the data",
    "text": "1.3 Taking a peek at the data\nWe can get an overview of the data using the glimpse() command.\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nOr we could take a look at the first rows of the data using head()\n\nhead(penguins, 5)\n\n# A tibble: 5 × 8\n  species island    bill_length_mm bill_depth_mm flipper_l…¹ body_…² sex    year\n  <fct>   <fct>              <dbl>         <dbl>       <int>   <int> <fct> <int>\n1 Adelie  Torgersen           39.1          18.7         181    3750 male   2007\n2 Adelie  Torgersen           39.5          17.4         186    3800 fema…  2007\n3 Adelie  Torgersen           40.3          18           195    3250 fema…  2007\n4 Adelie  Torgersen           NA            NA            NA      NA <NA>   2007\n5 Adelie  Torgersen           36.7          19.3         193    3450 fema…  2007\n# … with abbreviated variable names ¹​flipper_length_mm, ²​body_mass_g"
  },
  {
    "objectID": "ch_1_getting_started.html#inserting-data-into-a-database",
    "href": "ch_1_getting_started.html#inserting-data-into-a-database",
    "title": "1  Getting started",
    "section": "1.4 Inserting data into a database",
    "text": "1.4 Inserting data into a database\nLet’s put our penguins data into a duckdb database. We create the duckdb database, add the penguins data, and then create a reference to the table containing the data.\n\ndb<-dbConnect(duckdb::duckdb(), dbdir=\":memory:\")\ndbWriteTable(db, \"penguins\", penguins)\npenguins_db<-tbl(db, \"penguins\")\n\nNow the data is in a database we could use SQL to get the first rows that we saw before\n\ndbGetQuery(db, \"SELECT * FROM penguins LIMIT 5\")\n\n  species    island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n1  Adelie Torgersen           39.1          18.7               181        3750\n2  Adelie Torgersen           39.5          17.4               186        3800\n3  Adelie Torgersen           40.3          18.0               195        3250\n4  Adelie Torgersen             NA            NA                NA          NA\n5  Adelie Torgersen           36.7          19.3               193        3450\n     sex year\n1   male 2007\n2 female 2007\n3 female 2007\n4   <NA> 2007\n5 female 2007\n\n\nBut we could also use the same R code as before\n\nhead(penguins_db, 5)\n\n# Source:   SQL [5 x 8]\n# Database: DuckDB 0.5.1 [edbur@Windows 10 x64:R 4.2.1/:memory:]\n  species island    bill_length_mm bill_depth_mm flipper_l…¹ body_…² sex    year\n  <fct>   <fct>              <dbl>         <dbl>       <int>   <int> <fct> <int>\n1 Adelie  Torgersen           39.1          18.7         181    3750 male   2007\n2 Adelie  Torgersen           39.5          17.4         186    3800 fema…  2007\n3 Adelie  Torgersen           40.3          18           195    3250 fema…  2007\n4 Adelie  Torgersen           NA            NA            NA      NA <NA>   2007\n5 Adelie  Torgersen           36.7          19.3         193    3450 fema…  2007\n# … with abbreviated variable names ¹​flipper_length_mm, ²​body_mass_g"
  },
  {
    "objectID": "ch_1_getting_started.html#translation-from-r-to-sql",
    "href": "ch_1_getting_started.html#translation-from-r-to-sql",
    "title": "1  Getting started",
    "section": "1.5 Translation from R to SQL",
    "text": "1.5 Translation from R to SQL\nThe magic here is provided by dbplyr which takes the R code and converts it into SQL, which is this case looks like\n\nhead(penguins_db, 1) %>% \n  show_query()\n\n<SQL>\nSELECT *\nFROM penguins\nLIMIT 1\n\n\nMore complicated SQL can also be written in what might be familiar dplyr code, for example\n\npenguins_db %>% \n  group_by(species) %>% \n  summarise(min_bill_length_mm=min(bill_length_mm),\n            median_bill_length_mm=median(bill_length_mm),\n            max_bill_length_mm=max(bill_length_mm)) %>% \n  mutate(min_max_bill_length_mm=paste0(min_bill_length_mm, \n                                       \" to \",\n                                       max_bill_length_mm)) %>% \n  select(\"species\", \n         \"median_bill_length_mm\",\n         \"min_max_bill_length_mm\")\n\n# Source:   SQL [3 x 3]\n# Database: DuckDB 0.5.1 [edbur@Windows 10 x64:R 4.2.1/:memory:]\n  species   median_bill_length_mm min_max_bill_length_mm\n  <fct>                     <dbl> <chr>                 \n1 Adelie                     38.8 32.1 to 46.0          \n2 Gentoo                     47.3 40.9 to 59.6          \n3 Chinstrap                  49.6 40.9 to 58.0          \n\n\nwith the corresponding SQL looking like\n\npenguins_db %>% \n  group_by(species) %>% \n  summarise(min_bill_length_mm=min(bill_length_mm),\n            median_bill_length_mm=median(bill_length_mm),\n            max_bill_length_mm=max(bill_length_mm)) %>% \n  mutate(min_max_bill_length_mm=paste0(min, \" to \", max)) %>% \n  select(\"species\", \n         \"median_bill_length_mm\",\n         \"min_max_bill_length_mm\") %>% \n  show_query()\n\n<SQL>\nSELECT\n  species,\n  median_bill_length_mm,\n  CONCAT_WS('', .Primitive(\"min\"), ' to ', .Primitive(\"max\")) AS min_max_bill_length_mm\nFROM (\n  SELECT\n    species,\n    MIN(bill_length_mm) AS min_bill_length_mm,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY bill_length_mm) AS median_bill_length_mm,\n    MAX(bill_length_mm) AS max_bill_length_mm\n  FROM penguins\n  GROUP BY species\n) q01"
  },
  {
    "objectID": "ch_1_getting_started.html#example-analysis",
    "href": "ch_1_getting_started.html#example-analysis",
    "title": "1  Getting started",
    "section": "1.6 Example analysis",
    "text": "1.6 Example analysis\nLet´s start by getting a count by species\n\npenguins_db %>% \n  group_by(species) %>% \n  count()\n\n# Source:   SQL [3 x 2]\n# Database: DuckDB 0.5.1 [edbur@Windows 10 x64:R 4.2.1/:memory:]\n  species       n\n  <fct>     <dbl>\n1 Adelie      152\n2 Gentoo      124\n3 Chinstrap    68\n\n\nNow suppose we are particularly interested in the body mass variable. We can first notice that there are a couple of missing records for this.\n\npenguins_db %>% \n  mutate(missing_body_mass_g=if_else(\n    is.na(body_mass_g),1,0\n  )) %>% \n  group_by(species, missing_body_mass_g) %>% \n  tally()\n\n# Source:   SQL [5 x 3]\n# Database: DuckDB 0.5.1 [edbur@Windows 10 x64:R 4.2.1/:memory:]\n# Groups:   species\n  species   missing_body_mass_g     n\n  <fct>                   <dbl> <dbl>\n1 Adelie                      0   151\n2 Adelie                      1     1\n3 Gentoo                      0   123\n4 Gentoo                      1     1\n5 Chinstrap                   0    68\n\n\nWe can get the mean for each of the species (dropping those two missing records).\n\npenguins_db %>% \n  group_by(species) %>% \n  summarise(mean_body_mass_g=round(mean(body_mass_g, na.rm=TRUE),0))\n\n# Source:   SQL [3 x 2]\n# Database: DuckDB 0.5.1 [edbur@Windows 10 x64:R 4.2.1/:memory:]\n  species   mean_body_mass_g\n  <fct>                <dbl>\n1 Adelie                3701\n2 Gentoo                5076\n3 Chinstrap             3733\n\n\nWe can then also do a histogram for each of the species.\n\npenguins_db %>% \n  collect() %>% \n  ggplot(aes(group=species, fill=species))+\n  facet_grid(species~ .) +\n  geom_histogram(aes(body_mass_g), colour=\"black\", binwidth = 100)+\n  theme_bw()+\n  theme(legend.position = \"none\") \n\n\n\n\n\n\n\n\n\n\nChoosing the right time to collect\n\n\n\n\n\ncollect() brings data out of the database and into R. Above we use it to bring the entire penguins data back into R so that we can then use ggplot() to make our histogram.\nIn practice, however, we wouldn’t be reading out entire database tables as typically we are working with a database because we have data of a size that wouldn’t fit in the memory of our computer. Generally we would collect only once we prepared our data for extraction (i.e. limiting to rows and columns of interest).\n\n\n\nHow about the relationship between body mass and bill depth?\n\npenguins %>% \n  collect() %>% \n  ggplot(aes(x=bill_depth_mm,y=body_mass_g))+\n  geom_point()+\n  geom_smooth(method=\"lm\",se=FALSE )+\n  theme_bw()+\n  theme(legend.position = \"none\") \n\n\n\n\nA negative correlation between body mass and bill depth, that seems a little unexpected. What about if we stratify by species?\n\npenguins %>% \n  collect() %>% \n  ggplot(aes(x=bill_depth_mm,y=body_mass_g))+\n  facet_grid(species~ .) +\n  geom_point()+\n  geom_smooth(method=\"lm\",se=FALSE )+\n  theme_bw()+\n  theme(legend.position = \"none\") \n\n\n\n\nAs well as having an example of working with data in database from R, you also have an example of Simpson´s paradox! And now we’ve reached the end of this example, we can close the database like so\n\ndbDisconnect(db)"
  },
  {
    "objectID": "ch_1_getting_started.html#further-reading",
    "href": "ch_1_getting_started.html#further-reading",
    "title": "1  Getting started",
    "section": "1.7 Further reading",
    "text": "1.7 Further reading\n\nR for Data Science (Chapter 13: Relational data)\nWriting SQL with dbplyr\nData Carpentry: SQL databases and R"
  },
  {
    "objectID": "ch_2_cdm_reference.html",
    "href": "ch_2_cdm_reference.html",
    "title": "2  Creating a reference to the OMOP common data model",
    "section": "",
    "text": "Database connections from R can be made using the DBI package. The back-end for DBI is facilitated by database specific driver packages. As an example, lets say we want to work with a local duckdb from R. In this case the we can use the duckdb R package as the driver.\n\nlibrary(DBI)\ndb<-dbConnect(duckdb::duckdb(), dbdir=\":memory:\")\n\nIf we instead wanted to connect to other database management systems, these connections would be supported by the associated back-end packages and could look something like the below example for Postgres:\n\n# Postgres\ndb <- DBI::dbConnect(RPostgres::Postgres(),\n                      dbname = Sys.getenv(\"CDM5_POSTGRESQL_DBNAME\"),\n                      host = Sys.getenv(\"CDM5_POSTGRESQL_HOST\"),\n                      user = Sys.getenv(\"CDM5_POSTGRESQL_USER\"),\n                      password = Sys.getenv(\"CDM5_POSTGRESQL_PASSWORD\"))"
  },
  {
    "objectID": "ch_2_cdm_reference.html#creating-a-reference-to-the-omop-common-data-model",
    "href": "ch_2_cdm_reference.html#creating-a-reference-to-the-omop-common-data-model",
    "title": "2  Creating a reference to the OMOP common data model",
    "section": "2.2 Creating a reference to the OMOP common data model",
    "text": "2.2 Creating a reference to the OMOP common data model\nAs seen in the previous chapter, once a connection to the database has been created we could then create references to the various tables in the database and build queries using in a familiar dplyr style. However, as we already know what the structure of the OMOP CDM looks like, we can avoid the overhead of creating references to the OMOP CDM tables by using the CDMConnector package to quickly create a reference to the database as a whole.\nIf you don’t already have it installed, the first step would be to install CDMConnector from CRAN.\n\ninstall.packages(\"CDMConnector\")\n\nFor this example, we’ll use the Eunomia example data contained in a duckdb database. First we need to download the data. And once downloaded, make sure to add the path to your Renviron.\n\nlibrary(CDMConnector)\n\n\n# change pathToData to the location you want to save the data\nCDMConnector::downloadEunomiaData(\n  pathToData = here::here(), \n  overwrite = TRUE\n)\n# once downloaded, save your pathToData to your Renviron (and then restart R)\n# EUNOMIA_DATA_FOLDER=\"......\"\n\n\ndb <- DBI::dbConnect(duckdb::duckdb(), \n                     dbdir = CDMConnector::eunomia_dir())\ncdm <- CDMConnector::cdm_from_con(con = db, \n                                  cdm_schema = \"main\")\ncdm\n\n# OMOP CDM reference (tbl_duckdb_connection)\n\nTables: person, observation_period, visit_occurrence, visit_detail, condition_occurrence, drug_exposure, procedure_occurrence, measurement, observation, death, location, care_site, provider, drug_era, dose_era, condition_era, cdm_source, concept, vocabulary, concept_relationship, concept_synonym, concept_ancestor, drug_strength\n\n\nOnce we have created the our reference to the overall OMOP CDM, we can reference specific tables using the “$” operator.\n\ncdm$observation_period\n\n# Source:   table<main.observation_period> [?? x 5]\n# Database: DuckDB 0.5.0 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpELVYgC/ofdkwfsp]\n   observation_period_id person_id observation_period_start…¹ observat…² perio…³\n                   <dbl>     <dbl> <date>                     <date>       <dbl>\n 1                     6         6 1963-12-31                 2007-02-06  4.48e7\n 2                    13        13 2009-04-26                 2019-04-14  4.48e7\n 3                    27        27 2002-01-30                 2018-11-21  4.48e7\n 4                    16        16 1971-10-14                 2017-11-02  4.48e7\n 5                    55        55 2009-05-30                 2019-03-23  4.48e7\n 6                    60        60 1990-11-21                 2019-01-23  4.48e7\n 7                    42        42 1909-11-03                 2019-03-13  4.48e7\n 8                    33        33 1986-05-12                 2018-09-10  4.48e7\n 9                    18        18 1965-11-17                 2018-11-07  4.48e7\n10                    25        25 2007-03-18                 2019-04-07  4.48e7\n# … with more rows, and abbreviated variable names\n#   ¹​observation_period_start_date, ²​observation_period_end_date,\n#   ³​period_type_concept_id\n\n\nAlternatively, you could also access a specific table reference like so\n\ncdm[[\"observation_period\"]]\n\n# Source:   table<main.observation_period> [?? x 5]\n# Database: DuckDB 0.5.0 [eburn@Windows 10 x64:R 4.2.1/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpELVYgC/ofdkwfsp]\n   observation_period_id person_id observation_period_start…¹ observat…² perio…³\n                   <dbl>     <dbl> <date>                     <date>       <dbl>\n 1                     6         6 1963-12-31                 2007-02-06  4.48e7\n 2                    13        13 2009-04-26                 2019-04-14  4.48e7\n 3                    27        27 2002-01-30                 2018-11-21  4.48e7\n 4                    16        16 1971-10-14                 2017-11-02  4.48e7\n 5                    55        55 2009-05-30                 2019-03-23  4.48e7\n 6                    60        60 1990-11-21                 2019-01-23  4.48e7\n 7                    42        42 1909-11-03                 2019-03-13  4.48e7\n 8                    33        33 1986-05-12                 2018-09-10  4.48e7\n 9                    18        18 1965-11-17                 2018-11-07  4.48e7\n10                    25        25 2007-03-18                 2019-04-07  4.48e7\n# … with more rows, and abbreviated variable names\n#   ¹​observation_period_start_date, ²​observation_period_end_date,\n#   ³​period_type_concept_id\n\n\nWhen we created our reference we could have also specified a subset of cdm tables that we want to reference to:\n\ncdm <- cdm_from_con(db, \n                    cdm_tables = c(\"person\",\"observation_period\"))\ncdm\n\n# OMOP CDM reference (tbl_duckdb_connection)\n\nTables: person, observation_period\n\n\nMoreover, we can also specify a write schema. This would be a schema in which we have permission to create tables (as we’re unlikely to have that permission for the schema containing the tables with the patient-level data).\n\ncdm <- cdm_from_con(db,\n  cdm_schema = \"main\",\n  cdm_tables = c(\"person\",\"observation_period\"),\n  write_schema = \"results\")\n\nAnd if we already had some cohort tables in the results schema, we could include references to these like so:\n\ncdm <- cdm_from_con(db,\n  cdm_schema = \"main\",\n  cdm_tables = c(\"person\",\"observation_period\"),\n  write_schema = \"results\",\n  cohort_tables = c(\"exposure_cohort\", \"outcome_cohort\"))"
  },
  {
    "objectID": "ch_2_cdm_reference.html#database-snapshot",
    "href": "ch_2_cdm_reference.html#database-snapshot",
    "title": "2  Creating a reference to the OMOP common data model",
    "section": "2.3 Database snapshot",
    "text": "2.3 Database snapshot\nWe can also use CDMConnector to provide a summary of the metadata for the OMOP CDM data we have connected to using the snapshot() function.\n\n\n\n\ncdm_from_con(con = db, \n             cdm_schema = \"main\") %>% \n  snapshot() %>% \n  glimpse()\n\nList of 7\n $ cdm_source_name       : chr \"Synthea synthetic health database\"\n $ cdm_version           : chr \"v5.3.1\"\n $ cdm_holder            : chr \"OHDSI Community\"\n $ cdm_release_date      : Date[1:1], format: \"2019-05-25\"\n $ vocabulary_version    : chr \"v5.0 18-JAN-19\"\n $ person_cnt            : num 2694\n $ observation_period_cnt: num 5343\n - attr(*, \"class\")= chr \"cdm_snapshot\""
  },
  {
    "objectID": "ch_2_cdm_reference.html#further-reading",
    "href": "ch_2_cdm_reference.html#further-reading",
    "title": "2  Creating a reference to the OMOP common data model",
    "section": "2.4 Further reading",
    "text": "2.4 Further reading\n\nCDMConnector package"
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html",
    "href": "ch_3_exploring_the_cdm.html",
    "title": "3  Exploring the CDM",
    "section": "",
    "text": "Let’s first connect again to our Eunomia data and create the reference to the common data model."
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#counting-people",
    "href": "ch_3_exploring_the_cdm.html#counting-people",
    "title": "3  Exploring the CDM",
    "section": "3.2 Counting people",
    "text": "3.2 Counting people\nThe OMOP CDM is person-centric, with the person table containing records to uniquely identify each person in the database. As each row refers to a unique person, we can quickly get a count of the number of individuals in the database like so\n\ncdm$person %>% \n  count() %>% \n  pull()\n\n[1] 2694\n\n\nThe person table also contains some demographic information, including a gender_concept_id for each person. We can get a count grouped by this variable, but as this uses a concept we’ll also need to join to the concept table to get the corresponding concept name for each concept id.\n\ncdm$person %>% \n  group_by(gender_concept_id) %>% \n  count() %>% \n  left_join(cdm$concept, \n            by=c(\"gender_concept_id\" = \"concept_id\")) %>% \n              select(\"gender_concept_id\", \"concept_name\", \"n\") %>% \n  collect()\n\n# A tibble: 2 × 3\n  gender_concept_id concept_name     n\n              <dbl> <chr>        <dbl>\n1              8532 FEMALE        1373\n2              8507 MALE          1321\n\n\nThe observation period table contains records indicating spans of time over which clinical events can be reliably observed for the people in the person table. Someone can potentially have multiple observation periods. So say we wanted a count of people grouped by the year during which their first observation period started. We could do this like so:\n\nfirst_observation_period <- cdm$observation_period %>%\n    group_by(person_id) %>% \n    filter(dplyr::row_number() == 1) %>% \n    compute()\n\ncdm$person %>% \n  left_join(first_observation_period,\n            by = \"person_id\") %>% \n  mutate(observation_period_start_year=year(observation_period_start_date)) %>% \n  group_by(observation_period_start_year) %>% \n  count() %>% \n  collect() %>% \n  ggplot() +\n  geom_col(aes(observation_period_start_year, n)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nTo compute or not to compute\n\n\n\n\n\nThe compute() function will force the computation of a query. In the example above we use it to split up two queries; the first to keep the first observation period record for each individual.\n\ncdm$observation_period %>%\n    group_by(person_id) %>% \n    filter(dplyr::row_number() == 1) %>% \n    show_query()\n\n<SQL>\nSELECT\n  observation_period_id,\n  person_id,\n  observation_period_start_date,\n  observation_period_end_date,\n  period_type_concept_id\nFROM (\n  SELECT *, ROW_NUMBER() OVER (PARTITION BY person_id) AS q03\n  FROM main.observation_period\n) q01\nWHERE (q03 = 1.0)\n\n\nFollowed by a second query that left joins the person table with the result from the first (which is now in a temporary table), followed by extracted the year in which peoples first observation period starts and then, finally, a count by year.\n\ncdm$person %>% \n  left_join(first_observation_period,\n            by = \"person_id\") %>% \n  mutate(observation_period_start_year=year(observation_period_start_date)) %>% \n  group_by(observation_period_start_year) %>% \n  count() %>% \n  show_query()\n\n<SQL>\nSELECT observation_period_start_year, COUNT(*) AS n\nFROM (\n  SELECT\n    *,\n    EXTRACT(year FROM observation_period_start_date) AS observation_period_start_year\n  FROM (\n    SELECT\n      LHS.person_id AS person_id,\n      gender_concept_id,\n      year_of_birth,\n      month_of_birth,\n      day_of_birth,\n      birth_datetime,\n      race_concept_id,\n      ethnicity_concept_id,\n      location_id,\n      provider_id,\n      care_site_id,\n      person_source_value,\n      gender_source_value,\n      gender_source_concept_id,\n      race_source_value,\n      race_source_concept_id,\n      ethnicity_source_value,\n      ethnicity_source_concept_id,\n      observation_period_id,\n      observation_period_start_date,\n      observation_period_end_date,\n      period_type_concept_id\n    FROM main.person AS LHS\n    LEFT JOIN dbplyr_001 AS RHS\n      ON (LHS.person_id = RHS.person_id)\n  ) q01\n) q02\nGROUP BY observation_period_start_year\n\n\nWe could, however, have done this without compute, with instead the SQL being done all at once.\n\ncdm$person %>% \n  left_join(cdm$observation_period %>%\n    group_by(person_id) %>% \n    filter(dplyr::row_number() == 1),\n            by = \"person_id\") %>% \n  mutate(observation_period_start_year=year(observation_period_start_date)) %>% \n  group_by(observation_period_start_year) %>% \n  count() %>% \n  show_query()\n\n<SQL>\nSELECT observation_period_start_year, COUNT(*) AS n\nFROM (\n  SELECT\n    *,\n    EXTRACT(year FROM observation_period_start_date) AS observation_period_start_year\n  FROM (\n    SELECT\n      LHS.person_id AS person_id,\n      gender_concept_id,\n      year_of_birth,\n      month_of_birth,\n      day_of_birth,\n      birth_datetime,\n      race_concept_id,\n      ethnicity_concept_id,\n      location_id,\n      provider_id,\n      care_site_id,\n      person_source_value,\n      gender_source_value,\n      gender_source_concept_id,\n      race_source_value,\n      race_source_concept_id,\n      ethnicity_source_value,\n      ethnicity_source_concept_id,\n      observation_period_id,\n      observation_period_start_date,\n      observation_period_end_date,\n      period_type_concept_id\n    FROM main.person AS LHS\n    LEFT JOIN (\n      SELECT\n        observation_period_id,\n        person_id,\n        observation_period_start_date,\n        observation_period_end_date,\n        period_type_concept_id\n      FROM (\n        SELECT *, ROW_NUMBER() OVER (PARTITION BY person_id) AS q03\n        FROM main.observation_period\n      ) q01\n      WHERE (q03 = 1.0)\n    ) RHS\n      ON (LHS.person_id = RHS.person_id)\n  ) q02\n) q03\nGROUP BY observation_period_start_year\n\n\nIn this case the SQL is not much more complicated than before. However, you can imagine that without forcing computation, the SQL associated with a series of data manipulations could quickly become unmanageable. So although we don’t want to overuse compute, it is often a necessity when writing analysis scripts.\nAn advantage of using compute, is that we can use the result for multiple subsequent queries. For example, say we want a count of condition occurrence and drug exposure records for those born before 1970. We could get these counts independently:\n\ncdm$person %>% \n  filter(year_of_birth < \"1970\") %>% \n  select(\"person_id\") %>% \n  left_join(cdm$condition_occurrence,\n            by=\"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.5.1 [edbur@Windows 10 x64:R 4.2.1/C:\\Users\\edbur\\AppData\\Local\\Temp\\RtmpaqH8R0/zjntpkde]\n      n\n  <dbl>\n1 51858\n\ncdm$person %>% \n  filter(year_of_birth < \"1970\") %>% \n  select(\"person_id\") %>% \n  left_join(cdm$drug_exposure,\n            by=\"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.5.1 [edbur@Windows 10 x64:R 4.2.1/C:\\Users\\edbur\\AppData\\Local\\Temp\\RtmpaqH8R0/zjntpkde]\n      n\n  <dbl>\n1 49447\n\n\nBut we could have instead first subsetted the person table and then used the result for both queries.\n\ncdm$person_pre_1970 <- cdm$person %>% \n  filter(year_of_birth < \"1970\") %>% \n  compute()\n\ncdm$person_pre_1970 %>% \n  select(\"person_id\") %>% \n  left_join(cdm$condition_occurrence,\n            by=\"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.5.1 [edbur@Windows 10 x64:R 4.2.1/C:\\Users\\edbur\\AppData\\Local\\Temp\\RtmpaqH8R0/zjntpkde]\n      n\n  <dbl>\n1 51858\n\ncdm$person_pre_1970 %>% \n  select(\"person_id\") %>% \n  left_join(cdm$drug_exposure,\n            by=\"person_id\") %>% \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: DuckDB 0.5.1 [edbur@Windows 10 x64:R 4.2.1/C:\\Users\\edbur\\AppData\\Local\\Temp\\RtmpaqH8R0/zjntpkde]\n      n\n  <dbl>\n1 49447\n\n\n\n\n\n\n\n\n\n\n\ncomputeQuery()\n\n\n\n\n\nThe compute() function from dplyr is currently somewhat inconsistent across database platforms. For this reason CDMConnector provides the computeQuery() which does the same job, but with greater consistency across its supported database management systems.\n\ncdm$person %>% \n  tally() %>% \n  computeQuery()\n\n# Source:   table<dbplyr_003> [1 x 1]\n# Database: DuckDB 0.5.1 [edbur@Windows 10 x64:R 4.2.1/C:\\Users\\edbur\\AppData\\Local\\Temp\\RtmpaqH8R0/zjntpkde]\n      n\n  <dbl>\n1  2694"
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#counting-records",
    "href": "ch_3_exploring_the_cdm.html#counting-records",
    "title": "3  Exploring the CDM",
    "section": "3.3 Counting records",
    "text": "3.3 Counting records\nNumber of drug exposure records per person\n\ncdm$person %>% \n  left_join(cdm$measurement %>% \n  group_by(person_id) %>% \n  count(name = \"condition_occurrence_records\"),\n            by=\"person_id\") %>% \n  mutate(condition_occurrence_records = if_else(\n    is.na(condition_occurrence_records), 0,\n    condition_occurrence_records)) %>% \n  group_by(condition_occurrence_records) %>%\n  count() %>% \n  collect() %>% \n  ggplot() +\n  geom_col(aes(condition_occurrence_records, n)) +\n  theme_bw()"
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#working-with-dates",
    "href": "ch_3_exploring_the_cdm.html#working-with-dates",
    "title": "3  Exploring the CDM",
    "section": "3.4 Working with dates",
    "text": "3.4 Working with dates\nDates are supported somewhat inconsistently by dbplyr but, as with computeQuery(), CDMConnector also provides some date functions that are tested to work across supported databases. We can use the datediff() function for example to calculate the difference between two dates. We can use this below to get the number of years observation periods last for.\n\ncdm$observation_period %>%\n  dplyr::mutate(observation_years = \n                  !!CDMConnector::datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"year\"))  %>% \n  collect() %>% \n  ggplot() +\n  geom_histogram(aes(observation_years), \n                 binwidth=2, colour=\"grey\") +\n  theme_bw()"
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#statistical-summaries",
    "href": "ch_3_exploring_the_cdm.html#statistical-summaries",
    "title": "3  Exploring the CDM",
    "section": "3.5 Statistical summaries",
    "text": "3.5 Statistical summaries\nWe can also use summarise for various other calculations\n\ncdm$person %>% \n  summarise(min_year_of_birth = min(year_of_birth, na.rm=TRUE),\n            q05_year_of_birth = quantile(year_of_birth, 0.05, na.rm=TRUE),\n            mean_year_of_birth = round(mean(year_of_birth, na.rm=TRUE),0),\n            median_year_of_birth = median(year_of_birth, na.rm=TRUE),\n            q95_year_of_birth = quantile(year_of_birth, 0.95, na.rm=TRUE),\n            max_year_of_birth = max(year_of_birth, na.rm=TRUE)) %>%  \n  glimpse()\n\nRows: ??\nColumns: 6\nDatabase: DuckDB 0.5.1 [edbur@Windows 10 x64:R 4.2.1/C:\\Users\\edbur\\AppData\\Local\\Temp\\RtmpaqH8R0/zjntpkde]\n$ min_year_of_birth    <dbl> 1908\n$ q05_year_of_birth    <dbl> 1922\n$ mean_year_of_birth   <dbl> 1958\n$ median_year_of_birth <dbl> 1961\n$ q95_year_of_birth    <dbl> 1979\n$ max_year_of_birth    <dbl> 1986\n\n\n\n\n\n\n\n\nPiping and SQL\n\n\n\n\n\nAlthough piping queries has little impact on performance when using R with data in memory, when working with a database the SQL generated will differ when using multiple function calls (with a separate operation specified in each) instead of multiple operations within a single function call.\nFor example, the single summarise function above would generate the below SQL.\n\ncdm$person %>% \n  summarise(min_year_of_birth = min(year_of_birth, na.rm=TRUE),\n            q05_year_of_birth = quantile(year_of_birth, 0.05, na.rm=TRUE),\n            mean_year_of_birth = round(mean(year_of_birth, na.rm=TRUE),0),\n            median_year_of_birth = median(year_of_birth, na.rm=TRUE),\n            q95_year_of_birth = quantile(year_of_birth, 0.95, na.rm=TRUE),\n            max_year_of_birth = max(year_of_birth, na.rm=TRUE)) %>% \n  show_query()\n\n<SQL>\nSELECT\n  MIN(year_of_birth) AS min_year_of_birth,\n  PERCENTILE_CONT(0.05) WITHIN GROUP (ORDER BY year_of_birth) AS q05_year_of_birth,\n  ROUND(AVG(year_of_birth), CAST(ROUND(0.0, 0) AS INTEGER)) AS mean_year_of_birth,\n  PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY year_of_birth) AS median_year_of_birth,\n  PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY year_of_birth) AS q95_year_of_birth,\n  MAX(year_of_birth) AS max_year_of_birth\nFROM main.person\n\n\nCalling summarise for each though would lead to a more involved query.\n\ncdm$person %>% \n  summarise(min_year_of_birth = min(year_of_birth, na.rm=TRUE)) %>% \n  summarise(q05_year_of_birth = quantile(year_of_birth, 0.05, na.rm=TRUE)) %>% \n  summarise(mean_year_of_birth = round(mean(year_of_birth, na.rm=TRUE),0)) %>% \n  summarise(median_year_of_birth = median(year_of_birth, na.rm=TRUE)) %>% \n  summarise(q95_year_of_birth = quantile(year_of_birth, 0.95, na.rm=TRUE)) %>% \n  summarise(max_year_of_birth = max(year_of_birth, na.rm=TRUE)) %>% \n  show_query()\n\n<SQL>\nSELECT MAX(year_of_birth) AS max_year_of_birth\nFROM (\n  SELECT PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY year_of_birth) AS q95_year_of_birth\n  FROM (\n    SELECT PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY year_of_birth) AS median_year_of_birth\n    FROM (\n      SELECT ROUND(AVG(year_of_birth), CAST(ROUND(0.0, 0) AS INTEGER)) AS mean_year_of_birth\n      FROM (\n        SELECT PERCENTILE_CONT(0.05) WITHIN GROUP (ORDER BY year_of_birth) AS q05_year_of_birth\n        FROM (\n          SELECT MIN(year_of_birth) AS min_year_of_birth\n          FROM main.person\n        ) q01\n      ) q02\n    ) q03\n  ) q04\n) q05\n\n\nA similar story can be seen with mutate\n\ncdm$observation_period %>%\n  mutate(observation_days = !!datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"day\"),\n        observation_years = !!datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"year\")) %>% \n  select(\"observation_period_id\", \"person_id\", \n         \"observation_days\",\"observation_years\") %>% \n  show_query()\n\n<SQL>\nSELECT\n  observation_period_id,\n  person_id,\n  datediff('day', observation_period_start_date, observation_period_end_date) AS observation_days,\n  datediff('year', observation_period_start_date, observation_period_end_date) AS observation_years\nFROM main.observation_period\n\n\n\ncdm$observation_period %>%\n  mutate(observation_days = !!datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"day\")) %>% \n  mutate(observation_years = !!datediff(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \n                             interval = \"year\")) %>% \n  select(\"observation_period_id\", \"person_id\", \n         \"observation_days\",\"observation_years\") %>% \n  show_query()\n\n<SQL>\nSELECT\n  observation_period_id,\n  person_id,\n  observation_days,\n  datediff('year', observation_period_start_date, observation_period_end_date) AS observation_years\nFROM (\n  SELECT\n    *,\n    datediff('day', observation_period_start_date, observation_period_end_date) AS observation_days\n  FROM main.observation_period\n) q01\n\n\n\n\n\nAs we’ve seen before, we can also quickly get results for various groupings or restrictions\n\ncdm$person %>% \n   group_by(gender_concept_id) %>% \n   summarise(min_year_of_birth = min(year_of_birth, na.rm=TRUE),\n            q25_year_of_birth = quantile(year_of_birth, 0.25, na.rm=TRUE),\n            median_year_of_birth = median(year_of_birth, na.rm=TRUE),\n            q75_year_of_birth = quantile(year_of_birth, 0.75, na.rm=TRUE),\n            max_year_of_birth = max(year_of_birth, na.rm=TRUE)) %>% \n  left_join(cdm$concept, \n            by=c(\"gender_concept_id\" = \"concept_id\")) %>% \n   collect() %>% \n  ggplot(aes(x = concept_name, group = concept_name,\n             fill = concept_name)) +\n  geom_boxplot(aes(\n    lower = q25_year_of_birth, \n    upper = q75_year_of_birth, \n    middle = median_year_of_birth, \n    ymin = min_year_of_birth, \n    ymax = max_year_of_birth),\n    stat = \"identity\", width = 0.5) + \n  theme_bw()+ \n  theme(legend.position = \"none\") +\n  xlab(\"\")"
  },
  {
    "objectID": "ch_4_building_a_cohort.html",
    "href": "ch_4_building_a_cohort.html",
    "title": "4  Adding a cohort",
    "section": "",
    "text": "library(CDMConnector)\nlibrary(dplyr)\nlibrary(CodelistGenerator)\nlibrary(Capr)"
  },
  {
    "objectID": "ch_4_building_a_cohort.html#adding-a-cohort-to-the-cdm",
    "href": "ch_4_building_a_cohort.html#adding-a-cohort-to-the-cdm",
    "title": "4  Adding a cohort",
    "section": "4.2 Adding a cohort to the CDM",
    "text": "4.2 Adding a cohort to the CDM\nvia cdm connector"
  },
  {
    "objectID": "ch_4_building_a_cohort.html#cohort-summary",
    "href": "ch_4_building_a_cohort.html#cohort-summary",
    "title": "4  Adding a cohort",
    "section": "4.3 Cohort summary",
    "text": "4.3 Cohort summary\nAttributes: Cohort count, settings, attrition ….."
  },
  {
    "objectID": "ch_5_describing_a_cohort.html#section",
    "href": "ch_5_describing_a_cohort.html#section",
    "title": "5  Dscribing a cohort",
    "section": "5.2 ",
    "text": "5.2"
  },
  {
    "objectID": "ch_4_building_a_cohort.html#defining-a-cohort-definition",
    "href": "ch_4_building_a_cohort.html#defining-a-cohort-definition",
    "title": "4  Adding a cohort",
    "section": "4.1 Defining a cohort definition",
    "text": "4.1 Defining a cohort definition\nWe can define a cohort programmatically using the Capr package.\n\ncon <- DBI::dbConnect(duckdb::duckdb(), eunomia_dir())\n\ncdm <- CDMConnector::cdm_from_con(\n  con = con,\n  cdm_schema = \"main\",\n  write_schema = \"main\"\n)\n\nLet´s say we want to identify people with a gastrointestinal hemorrhage. First we´ll need to identify the code … and generate a conc\n\ngibleed_codes <- getCandidateCodes(cdm = cdm, \n                  keywords = \"gastrointestinal hemorrhage\",\n                  domains = \"condition\",\n                  exactMatch = TRUE,\n                  includeDescendants = FALSE)\ngibleed_concept_set <- cs(descendants(gibleed_codes$concept_id))\n\nWe can now us\n\ngibleed_cohort_definition <- cohort(\n   entry = entry(\n    condition(gibleed_concept_set),\n    primaryCriteriaLimit = \"First\"\n  ))\n\nLet´s make things a little more complicated. We´ll exclude people with rheumatoid arthritis (regardless of when they were diagnosed). We´ll also require that people\n\nrheumatoid_arthritis_codes <- getCandidateCodes(cdm = cdm, \n                  keywords = \"rheumatoid arthritis\",\n                  domains = \"condition\",\n                  exactMatch = TRUE,\n                  includeDescendants = FALSE)\nrheumatoid_arthritis_concept_set <- cs(descendants(\n  rheumatoid_arthritis_codes$concept_id))\n\n\n\ngibleed_no_RA_cohort_definition <- cohort(\n   entry = entry(\n    condition(gibleed_concept_set),\n    observationWindow = continuousObservation(0L, 0L),\n    primaryCriteriaLimit = \"First\"\n  ),\n  attrition = attrition(\n    \"no RA\" = withAll(\n      exactly(0,\n              condition(rheumatoid_arthritis_concept_set),\n              duringInterval(eventStarts(-Inf, Inf))))\n  ))\n\n\n\n\npath <- file.path(tempdir(), \"cohorts\")\ndir.create(path)\nwriteCohort(gibleed_cohort_definition, file.path(path, \"gibleed.json\"))\ngibleed_cohort_set <- readCohortSet(path = path)\n\n\n\n# cdm <- generateCohortSet(\n#   cdm,\n#   gibleed_cohort_set,\n#   name = \"gibleed\",\n#   computeAttrition = TRUE\n# )\n\n\n\n\n\n\n\nJSON representation of a cohort\n\n\n\n\n\n\ncat(as.json(gibleed_concept_set))\n\n{\n  \"items\": [\n    {\n      \"concept\": {\n        \"CONCEPT_ID\": 192671,\n        \"CONCEPT_NAME\": \"\",\n        \"STANDARD_CONCEPT\": \"\",\n        \"STANDARD_CONCEPT_CAPTION\": \"\",\n        \"INVALID_REASON\": \"\",\n        \"INVALID_REASON_CAPTION\": \"\",\n        \"CONCEPT_CODE\": \"\",\n        \"DOMAIN_ID\": \"\",\n        \"VOCABULARY_ID\": \"\",\n        \"CONCEPT_CLASS_ID\": \"\"\n      },\n      \"isExcluded\": false,\n      \"includeDescendants\": true,\n      \"includeMapped\": false\n    }\n  ]\n}\n\ncat(as.json(rheumatoid_arthritis_concept_set))\n\n{\n  \"items\": [\n    {\n      \"concept\": {\n        \"CONCEPT_ID\": 80809,\n        \"CONCEPT_NAME\": \"\",\n        \"STANDARD_CONCEPT\": \"\",\n        \"STANDARD_CONCEPT_CAPTION\": \"\",\n        \"INVALID_REASON\": \"\",\n        \"INVALID_REASON_CAPTION\": \"\",\n        \"CONCEPT_CODE\": \"\",\n        \"DOMAIN_ID\": \"\",\n        \"VOCABULARY_ID\": \"\",\n        \"CONCEPT_CLASS_ID\": \"\"\n      },\n      \"isExcluded\": false,\n      \"includeDescendants\": true,\n      \"includeMapped\": false\n    }\n  ]\n}\n\n\n\n\n\n\n\n\n\n\n\nJSON representation of a cohort\n\n\n\n\n\n\ncat(as.json((gibleed_cohort_definition)))\n\n{\n  \"ConceptSets\": [\n    {\n      \"id\": 0,\n      \"name\": \"\",\n      \"expression\": {\n        \"items\": [\n          {\n            \"concept\": {\n              \"CONCEPT_ID\": 192671,\n              \"CONCEPT_NAME\": \"\",\n              \"STANDARD_CONCEPT\": \"\",\n              \"STANDARD_CONCEPT_CAPTION\": \"\",\n              \"INVALID_REASON\": \"\",\n              \"INVALID_REASON_CAPTION\": \"\",\n              \"CONCEPT_CODE\": \"\",\n              \"DOMAIN_ID\": \"\",\n              \"VOCABULARY_ID\": \"\",\n              \"CONCEPT_CLASS_ID\": \"\"\n            },\n            \"isExcluded\": false,\n            \"includeDescendants\": true,\n            \"includeMapped\": false\n          }\n        ]\n      }\n    }\n  ],\n  \"PrimaryCriteria\": {\n    \"CriteriaList\": [\n      {\n        \"ConditionOccurrence\": {\n          \"CodesetId\": 0\n        }\n      }\n    ],\n    \"ObservationWindow\": {\n      \"PriorDays\": 0,\n      \"PostDays\": 0\n    },\n    \"PrimaryCriteriaLimit\": {\n      \"Type\": \"First\"\n    }\n  },\n  \"QualifiedLimit\": {\n    \"Type\": \"First\"\n  },\n  \"ExpressionLimit\": {\n    \"Type\": \"First\"\n  },\n  \"InclusionRules\": [],\n  \"CensoringCriteria\": [],\n  \"CollapseSettings\": {\n    \"CollapseType\": \"ERA\",\n    \"EraPad\": 0\n  },\n  \"CensorWindow\": {},\n  \"cdmVersionRange\": \">=5.0.0\"\n}\n\ncat(as.json((gibleed_no_RA_cohort_definition)))\n\n{\n  \"ConceptSets\": [\n    {\n      \"id\": 0,\n      \"name\": \"\",\n      \"expression\": {\n        \"items\": [\n          {\n            \"concept\": {\n              \"CONCEPT_ID\": 192671,\n              \"CONCEPT_NAME\": \"\",\n              \"STANDARD_CONCEPT\": \"\",\n              \"STANDARD_CONCEPT_CAPTION\": \"\",\n              \"INVALID_REASON\": \"\",\n              \"INVALID_REASON_CAPTION\": \"\",\n              \"CONCEPT_CODE\": \"\",\n              \"DOMAIN_ID\": \"\",\n              \"VOCABULARY_ID\": \"\",\n              \"CONCEPT_CLASS_ID\": \"\"\n            },\n            \"isExcluded\": false,\n            \"includeDescendants\": true,\n            \"includeMapped\": false\n          }\n        ]\n      }\n    },\n    {\n      \"id\": 1,\n      \"name\": \"\",\n      \"expression\": {\n        \"items\": [\n          {\n            \"concept\": {\n              \"CONCEPT_ID\": 80809,\n              \"CONCEPT_NAME\": \"\",\n              \"STANDARD_CONCEPT\": \"\",\n              \"STANDARD_CONCEPT_CAPTION\": \"\",\n              \"INVALID_REASON\": \"\",\n              \"INVALID_REASON_CAPTION\": \"\",\n              \"CONCEPT_CODE\": \"\",\n              \"DOMAIN_ID\": \"\",\n              \"VOCABULARY_ID\": \"\",\n              \"CONCEPT_CLASS_ID\": \"\"\n            },\n            \"isExcluded\": false,\n            \"includeDescendants\": true,\n            \"includeMapped\": false\n          }\n        ]\n      }\n    }\n  ],\n  \"PrimaryCriteria\": {\n    \"CriteriaList\": [\n      {\n        \"ConditionOccurrence\": {\n          \"CodesetId\": 0\n        }\n      }\n    ],\n    \"ObservationWindow\": {\n      \"PriorDays\": 0,\n      \"PostDays\": 0\n    },\n    \"PrimaryCriteriaLimit\": {\n      \"Type\": \"First\"\n    }\n  },\n  \"QualifiedLimit\": {\n    \"Type\": \"First\"\n  },\n  \"ExpressionLimit\": {\n    \"Type\": \"First\"\n  },\n  \"InclusionRules\": [\n    {\n      \"name\": \"no RA\",\n      \"expression\": {\n        \"Type\": \"ALL\",\n        \"CriteriaList\": [\n          {\n            \"Criteria\": {\n              \"ConditionOccurrence\": {\n                \"CodesetId\": 1\n              }\n            },\n            \"StartWindow\": {\n              \"Start\": {\n                \"Coeff\": -1\n              },\n              \"End\": {\n                \"Coeff\": 1\n              },\n              \"UseIndexEnd\": false,\n              \"UseEventEnd\": false\n            },\n            \"Occurrence\": {\n              \"Type\": 0,\n              \"Count\": 0\n            }\n          }\n        ],\n        \"DemographicCriteriaList\": [],\n        \"Groups\": []\n      }\n    }\n  ],\n  \"CensoringCriteria\": [],\n  \"CollapseSettings\": {\n    \"CollapseType\": \"ERA\",\n    \"EraPad\": 0\n  },\n  \"CensorWindow\": {},\n  \"cdmVersionRange\": \">=5.0.0\"\n}"
  },
  {
    "objectID": "ch_3_exploring_the_cdm.html#vocabulary-tables",
    "href": "ch_3_exploring_the_cdm.html#vocabulary-tables",
    "title": "3  Exploring the CDM",
    "section": "3.1 Vocabulary tables",
    "text": "3.1 Vocabulary tables\nADD SOME INTRODUCTION TO THE VOCAB TABLES\n\ncdm$concept %>% \n  glimpse()\n\nRows: ??\nColumns: 10\nDatabase: DuckDB 0.5.1 [edbur@Windows 10 x64:R 4.2.1/C:\\Users\\edbur\\AppData\\Local\\Temp\\RtmpaqH8R0/zjntpkde]\n$ concept_id       <dbl> 35208414, 1118088, 40213201, 1557272, 4336464, 429588…\n$ concept_name     <chr> \"Gastrointestinal hemorrhage, unspecified\", \"celecoxi…\n$ domain_id        <chr> \"Condition\", \"Drug\", \"Drug\", \"Drug\", \"Procedure\", \"Pr…\n$ vocabulary_id    <chr> \"ICD10CM\", \"RxNorm\", \"CVX\", \"RxNorm\", \"SNOMED\", \"SNOM…\n$ concept_class_id <chr> \"4-char billing code\", \"Branded Drug\", \"CVX\", \"Ingred…\n$ standard_concept <chr> NA, \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", NA, NA, \"S\", \"…\n$ concept_code     <chr> \"K92.2\", \"213469\", \"33\", \"46041\", \"232717009\", \"76601…\n$ valid_start_date <date> 2007-01-01, 1970-01-01, 2008-12-01, 1970-01-01, 1970…\n$ valid_end_date   <date> 2099-12-31, 2099-12-31, 2099-12-31, 2099-12-31, 2099…\n$ invalid_reason   <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"
  }
]