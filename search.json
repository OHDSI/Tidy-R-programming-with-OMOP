[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tidy R programming with the OMOP common data model",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#is-this-book-for-me",
    "href": "index.html#is-this-book-for-me",
    "title": "Tidy R programming with the OMOP common data model",
    "section": "Is this book for me?",
    "text": "Is this book for me?\nWe’ve written this book for anyone interested in a working with databases mapped to the OMOP Common Data Model (CDM) in a tidyverse inspired approach. That is, human centered, consistent, composable, and inclusive (see https://design.tidyverse.org/unifying.html for more details on these principles).\nNew to the OMOP CDM? We’d recommend you pare this book with The Book of OHDSI\nNew to R? We recommend you compliment the book with R for data science",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "Tidy R programming with the OMOP common data model",
    "section": "Citation",
    "text": "Citation\nTO ADD",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Tidy R programming with the OMOP common data model",
    "section": "License",
    "text": "License\n This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#code",
    "href": "index.html#code",
    "title": "Tidy R programming with the OMOP common data model",
    "section": "Code",
    "text": "Code\nThe source code for the book can be found at this Github repository",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "1  Getting started",
    "section": "",
    "text": "1.1 A first data analysis in R with a database\nArtwork by @allison_horst\nBefore we start thinking about working with health care data spread across a database using the OMOP common data model, let’s first do a quick data analysis from R using a simpler dataset held in a database to quickly understand the general approach. For this we’ll use data from palmerpenguins package, which contains data on penguins collected from the Palmer Station in Antarctica.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#getting-set-up",
    "href": "getting_started.html#getting-set-up",
    "title": "1  Getting started",
    "section": "1.2 Getting set up",
    "text": "1.2 Getting set up\nAssuming that you have R and RStudio already set up, first we need to install a few packages not included in base R if we don´t already have them.\n\ninstall.packages(\"dplyr\")\ninstall.packages(\"ggplot2\")\ninstall.packages(\"DBI\")\ninstall.packages(\"duckdb\")\ninstall.packages(\"palmerpenguins\")\n\nOnce installed, we can load them like so.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(DBI)\nlibrary(duckdb)\nlibrary(palmerpenguins)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#taking-a-peek-at-the-data",
    "href": "getting_started.html#taking-a-peek-at-the-data",
    "title": "1  Getting started",
    "section": "1.3 Taking a peek at the data",
    "text": "1.3 Taking a peek at the data\nWe can get an overview of the data using the glimpse() command.\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n$ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…\n\n\nOr we could take a look at the first rows of the data using head()\n\nhead(penguins, 5)\n\n# A tibble: 5 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#inserting-data-into-a-database",
    "href": "getting_started.html#inserting-data-into-a-database",
    "title": "1  Getting started",
    "section": "1.4 Inserting data into a database",
    "text": "1.4 Inserting data into a database\nLet’s put our penguins data into a duckdb database. We create the database, add the penguins data, and then create a reference to the table containing the data.\n\ndb &lt;- dbConnect(duckdb::duckdb(), dbdir = \":memory:\")\ndbWriteTable(db, \"penguins\", penguins)\npenguins_db &lt;- tbl(db, \"penguins\")\n\nWe can see that our database now has one table\n\nDBI::dbListTables(db)\n\n[1] \"penguins\"\n\n\nAnd now that the data is in a database we could use SQL to get the first rows that we saw before\n\ndbGetQuery(db, \"SELECT * FROM penguins LIMIT 5\")\n\n  species    island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n1  Adelie Torgersen           39.1          18.7               181        3750\n2  Adelie Torgersen           39.5          17.4               186        3800\n3  Adelie Torgersen           40.3          18.0               195        3250\n4  Adelie Torgersen             NA            NA                NA          NA\n5  Adelie Torgersen           36.7          19.3               193        3450\n     sex year\n1   male 2007\n2 female 2007\n3 female 2007\n4   &lt;NA&gt; 2007\n5 female 2007",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#translation-from-r-to-sql",
    "href": "getting_started.html#translation-from-r-to-sql",
    "title": "1  Getting started",
    "section": "1.5 Translation from R to SQL",
    "text": "1.5 Translation from R to SQL\nInstead of using SQL, we could instead use the same R code as before. Now it will query the data held in a database.\n\nhead(penguins_db, 5)\n\n# Source:   SQL [?? x 8]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/:memory:]\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nThe magic here is provided by the dbplyr which takes the R code and converts it into SQL, which in this case looks like the SQL we could have written instead.\n\nhead(penguins_db, 5) |&gt; \n  show_query()\n\n&lt;SQL&gt;\nSELECT penguins.*\nFROM penguins\nLIMIT 5\n\n\nMore complicated SQL can also be generated by using familiar dplyr code. For example, we could get a summary of bill length by species like so\n\npenguins_db |&gt;\n  group_by(species) |&gt;\n  summarise(\n    min_bill_length_mm = min(bill_length_mm),\n    median_bill_length_mm = median(bill_length_mm),\n    max_bill_length_mm = max(bill_length_mm)\n  ) |&gt;\n  mutate(min_max_bill_length_mm = paste0(\n    min_bill_length_mm,\n    \" to \",\n    max_bill_length_mm\n  )) |&gt;\n  select(\n    \"species\",\n    \"median_bill_length_mm\",\n    \"min_max_bill_length_mm\"\n  )\n\n# Source:   SQL [?? x 3]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/:memory:]\n  species   median_bill_length_mm min_max_bill_length_mm\n  &lt;fct&gt;                     &lt;dbl&gt; &lt;chr&gt;                 \n1 Adelie                     38.8 32.1 to 46.0          \n2 Chinstrap                  49.6 40.9 to 58.0          \n3 Gentoo                     47.3 40.9 to 59.6          \n\n\nThe benefit of using dbplyr now becomes quite clear if we take a look at the corresponding SQL that is generated for us.\n\npenguins_db |&gt;\n  group_by(species) |&gt;\n  summarise(\n    min_bill_length_mm = min(bill_length_mm),\n    median_bill_length_mm = median(bill_length_mm),\n    max_bill_length_mm = max(bill_length_mm)\n  ) |&gt;\n  mutate(min_max_bill_length_mm = paste0(min, \" to \", max)) |&gt;\n  select(\n    \"species\",\n    \"median_bill_length_mm\",\n    \"min_max_bill_length_mm\"\n  ) |&gt;\n  show_query()\n\n&lt;SQL&gt;\nSELECT\n  species,\n  median_bill_length_mm,\n  CONCAT_WS('', .Primitive(\"min\"), ' to ', .Primitive(\"max\")) AS min_max_bill_length_mm\nFROM (\n  SELECT\n    species,\n    MIN(bill_length_mm) AS min_bill_length_mm,\n    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY bill_length_mm) AS median_bill_length_mm,\n    MAX(bill_length_mm) AS max_bill_length_mm\n  FROM penguins\n  GROUP BY species\n) q01\n\n\nNow instead of having to write this somewhat complex SQL we can use the friendlier dplyr syntax that may well be more familiar if coming from an R programming background.\n\n\n\n\n\n\nDifferent SQL for different database management systems\n\n\n\n\n\nWhile using the SQL programming language allows us to process information in a relational database, there are a range of SQL dialects used with different database management systems. One particular benefit of using the above approach of translating R code to SQL via dbplyr is that the SQL generated will be in the appropriate dialect for the database management system being used. Here for example we can see how the same R code will generate different SQL for PosgreSQL compared to SQL Server.\n\npenguins |&gt;\n  dbplyr::lazy_frame(con = dbplyr::simulate_postgres()) |&gt;\n  mutate(\n    category = if_else(bill_length_mm &gt; 40 & bill_depth_mm &gt; 18,\n      \"big\", \"small\"\n    ),\n    date = as.Date(paste0(\"01-01-\", year))\n  ) |&gt;\n  show_query()\n\n&lt;SQL&gt;\nSELECT\n  `df`.*,\n  CASE WHEN (`bill_length_mm` &gt; 40.0 AND `bill_depth_mm` &gt; 18.0) THEN 'big' WHEN NOT (`bill_length_mm` &gt; 40.0 AND `bill_depth_mm` &gt; 18.0) THEN 'small' END AS `category`,\n  CAST(CONCAT_WS('', '01-01-', `year`) AS DATE) AS `date`\nFROM `df`\n\npenguins |&gt;\n  dbplyr::lazy_frame(con = dbplyr::simulate_mssql()) |&gt;\n  mutate(\n    category = if_else(bill_length_mm &gt; 40 & bill_depth_mm &gt; 18,\n      \"big\", \"small\"\n    ),\n    date = as.Date(paste0(\"01-01-\", year))\n  ) |&gt;\n  show_query()\n\n&lt;SQL&gt;\nSELECT\n  `df`.*,\n  IIF(`bill_length_mm` &gt; 40.0 AND `bill_depth_mm` &gt; 18.0, 'big', 'small') AS `category`,\n  TRY_CAST('01-01-' + `year` AS DATE) AS `date`\nFROM `df`",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#example-analysis",
    "href": "getting_started.html#example-analysis",
    "title": "1  Getting started",
    "section": "1.6 Example analysis",
    "text": "1.6 Example analysis\nTo see a little more how this approach will work in practice for perfoming a data analysis, let´s start by getting a count by species\n\npenguins_db |&gt; \n  group_by(species) |&gt; \n  count()\n\n# Source:   SQL [?? x 2]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/:memory:]\n# Groups:   species\n  species       n\n  &lt;fct&gt;     &lt;dbl&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nNow suppose we are particularly interested in the body mass variable. We can first notice that there are a couple of missing records for this.\n\npenguins_db |&gt;\n  mutate(missing_body_mass_g = if_else(\n    is.na(body_mass_g), 1, 0\n  )) |&gt;\n  group_by(species, missing_body_mass_g) |&gt;\n  tally()\n\n# Source:   SQL [?? x 3]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/:memory:]\n  species   missing_body_mass_g     n\n  &lt;fct&gt;                   &lt;dbl&gt; &lt;dbl&gt;\n1 Gentoo                      0   123\n2 Chinstrap                   0    68\n3 Adelie                      0   151\n4 Adelie                      1     1\n5 Gentoo                      1     1\n\n\nWe can get the mean for each of the species (dropping those two missing records).\n\npenguins_db |&gt;\n  group_by(species) |&gt;\n  summarise(mean_body_mass_g = round(mean(body_mass_g, na.rm = TRUE), 1))\n\n# Source:   SQL [?? x 2]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/:memory:]\n  species   mean_body_mass_g\n  &lt;fct&gt;                &lt;dbl&gt;\n1 Adelie               3701.\n2 Chinstrap            3733.\n3 Gentoo               5076 \n\n\nWe could also make a histogram of values for each of the species.\n\npenguins_db |&gt;\n  collect() |&gt;\n  ggplot(aes(group = species, fill = species)) +\n  facet_grid(species ~ .) +\n  geom_histogram(aes(body_mass_g), colour = \"black\", binwidth = 100) +\n  xlab(\"Body mass (g)\") +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChoosing the right time to collect\n\n\n\n\n\ncollect() brings data out of the database and into R. Above we use it to bring the entire penguins data back into R so that we can then use ggplot() to make our histogram.\nWhen working with large data sets, as is often the case when interacting with a database, we typically want to keep as much computation as possible on the database side, up until the point we need to bring the data out for further analysis steps that are not possible using SQL. This could be like the case above for plotting, but could also be for other analytic steps like fitting statistical models. In such cases it is important that we only bring out the required data for this task as we will likely have much less memory available on our local computer than is available for the database.\n\n\n\nNow let’s look at the relationship between body mass and bill depth.\n\npenguins |&gt;\n  collect() |&gt;\n  ggplot(aes(x = bill_depth_mm, y = body_mass_g)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  xlab(\"Bill depth (mm)\") +\n  ylab(\"Body mass (g)\") +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nHere we see a negative correlation between body mass and bill depth which seems rather unexpected. But what about if we stratify this query by species?\n\npenguins |&gt;\n  collect() |&gt;\n  ggplot(aes(x = bill_depth_mm, y = body_mass_g)) +\n  facet_grid(species ~ .) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  xlab(\"Bill depth (mm)\") +\n  ylab(\"Body mass (g)\") +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nAs well as having an example of working with data in database from R, you also have an example of Simpson´s paradox!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#disconnecting-from-the-database",
    "href": "getting_started.html#disconnecting-from-the-database",
    "title": "1  Getting started",
    "section": "1.7 Disconnecting from the database",
    "text": "1.7 Disconnecting from the database\nAnd now we’ve reached the end of this example, we can close our connection to the database.\n\ndbDisconnect(db)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#further-reading",
    "href": "getting_started.html#further-reading",
    "title": "1  Getting started",
    "section": "1.8 Further reading",
    "text": "1.8 Further reading\n\nR for Data Science (Chapter 13: Relational data)\nWriting SQL with dbplyr\nData Carpentry: SQL databases and R",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting started</span>"
    ]
  },
  {
    "objectID": "explore.html",
    "href": "explore.html",
    "title": "Getting to know the OMOP CDM",
    "section": "",
    "text": "The OMOP CDM standardises the format and content of health care data.\n\nIn 2  Creating a reference to data in the OMOP CDM we will see how we will see how to create a reference in R to each of these OMOP CDM tables. Because we already know the structure of our data, creating this reference to the various tables will be our first step in our analysis scripts.\nThe OMOP CDM is a person-centric model, and the person and observation period tables are two key tables for any analysis. In 3  Person we will see more on how these tables can be used as the starting point for identifying your study participants.\nThe OMOP CDM standarises the content of health care data via the OMOP CDM vocabulary tables, which provides a set of standard concepts to represent different clinical events. The vocabulary tables are described in 4  Working with the OMOP CDM vocabularies, with these tables playing a fundamental role when we identify the clinical events of interest for our study.\nClinical records associated with individuals are spread across various OMOP CDM tables, covering various domains. In 5  Working with the OMOP CDM clinical tables we will see how these tables represent events and link back to the person and vocabulary tables.",
    "crumbs": [
      "Getting to know the OMOP CDM"
    ]
  },
  {
    "objectID": "cdm_reference.html",
    "href": "cdm_reference.html",
    "title": "2  Creating a reference to data in the OMOP CDM",
    "section": "",
    "text": "2.1 Connecting to a database from R using DBI\nAn entity-relationship diagram for version 5.4 of the OMOP CDM is shown below.\nDatabase connections from R can be made using the DBI package. The back-end for DBI is facilitated by database specific driver packages. We saw in Chapter 1 an example where we created a new, empty, in-process duckdb database which we then added database. But we could have instead connected to an existing duckdb database. This could, for example, look like\nlibrary(DBI)\nlibrary(here)\nlibrary(dplyr)\ndb &lt;- dbConnect(duckdb::duckdb(), \n              dbdir = here(\"my_duckdb_database.ducdkb\"))\nFor other database management systems, creating connections would be supported by the associated back-end packages. For example a connection to a Postgres database would look something like:\ndb &lt;- DBI::dbConnect(RPostgres::Postgres(),\n                      dbname = Sys.getenv(\"CDM5_POSTGRESQL_DBNAME\"),\n                      host = Sys.getenv(\"CDM5_POSTGRESQL_HOST\"),\n                      user = Sys.getenv(\"CDM5_POSTGRESQL_USER\"),\n                      password = Sys.getenv(\"CDM5_POSTGRESQL_PASSWORD\"))",
    "crumbs": [
      "Getting to know the OMOP CDM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating a reference to data in the OMOP CDM</span>"
    ]
  },
  {
    "objectID": "cdm_reference.html#referencing-tables-from-the-omop-common-data-model",
    "href": "cdm_reference.html#referencing-tables-from-the-omop-common-data-model",
    "title": "2  Creating a reference to data in the OMOP CDM",
    "section": "2.2 Referencing tables from the OMOP common data model",
    "text": "2.2 Referencing tables from the OMOP common data model\nAs seen in the previous chapter, once a connection to the database has been created we can then create references to the various tables in the database and build queries using in a familiar dplyr style. To show this, let’s download an example dataset (synthea-covid19-10k) provided by CDMConnector.\nNow we have this downloaded, we can create a connection to a duckdb database containing the data in a similar way to how we’ve done before.\n\ndb &lt;- dbConnect(\n  duckdb::duckdb(), \n  dbdir = CDMConnector::eunomiaDir(datasetName = \"synthea-covid19-10k\"))\n\ndb |&gt; \n  tbl(\"person\")\n\n# Source:   table&lt;person&gt; [?? x 18]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMMdkc\\file5330d56293e.duckdb]\n   person_id gender_concept_id year_of_birth month_of_birth day_of_birth\n       &lt;int&gt;             &lt;int&gt;         &lt;int&gt;          &lt;int&gt;        &lt;int&gt;\n 1         1              8532          1970              4           24\n 2         2              8532          1929              3           18\n 3         3              8532          1970              4            4\n 4         4              8507          1966              2           26\n 5         5              8532          1936              6           10\n 6         6              8507          1996              5           29\n 7         7              8507          1923             11           14\n 8         8              8507          2018              8           20\n 9         9              8532          1933              2           11\n10        10              8507          2010              3            7\n# ℹ more rows\n# ℹ 13 more variables: birth_datetime &lt;dttm&gt;, race_concept_id &lt;int&gt;,\n#   ethnicity_concept_id &lt;int&gt;, location_id &lt;int&gt;, provider_id &lt;int&gt;,\n#   care_site_id &lt;int&gt;, person_source_value &lt;chr&gt;, gender_source_value &lt;chr&gt;,\n#   gender_source_concept_id &lt;int&gt;, race_source_value &lt;chr&gt;,\n#   race_source_concept_id &lt;int&gt;, ethnicity_source_value &lt;chr&gt;,\n#   ethnicity_source_concept_id &lt;int&gt;\n\ndb |&gt; \n  tbl(\"observation_period\")\n\n# Source:   table&lt;observation_period&gt; [?? x 5]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMMdkc\\file5330d56293e.duckdb]\n   observation_period_id person_id observation_period_s…¹ observation_period_e…²\n                   &lt;int&gt;     &lt;int&gt; &lt;date&gt;                 &lt;date&gt;                \n 1                     1         1 2014-05-09             2023-05-12            \n 2                     2         2 1977-04-11             1986-09-15            \n 3                     3         3 2014-04-19             2023-04-22            \n 4                     4         4 2014-03-22             2023-04-08            \n 5                     5         5 2013-11-13             2023-01-04            \n 6                     6         6 2013-07-17             2021-08-04            \n 7                     7         7 2013-06-26             2022-08-17            \n 8                     8         8 2018-08-20             2022-07-25            \n 9                     9         9 2013-08-03             2022-09-24            \n10                    10        10 2013-08-11             2023-04-02            \n# ℹ more rows\n# ℹ abbreviated names: ¹​observation_period_start_date,\n#   ²​observation_period_end_date\n# ℹ 1 more variable: period_type_concept_id &lt;int&gt;\n\n\nWe could also perform similar queries to those seen in chapter 1, but this time working with the patient-level, rather than penguin-level, data.\n\ndb |&gt; \n  tbl(\"person\") |&gt; \n  group_by(year_of_birth) |&gt; \n  count() \n\n# Source:   SQL [?? x 2]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMMdkc\\file5330d56293e.duckdb]\n# Groups:   year_of_birth\n   year_of_birth     n\n           &lt;int&gt; &lt;dbl&gt;\n 1          1923    66\n 2          1924   123\n 3          1925   140\n 4          1926   146\n 5          1927   162\n 6          1928   136\n 7          1929   146\n 8          1930   119\n 9          1931   135\n10          1932   142\n# ℹ more rows",
    "crumbs": [
      "Getting to know the OMOP CDM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating a reference to data in the OMOP CDM</span>"
    ]
  },
  {
    "objectID": "cdm_reference.html#creating-a-reference-to-the-omop-common-data-model",
    "href": "cdm_reference.html#creating-a-reference-to-the-omop-common-data-model",
    "title": "2  Creating a reference to data in the OMOP CDM",
    "section": "2.3 Creating a reference to the OMOP common data model",
    "text": "2.3 Creating a reference to the OMOP common data model\nAs the structure of the OMOP CDM is already known, we can avoid the overhead of creating individual references to the OMOP CDM tables like above by instead creating a joint reference for all OMOP CDM database tables in one go.\nThe R object representing OMOP CDM data is defined by the omopgenerics package), with the the CDMConnector package providing a means of connecting to a OMOP CDM data held in a database. As well as specifying the schema containing our OMOP CDM tables, we also specify a write schema where any database tables we create during our analysis will be stored (often our OMOP CDM tables will be in a schema that we only have read-access to and we’ll have another schema where we can have write-access where we intermediate tables are created for a given a study).\n\nlibrary(omopgenerics)\n\nWarning: package 'omopgenerics' was built under R version 4.4.2\n\n\n\nAttaching package: 'omopgenerics'\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nlibrary(CDMConnector)\n\n\nAttaching package: 'CDMConnector'\n\n\nThe following objects are masked from 'package:omopgenerics':\n\n    cdmName, recordCohortAttrition, uniqueTableName\n\ncdm &lt;- cdmFromCon(con = db,\n                  cdmSchema = \"main\", \n                  writeSchema = \"main\", \n                  cdmName = \"Synthea Covid-19 data\")\n\nNote: method with signature 'DBIConnection#Id' chosen for function 'dbExistsTable',\n target signature 'duckdb_connection#Id'.\n \"duckdb_connection#ANY\" would also be valid\n\ncdm\n\n\n\n\n── # OMOP CDM reference (duckdb) of Synthea Covid-19 data ──────────────────────\n\n\n• omop tables: person, observation_period, visit_occurrence, visit_detail,\ncondition_occurrence, drug_exposure, procedure_occurrence, device_exposure,\nmeasurement, observation, death, note, note_nlp, specimen, fact_relationship,\nlocation, care_site, provider, payer_plan_period, cost, drug_era, dose_era,\ncondition_era, metadata, cdm_source, concept, vocabulary, domain,\nconcept_class, concept_relationship, relationship, concept_synonym,\nconcept_ancestor, source_to_concept_map, drug_strength, cohort_definition,\nattribute_definition\n\n\n• cohort tables: -\n\n\n• achilles tables: -\n\n\n• other tables: -\n\n\n\n\n\n\n\n\nSetting a write prefix\n\n\n\n\n\nWe can also specify a write prefix and this will be used whenever permanent tables are created the write schema. This can be useful when we’re sharing our write schema with others and want to avoid table name conflicts and easily drop tables created as part of a particular study.\n\ncdm &lt;- cdmFromCon(con = db,\n                  cdmSchema = \"main\", \n                  writeSchema = \"main\", \n                  writePrefix = \"my_study_\",\n                  cdmName = \"Synthea Covid-19 data\")\n\n\n\n\nWe can see that we now have an object that contains references to all the OMOP CDM tables. We can reference specific tables using the “$” or “[[ … ]]” operators.\n\ncdm$person\n\n# Source:   table&lt;main.person&gt; [?? x 18]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMMdkc\\file5330d56293e.duckdb]\n   person_id gender_concept_id year_of_birth month_of_birth day_of_birth\n       &lt;int&gt;             &lt;int&gt;         &lt;int&gt;          &lt;int&gt;        &lt;int&gt;\n 1         1              8532          1970              4           24\n 2         2              8532          1929              3           18\n 3         3              8532          1970              4            4\n 4         4              8507          1966              2           26\n 5         5              8532          1936              6           10\n 6         6              8507          1996              5           29\n 7         7              8507          1923             11           14\n 8         8              8507          2018              8           20\n 9         9              8532          1933              2           11\n10        10              8507          2010              3            7\n# ℹ more rows\n# ℹ 13 more variables: birth_datetime &lt;dttm&gt;, race_concept_id &lt;int&gt;,\n#   ethnicity_concept_id &lt;int&gt;, location_id &lt;int&gt;, provider_id &lt;int&gt;,\n#   care_site_id &lt;int&gt;, person_source_value &lt;chr&gt;, gender_source_value &lt;chr&gt;,\n#   gender_source_concept_id &lt;int&gt;, race_source_value &lt;chr&gt;,\n#   race_source_concept_id &lt;int&gt;, ethnicity_source_value &lt;chr&gt;,\n#   ethnicity_source_concept_id &lt;int&gt;\n\ncdm[[\"observation_period\"]]\n\n# Source:   table&lt;main.observation_period&gt; [?? x 5]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMMdkc\\file5330d56293e.duckdb]\n   observation_period_id person_id observation_period_s…¹ observation_period_e…²\n                   &lt;int&gt;     &lt;int&gt; &lt;date&gt;                 &lt;date&gt;                \n 1                     1         1 2014-05-09             2023-05-12            \n 2                     2         2 1977-04-11             1986-09-15            \n 3                     3         3 2014-04-19             2023-04-22            \n 4                     4         4 2014-03-22             2023-04-08            \n 5                     5         5 2013-11-13             2023-01-04            \n 6                     6         6 2013-07-17             2021-08-04            \n 7                     7         7 2013-06-26             2022-08-17            \n 8                     8         8 2018-08-20             2022-07-25            \n 9                     9         9 2013-08-03             2022-09-24            \n10                    10        10 2013-08-11             2023-04-02            \n# ℹ more rows\n# ℹ abbreviated names: ¹​observation_period_start_date,\n#   ²​observation_period_end_date\n# ℹ 1 more variable: period_type_concept_id &lt;int&gt;",
    "crumbs": [
      "Getting to know the OMOP CDM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating a reference to data in the OMOP CDM</span>"
    ]
  },
  {
    "objectID": "cdm_reference.html#cdm-attributes",
    "href": "cdm_reference.html#cdm-attributes",
    "title": "2  Creating a reference to data in the OMOP CDM",
    "section": "2.4 CDM attributes",
    "text": "2.4 CDM attributes\n\n2.4.1 CDM name\nOur cdm reference will be associated with a name. By default this name will be taken from the cdm source name field from the cdm source table. We can though set this to a different name when creating our cdm reference. This cdm name attribute of our reference is particularly useful in the context of network studies to keep track of which results are associated with which database.\n\ncdm &lt;- cdmFromCon(db,\n  cdmSchema = \"main\", \n  writeSchema = \"main\")\ncdm$cdm_source\n\n# Source:   table&lt;main.cdm_source&gt; [?? x 10]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMMdkc\\file5330d56293e.duckdb]\n  cdm_source_name cdm_source_abbreviation cdm_holder source_description    \n  &lt;chr&gt;           &lt;chr&gt;                   &lt;chr&gt;      &lt;chr&gt;                 \n1 Synthea         Synthea                 \"\"         Synthea Synthetic Data\n# ℹ 6 more variables: source_documentation_reference &lt;chr&gt;,\n#   cdm_etl_reference &lt;chr&gt;, source_release_date &lt;date&gt;,\n#   cdm_release_date &lt;date&gt;, cdm_version &lt;chr&gt;, vocabulary_version &lt;chr&gt;\n\ncdmName(cdm)\n\n[1] \"Synthea\"\n\ncdm &lt;- cdmFromCon(db,\n  cdmSchema = \"main\", \n  writeSchema = \"main\", \n  cdmName = \"my_cdm\")\ncdmName(cdm)\n\n[1] \"my_cdm\"\n\n\n\n\n2.4.2 CDM version\nWe can also easily check the OMOP CDM version that is being used\n\ncdmVersion(cdm)\n\n[1] \"5.3\"\n\n\n\n\n2.4.3 CDM Source\nAlthough typically we won’t need to use them for writing study code, we can also access lower-level information on the source, such as the database connection.\n\nattr(cdmSource(cdm), \"dbcon\")\n\n&lt;duckdb_connection ce6e0 driver=&lt;duckdb_driver dbdir='C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpCMMdkc\\file5330d56293e.duckdb' read_only=FALSE bigint=numeric&gt;&gt;",
    "crumbs": [
      "Getting to know the OMOP CDM",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Creating a reference to data in the OMOP CDM</span>"
    ]
  },
  {
    "objectID": "omop_person_obs_period.html",
    "href": "omop_person_obs_period.html",
    "title": "3  Person",
    "section": "",
    "text": "3.1 Person table",
    "crumbs": [
      "Getting to know the OMOP CDM",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Person</span>"
    ]
  },
  {
    "objectID": "omop_person_obs_period.html#observation-period-table",
    "href": "omop_person_obs_period.html#observation-period-table",
    "title": "3  Person",
    "section": "3.2 Observation period table",
    "text": "3.2 Observation period table",
    "crumbs": [
      "Getting to know the OMOP CDM",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Person</span>"
    ]
  },
  {
    "objectID": "exploring_the_cdm.html",
    "href": "exploring_the_cdm.html",
    "title": "6  Exploring the OMOP CDM",
    "section": "",
    "text": "6.1 Counting people\nFor this chapter, lets again use the synthetic Covid-19 dataset.\nThe OMOP CDM is person-centric, with the person table containing records to uniquely identify each person in the database. As each row refers to a unique person, we can quickly get a count of the number of individuals in the database like so\ncdm$person |&gt; \n  count()\n\n# Source:   SQL [?? x 1]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp2JzmkJ\\file7744d34138b.duckdb]\n      n\n  &lt;dbl&gt;\n1 10754\nThe person table also contains some demographic information, including a gender concept for each person. We can get a count grouped by this variable, but as this uses a concept we’ll also need to join to the concept table to get the corresponding concept name for each concept id.\ncdm$person |&gt; \n  group_by(gender_concept_id) |&gt; \n  count() |&gt; \n  left_join(cdm$concept, \n            by=c(\"gender_concept_id\" = \"concept_id\")) |&gt; \n              select(\"gender_concept_id\", \"concept_name\", \"n\") |&gt; \n  collect()\n\n# A tibble: 2 × 3\n# Groups:   gender_concept_id [2]\n  gender_concept_id concept_name     n\n              &lt;int&gt; &lt;chr&gt;        &lt;dbl&gt;\n1              8532 FEMALE        5165\n2              8507 MALE          5589\nThe observation period table contains records indicating spans of time over which clinical events can be reliably observed for the people in the person table. Someone can potentially have multiple observation periods. So say we wanted a count of people grouped by the year during which their first observation period started. We could do this like so:\nfirst_observation_period &lt;- cdm$observation_period |&gt;\n    group_by(person_id) |&gt; \n    filter(row_number() == 1) |&gt; \n    compute()\n\ncdm$person |&gt; \n  left_join(first_observation_period,\n            by = \"person_id\") |&gt; \n  mutate(observation_period_start_year = get_year(observation_period_start_date)) |&gt; \n  group_by(observation_period_start_year) |&gt; \n  count() |&gt; \n  collect() |&gt; \n  ggplot() +\n  geom_col(aes(observation_period_start_year, n)) +\n  theme_bw()",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Exploring the OMOP CDM</span>"
    ]
  },
  {
    "objectID": "exploring_the_cdm.html#counting-people",
    "href": "exploring_the_cdm.html#counting-people",
    "title": "6  Exploring the OMOP CDM",
    "section": "",
    "text": "Computing intermediate queries\n\n\n\n\n\nThe compute() function will force the computation of a query (by default to a temporary table in the database). In the example above we use it to split up two queries; the first to keep the first observation period record for each individual.\n\ncdm$observation_period |&gt;\n    group_by(person_id) |&gt; \n    filter(row_number() == 1) |&gt; \n    show_query()\n\n&lt;SQL&gt;\nSELECT\n  observation_period_id,\n  person_id,\n  observation_period_start_date,\n  observation_period_end_date,\n  period_type_concept_id\nFROM (\n  SELECT\n    observation_period.*,\n    ROW_NUMBER() OVER (PARTITION BY person_id) AS col01\n  FROM main.observation_period\n) q01\nWHERE (col01 = 1.0)\n\n\nFollowed by a second query that left joins the person table with the result from the first (which is now in a temporary table), followed by extracted the year in which peoples first observation period starts and then, finally, a count by year.\n\ncdm$person |&gt; \n  left_join(first_observation_period,\n            by = \"person_id\") |&gt; \n  mutate(observation_period_start_year=year(observation_period_start_date)) |&gt; \n  group_by(observation_period_start_year) |&gt; \n  count() |&gt; \n  show_query()\n\n&lt;SQL&gt;\nSELECT observation_period_start_year, COUNT(*) AS n\nFROM (\n  SELECT\n    q01.*,\n    EXTRACT(year FROM observation_period_start_date) AS observation_period_start_year\n  FROM (\n    SELECT\n      person.*,\n      observation_period_id,\n      observation_period_start_date,\n      observation_period_end_date,\n      period_type_concept_id\n    FROM main.person\n    LEFT JOIN og_001_1735312303\n      ON (person.person_id = og_001_1735312303.person_id)\n  ) q01\n) q01\nGROUP BY observation_period_start_year\n\n\nWe could, however, have done this without compute, with instead the SQL being done all at once.\n\ncdm$person |&gt; \n  left_join(cdm$observation_period |&gt;\n    group_by(person_id) |&gt; \n    filter(row_number() == 1),\n            by = \"person_id\") |&gt; \n  mutate(observation_period_start_year=year(observation_period_start_date)) |&gt; \n  group_by(observation_period_start_year) |&gt; \n  count() |&gt; \n  show_query()\n\n&lt;SQL&gt;\nSELECT observation_period_start_year, COUNT(*) AS n\nFROM (\n  SELECT\n    q01.*,\n    EXTRACT(year FROM observation_period_start_date) AS observation_period_start_year\n  FROM (\n    SELECT\n      person.*,\n      observation_period_id,\n      observation_period_start_date,\n      observation_period_end_date,\n      period_type_concept_id\n    FROM main.person\n    LEFT JOIN (\n      SELECT\n        observation_period_id,\n        person_id,\n        observation_period_start_date,\n        observation_period_end_date,\n        period_type_concept_id\n      FROM (\n        SELECT\n          observation_period.*,\n          ROW_NUMBER() OVER (PARTITION BY person_id) AS col01\n        FROM main.observation_period\n      ) q01\n      WHERE (col01 = 1.0)\n    ) RHS\n      ON (person.person_id = RHS.person_id)\n  ) q01\n) q01\nGROUP BY observation_period_start_year\n\n\nIn this case the SQL is not much more complicated than before. However, you can imagine that without using computation to intermediate tables, the SQL associated with a series of data manipulations could quickly become unmanageable. Although we don’t want to overuse computation of intermediate queries, it is often a necessity when writing study analysis scripts.\nA particular advantage of computing a query, is that we can then use the result for multiple subsequent queries. For example, say we want a count of condition occurrence and drug exposure records for those born before 1970. We could get these counts independently:\n\ncdm$person |&gt; \n  filter(year_of_birth &lt; \"1970\") |&gt; \n  select(\"person_id\") |&gt; \n  left_join(cdm$condition_occurrence,\n            by=\"person_id\") |&gt; \n  tally()\n\n# Source:   SQL [?? x 1]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp2JzmkJ\\file7744d34138b.duckdb]\n      n\n  &lt;dbl&gt;\n1  9305\n\ncdm$person |&gt; \n  filter(year_of_birth &lt; \"1970\") |&gt; \n  select(\"person_id\") |&gt; \n  left_join(cdm$drug_exposure,\n            by=\"person_id\") |&gt; \n  tally()\n\n# Source:   SQL [?? x 1]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp2JzmkJ\\file7744d34138b.duckdb]\n       n\n   &lt;dbl&gt;\n1 165681\n\n\nBut we could have instead first subsetted the person table and then used the result for both queries.\n\ncdm$person_pre_1970 &lt;- cdm$person |&gt; \n  filter(year_of_birth &lt; \"1970\") |&gt; \n  compute()\n\ncdm$person_pre_1970 |&gt; \n  select(\"person_id\") |&gt; \n  left_join(cdm$condition_occurrence,\n            by=\"person_id\") |&gt; \n  tally()\n\n# Source:   SQL [?? x 1]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp2JzmkJ\\file7744d34138b.duckdb]\n      n\n  &lt;dbl&gt;\n1  9305\n\ncdm$person_pre_1970 |&gt; \n  select(\"person_id\") |&gt; \n  left_join(cdm$drug_exposure,\n            by=\"person_id\") |&gt; \n  tally()\n\n# Source:   SQL [?? x 1]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp2JzmkJ\\file7744d34138b.duckdb]\n       n\n   &lt;dbl&gt;\n1 165681",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Exploring the OMOP CDM</span>"
    ]
  },
  {
    "objectID": "exploring_the_cdm.html#counting-records",
    "href": "exploring_the_cdm.html#counting-records",
    "title": "6  Exploring the OMOP CDM",
    "section": "6.2 Counting records",
    "text": "6.2 Counting records\nWhat’s the number of condition occurrence records per person in the database? We can find this out like so\n\ncdm$person |&gt; \n  left_join(cdm$condition_occurrence |&gt; \n  group_by(person_id) |&gt; \n  count(name = \"condition_occurrence_records\"),\n  by=\"person_id\") |&gt; \n  mutate(condition_occurrence_records = if_else(\n    is.na(condition_occurrence_records), 0,\n    condition_occurrence_records)) |&gt; \n  group_by(condition_occurrence_records) |&gt;\n  count() |&gt; \n  collect() |&gt; \n  ggplot() +\n  geom_col(aes(condition_occurrence_records, n)) +\n  theme_bw()\n\n\n\n\n\n\n\n\nHow about we were interested in getting record counts for some specific concepts related to Covid-19 symptoms?\n\ncdm$condition_occurrence |&gt; \n  filter(condition_concept_id %in% c(437663,437390,31967,\n                                     4289517,4223659, 312437,\n                                     434490,254761,77074)) |&gt; \n  group_by(condition_concept_id) |&gt; \n  count() |&gt; \n  left_join(cdm$concept,\n            by=c(\"condition_concept_id\" = \"concept_id\")) |&gt; \n  collect() |&gt; \n  ggplot() +\n  geom_col(aes(concept_name, n)) +\n  theme_bw()+\n  xlab(\"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVocabulary tables\n\n\n\n\n\nAbove we’ve got counts by specific concept IDs recorded in the condition occurrence table. What these IDs represent is described in the concept table. Here we have the name associated with the concept, along with other information such as it’s domain and vocabulary id.\n\ncdm$concept |&gt; \n  glimpse()\n\nRows: ??\nColumns: 10\nDatabase: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp2JzmkJ\\file7744d34138b.duckdb]\n$ concept_id       &lt;int&gt; 45756805, 45756804, 45756803, 45756802, 45756801, 457…\n$ concept_name     &lt;chr&gt; \"Pediatric Cardiology\", \"Pediatric Anesthesiology\", \"…\n$ domain_id        &lt;chr&gt; \"Provider\", \"Provider\", \"Provider\", \"Provider\", \"Prov…\n$ vocabulary_id    &lt;chr&gt; \"ABMS\", \"ABMS\", \"ABMS\", \"ABMS\", \"ABMS\", \"ABMS\", \"ABMS…\n$ concept_class_id &lt;chr&gt; \"Physician Specialty\", \"Physician Specialty\", \"Physic…\n$ standard_concept &lt;chr&gt; \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\"…\n$ concept_code     &lt;chr&gt; \"OMOP4821938\", \"OMOP4821939\", \"OMOP4821940\", \"OMOP482…\n$ valid_start_date &lt;date&gt; 1970-01-01, 1970-01-01, 1970-01-01, 1970-01-01, 1970…\n$ valid_end_date   &lt;date&gt; 2099-12-31, 2099-12-31, 2099-12-31, 2099-12-31, 2099…\n$ invalid_reason   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\n\nOther vocabulary tables capture other information about concepts, such as the direct relationships between concepts (the concept relationship table) and hierarchical relationships between (the concept ancestor table).\n\ncdm$concept_relationship |&gt; \n  glimpse()\n\nRows: ??\nColumns: 6\nDatabase: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp2JzmkJ\\file7744d34138b.duckdb]\n$ concept_id_1     &lt;int&gt; 35804314, 35804314, 35804314, 35804327, 35804327, 358…\n$ concept_id_2     &lt;int&gt; 912065, 42542145, 42542145, 35803584, 42542145, 42542…\n$ relationship_id  &lt;chr&gt; \"Has modality\", \"Has accepted use\", \"Is current in\", …\n$ valid_start_date &lt;date&gt; 2021-01-26, 2019-08-29, 2019-08-29, 2019-05-27, 2019…\n$ valid_end_date   &lt;date&gt; 2099-12-31, 2099-12-31, 2099-12-31, 2099-12-31, 2099…\n$ invalid_reason   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n\ncdm$concept_ancestor |&gt; \n  glimpse()\n\nRows: ??\nColumns: 4\nDatabase: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp2JzmkJ\\file7744d34138b.duckdb]\n$ ancestor_concept_id      &lt;int&gt; 375415, 727760, 735979, 438112, 529411, 14196…\n$ descendant_concept_id    &lt;int&gt; 4335743, 2056453, 41070383, 36566114, 4326940…\n$ min_levels_of_separation &lt;int&gt; 4, 1, 3, 2, 3, 3, 4, 3, 2, 5, 1, 3, 4, 2, 2, …\n$ max_levels_of_separation &lt;int&gt; 4, 1, 5, 3, 3, 6, 12, 3, 2, 10, 1, 3, 4, 2, 2…\n\n\nMore information on the vocabulary tables (as well as other tables in the OMOP CDM version 5.3) can be found at https://ohdsi.github.io/CommonDataModel/cdm53.html#Vocabulary_Tables.",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Exploring the OMOP CDM</span>"
    ]
  },
  {
    "objectID": "exploring_the_cdm.html#working-with-dates",
    "href": "exploring_the_cdm.html#working-with-dates",
    "title": "6  Exploring the OMOP CDM",
    "section": "6.3 Working with dates",
    "text": "6.3 Working with dates\nWhen working with dates, the best supported functions come from the clock package. In particular, a lot of the date manipulations we might be interested in can be achieved through the use of add_days (to add days to or subtract days from a date), add_years (same as add_days by with years as the timescale), and date_count_between (to get the difference between two dates). For example let’s see how these can be applied to date fields in the observation period table.\n\nlibrary(clock)\nlibrary(ggplot2)\n\ncdm$observation_period |&gt; \n  mutate(observation_period_start_plus_30_days = \n           add_days(observation_period_start_date, 30L),\n         observation_period_start_date_plus_10_years = \n           add_years(observation_period_start_date, 10L)) |&gt; \n  glimpse()\n\nRows: ??\nColumns: 7\nDatabase: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp2JzmkJ\\file7744d34138b.duckdb]\n$ observation_period_id                       &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9,…\n$ person_id                                   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9,…\n$ observation_period_start_date               &lt;date&gt; 2014-05-09, 1977-04-11, 2…\n$ observation_period_end_date                 &lt;date&gt; 2023-05-12, 1986-09-15, 2…\n$ period_type_concept_id                      &lt;int&gt; 44814724, 44814724, 448147…\n$ observation_period_start_plus_30_days       &lt;dttm&gt; 2014-06-08, 1977-05-11, 2…\n$ observation_period_start_date_plus_10_years &lt;dttm&gt; 2024-05-09, 1987-04-11, 2…\n\ncdm$observation_period |&gt; \n  dplyr::mutate(observation_days = date_count_between(\"observation_period_start_date\", \n                             \"observation_period_end_date\", \"day\"))  |&gt; \n  dplyr::mutate(observation_years = observation_days/ 365.25) |&gt; \n  collect() |&gt; \n  ggplot() +\n  geom_histogram(aes(observation_years), \n                 binwidth=2, colour=\"grey\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPiping and SQL\n\n\n\n\n\nAlthough piping queries has little impact on performance when using R with data in memory, when working with a database the SQL generated will differ when using multiple function calls (with a separate operation specified in each) instead of multiple operations within a single function call.\nFor example, a single mutate function above would generate the below SQL.\n\ncdm$observation_period |&gt; \n  mutate(observation_period_start_plus_30_days = \n                add_days(observation_period_start_date, 30L),\n         observation_period_start_date_plus_10_years = \n                add_years(observation_period_start_date, 10L)) |&gt; \n  select(\"observation_period_id\", \"person_id\", \n         \"observation_period_start_plus_30_days\",\n         \"observation_period_start_date_plus_10_years\") |&gt; \n  show_query()\n\n&lt;SQL&gt;\nSELECT\n  observation_period_id,\n  person_id,\n  DATE_ADD(observation_period_start_date, INTERVAL '30 day') AS observation_period_start_plus_30_days,\n  DATE_ADD(observation_period_start_date, INTERVAL '10 year') AS observation_period_start_date_plus_10_years\nFROM main.observation_period\n\n\nWhereas the SQL will be different if using multiple mutate calls (now using a sub-query).\n\ncdm$observation_period |&gt; \n  mutate(observation_period_start_plus_30_days = \n               add_days(observation_period_start_date, 30L)) |&gt; \n  mutate(observation_period_start_date_plus_10_years = \n               add_years(observation_period_start_date, 10L)) |&gt; \n  select(\"observation_period_id\", \"person_id\", \n         \"observation_period_start_plus_30_days\",\n         \"observation_period_start_date_plus_10_years\") |&gt; \n  show_query()\n\n&lt;SQL&gt;\nSELECT\n  observation_period_id,\n  person_id,\n  observation_period_start_plus_30_days,\n  DATE_ADD(observation_period_start_date, INTERVAL '10 year') AS observation_period_start_date_plus_10_years\nFROM (\n  SELECT\n    observation_period.*,\n    DATE_ADD(observation_period_start_date, INTERVAL '30 day') AS observation_period_start_plus_30_days\n  FROM main.observation_period\n) q01",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Exploring the OMOP CDM</span>"
    ]
  },
  {
    "objectID": "exploring_the_cdm.html#statistical-summaries",
    "href": "exploring_the_cdm.html#statistical-summaries",
    "title": "6  Exploring the OMOP CDM",
    "section": "6.4 Statistical summaries",
    "text": "6.4 Statistical summaries\nWe can also use summarise for various other calculations\n\ncdm$person |&gt; \n  summarise(min_year_of_birth = min(year_of_birth, na.rm=TRUE),\n            q05_year_of_birth = quantile(year_of_birth, 0.05, na.rm=TRUE),\n            mean_year_of_birth = round(mean(year_of_birth, na.rm=TRUE),0),\n            median_year_of_birth = median(year_of_birth, na.rm=TRUE),\n            q95_year_of_birth = quantile(year_of_birth, 0.95, na.rm=TRUE),\n            max_year_of_birth = max(year_of_birth, na.rm=TRUE)) |&gt;  \n  glimpse()\n\nRows: ??\nColumns: 6\nDatabase: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\Rtmp2JzmkJ\\file7744d34138b.duckdb]\n$ min_year_of_birth    &lt;int&gt; 1923\n$ q05_year_of_birth    &lt;dbl&gt; 1927\n$ mean_year_of_birth   &lt;dbl&gt; 1971\n$ median_year_of_birth &lt;dbl&gt; 1970\n$ q95_year_of_birth    &lt;dbl&gt; 2018\n$ max_year_of_birth    &lt;int&gt; 2023\n\n\nAs we’ve seen before, we can also quickly get results for various groupings or restrictions\n\ngrouped_summary &lt;- cdm$person |&gt; \n   group_by(gender_concept_id) |&gt; \n   summarise(min_year_of_birth = min(year_of_birth, na.rm=TRUE),\n            q25_year_of_birth = quantile(year_of_birth, 0.25, na.rm=TRUE),\n            median_year_of_birth = median(year_of_birth, na.rm=TRUE),\n            q75_year_of_birth = quantile(year_of_birth, 0.75, na.rm=TRUE),\n            max_year_of_birth = max(year_of_birth, na.rm=TRUE)) |&gt; \n  left_join(cdm$concept, \n            by=c(\"gender_concept_id\" = \"concept_id\")) |&gt; \n   collect() \n\ngrouped_summary |&gt; \n  ggplot(aes(x = concept_name, group = concept_name,\n             fill = concept_name)) +\n  geom_boxplot(aes(\n    lower = q25_year_of_birth, \n    upper = q75_year_of_birth, \n    middle = median_year_of_birth, \n    ymin = min_year_of_birth, \n    ymax = max_year_of_birth),\n    stat = \"identity\", width = 0.5) + \n  theme_bw()+ \n  theme(legend.position = \"none\") +\n  xlab(\"\")",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Exploring the OMOP CDM</span>"
    ]
  },
  {
    "objectID": "creating_cohorts.html",
    "href": "creating_cohorts.html",
    "title": "7  Adding cohorts to the CDM",
    "section": "",
    "text": "7.1 What is a cohort?\nWhen performing research with the OMOP common data model we often want to identify groups of individuals who share some set of characteristics. The criteria for including individuals can range from the seemingly simple (e.g. people diagnosed with asthma) to the much more complicated (e.g. adults diagnosed with asthma who had a year of prior observation time in the database prior to their diagnosis, had no prior history of chronic obstructive pulmonary disease, and no history of use of short-acting beta-antagonists).\nThe set of people we identify are cohorts, and the OMOP CDM has a specific structure by which they can be represented, with a cohort table having four required fields: 1) cohort definition id (a unique identifier for each cohort), 2) subject id (a foreign key to the subject in the cohort - typically referring to records in the person table), 3) cohort start date, and 4) cohort end date. Individuals can enter a cohort multiple times, but the time periods in which they are in the cohort cannot overlap. Individuals will only be considered in a cohort when they have have an ongoing observation period.\nIt is beyond the scope of this book to describe all the different ways cohorts could be created, however in this chapter we provide a summary of some of the key building blocks for cohort creation. Cohort-building pipelines can be created following these principles to create a wide range of study cohorts.",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Adding cohorts to the CDM</span>"
    ]
  },
  {
    "objectID": "creating_cohorts.html#set-up",
    "href": "creating_cohorts.html#set-up",
    "title": "7  Adding cohorts to the CDM",
    "section": "7.2 Set up",
    "text": "7.2 Set up\nWe’ll use our synthetic dataset for demonstrating how cohorts can be constructed.\n\nlibrary(CDMConnector)\nlibrary(CodelistGenerator)\nlibrary(CohortConstructor)\nlibrary(CohortCharacteristics)\nlibrary(dplyr)\n        \ndb &lt;- DBI::dbConnect(duckdb::duckdb(),\n              dbdir = eunomiaDir(datasetName = \"synthea-covid19-10k\"))\ncdm &lt;- cdmFromCon(db, cdmSchema = \"main\", writeSchema = \"main\")",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Adding cohorts to the CDM</span>"
    ]
  },
  {
    "objectID": "creating_cohorts.html#general-concept-based-cohort",
    "href": "creating_cohorts.html#general-concept-based-cohort",
    "title": "7  Adding cohorts to the CDM",
    "section": "7.3 General concept based cohort",
    "text": "7.3 General concept based cohort\nOften study cohorts will be based around a specific clinical event identified by some set of clinical codes. Here, for example, we use the CohortConstructor package to create a cohort of people with Covid-19. For this we are identifying any clinical records with the code 37311061.\n\ncdm$covid &lt;- conceptCohort(cdm = cdm, \n                     conceptSet = list(\"covid\" = 37311061), \n                     name = \"covid\")\ncdm$covid\n\n# Source:   table&lt;main.covid&gt; [?? x 4]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpMXitf9\\file15fc7dbf594d.duckdb]\n   cohort_definition_id subject_id cohort_start_date cohort_end_date\n                  &lt;int&gt;      &lt;int&gt; &lt;date&gt;            &lt;date&gt;         \n 1                    1       7557 2021-01-18        2021-02-18     \n 2                    1       5682 2021-01-02        2021-01-11     \n 3                    1       5730 2020-08-02        2020-08-24     \n 4                    1       4528 2020-12-16        2021-01-10     \n 5                    1       8317 2020-12-12        2020-12-28     \n 6                    1       8543 2021-01-24        2021-02-16     \n 7                    1       7944 2020-04-04        2020-04-18     \n 8                    1       8236 2020-12-10        2021-01-14     \n 9                    1       7616 2020-07-30        2020-08-14     \n10                    1       2246 2020-10-16        2020-11-18     \n# ℹ more rows\n\n\n\n\n\n\n\n\nFinding appropriate codes\n\n\n\n\n\nIn the defining the cohorts above we have needed to provide concept IDs to define our cohort. But, where do these come from?\nWe can search for codes of interest using the CodelistGenerator package. This can be done using a text search with the function CodelistGenerator::getCandidateCodes(). For example, we can have found the code we used above (and many others) like so:\n\ngetCandidateCodes(cdm = cdm, \n                  keywords = c(\"coronavirus\",\"covid\"),\n                  domains = \"condition\",\n                  includeDescendants = TRUE)\n\nLimiting to domains of interest\nGetting concepts to include\nAdding descendants\nSearch completed. Finishing up.\n✔ 37 candidate concepts identified\n\nTime taken: 0 minutes and 1 seconds\n\n\n# A tibble: 37 × 6\n   concept_id found_from   concept_name domain_id vocabulary_id standard_concept\n        &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;     &lt;chr&gt;         &lt;chr&gt;           \n 1    3661631 From initia… Lymphocytop… Condition SNOMED        S               \n 2    3661632 From initia… Thrombocyto… Condition SNOMED        S               \n 3    3655976 From initia… Acute hypox… Condition SNOMED        S               \n 4    3661406 From initia… Acute respi… Condition SNOMED        S               \n 5     703447 From initia… High risk c… Condition SNOMED        S               \n 6    3661748 From initia… Acute kidne… Condition SNOMED        S               \n 7   37310287 From initia… Myocarditis… Condition SNOMED        S               \n 8   37310286 From initia… Infection o… Condition SNOMED        S               \n 9     705076 From initia… Post-acute … Condition OMOP Extensi… S               \n10    3655973 From initia… At increase… Condition SNOMED        S               \n# ℹ 27 more rows\n\n\nWe can also do automated searches that make use of the hierarchies in the vocabularies. Here, for example, we find the code for the drug ingredient Acetaminophen and all of it’s descendants.\n\nCodelistGenerator::getDrugIngredientCodes(cdm = cdm, \n                                          name = \"acetaminophen\")\n\n\n\n\n── 1 codelist ──────────────────────────────────────────────────────────────────\n\n\n\n- 161_acetaminophen (25747 codes)\n\n\nNote that in practice clinical expertise is vital in the identification of appropriate codes so as to decide which the codes are in line with the clinical idea at hand.\n\n\n\nWe can see that as well as having the cohort entries above, our cohort table is associated with several attributes.\nFirst, we can see the settings associated with cohort.\n\nsettings(cdm$covid) |&gt; \n  glimpse()\n\nRows: 1\nColumns: 4\n$ cohort_definition_id &lt;int&gt; 1\n$ cohort_name          &lt;chr&gt; \"covid\"\n$ cdm_version          &lt;chr&gt; \"5.3\"\n$ vocabulary_version   &lt;chr&gt; \"v5.0 22-JUN-22\"\n\n\nSecond, we can get counts of the cohort.\n\ncohortCount(cdm$covid) |&gt; \n  glimpse()\n\nRows: 1\nColumns: 3\n$ cohort_definition_id &lt;int&gt; 1\n$ number_records       &lt;int&gt; 964\n$ number_subjects      &lt;int&gt; 964\n\n\nAnd last we can see attrition related to the cohort.\n\nattrition(cdm$covid) |&gt; \n  glimpse()\n\nRows: 4\nColumns: 7\n$ cohort_definition_id &lt;int&gt; 1, 1, 1, 1\n$ number_records       &lt;int&gt; 964, 964, 964, 964\n$ number_subjects      &lt;int&gt; 964, 964, 964, 964\n$ reason_id            &lt;int&gt; 1, 2, 3, 4\n$ reason               &lt;chr&gt; \"Initial qualifying events\", \"Record start &lt;= rec…\n$ excluded_records     &lt;int&gt; 0, 0, 0, 0\n$ excluded_subjects    &lt;int&gt; 0, 0, 0, 0\n\n\nAs we will see below these attributes of the cohorts become particularly useful as we apply further restrictions on our cohort.",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Adding cohorts to the CDM</span>"
    ]
  },
  {
    "objectID": "creating_cohorts.html#applying-inclusion-criteria",
    "href": "creating_cohorts.html#applying-inclusion-criteria",
    "title": "7  Adding cohorts to the CDM",
    "section": "7.4 Applying inclusion criteria",
    "text": "7.4 Applying inclusion criteria\n\n7.4.1 Only include first cohort entry per person\nLet’s say we first want to restrict to first entry.\n\ncdm$covid &lt;- cdm$covid |&gt; \n     requireIsFirstEntry() \n\n\n\n7.4.2 Restrict to study period\n\ncdm$covid &lt;- cdm$covid |&gt;\n   requireInDateRange(dateRange = c(as.Date(\"2020-09-01\"), NA))\n\n\n\n7.4.3 Applying demographic inclusion criteria\nSay for our study we want to include people with a GI bleed who were aged 40 or over at the time. We can use the add variables with these characteristics as seen in chapter 4 and then filter accordingly. The function CDMConnector::record_cohort_attrition() will then update our cohort attributes as we can see below.\n\ncdm$covid &lt;- cdm$covid |&gt;\n   requireDemographics(ageRange = c(18, 64), sex = \"Male\")\n\n\n\n7.4.4 Applying cohort-based inclusion criteria\nAs well as requirements about specific demographics, we may also want to use another cohort for inclusion criteria. Let’s say we want to exclude anyone with a history of cardiac conditions before their Covid-19 cohort entry.\nWe can first generate this new cohort table with records of cardiac conditions.\n\ncdm$cardiac &lt;- conceptCohort(\n  cdm = cdm,\n  list(\"myocaridal_infarction\" = c(\n    317576, 313217, 321042, 4329847\n  )), \nname = \"cardiac\"\n)\ncdm$cardiac\n\n# Source:   table&lt;main.cardiac&gt; [?? x 4]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpMXitf9\\file15fc7dbf594d.duckdb]\n   cohort_definition_id subject_id cohort_start_date cohort_end_date\n                  &lt;int&gt;      &lt;int&gt; &lt;date&gt;            &lt;date&gt;         \n 1                    1        311 2002-02-10        2002-02-10     \n 2                    1       3833 2020-12-24        2020-12-24     \n 3                    1       8808 1983-06-28        1983-06-28     \n 4                    1       2087 2018-08-24        2018-08-24     \n 5                    1       8683 2013-10-06        2013-10-06     \n 6                    1      10449 1994-05-10        1994-05-10     \n 7                    1        695 1999-02-25        1999-02-25     \n 8                    1       3292 2003-02-27        2003-02-27     \n 9                    1       7094 1981-08-29        1981-08-29     \n10                    1       7145 2016-11-21        2016-11-21     \n# ℹ more rows\n\n\nAnd now we can apply the inclusion criteria that individuals have zero intersections with the table in the time prior to their Covid-19 cohort entry.\n\ncdm$covid &lt;- cdm$covid |&gt; \n  requireCohortIntersect(targetCohortTable = \"cardiac\", \n                         indexDate = \"cohort_start_date\", \n                         window = c(-Inf, -1), \n                         intersections = 0) \n\nNote if we had wanted to have required that individuals did have a history of a cardiac condition we would instead have set intersections = c(1, Inf) above.",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Adding cohorts to the CDM</span>"
    ]
  },
  {
    "objectID": "creating_cohorts.html#cohort-attributes",
    "href": "creating_cohorts.html#cohort-attributes",
    "title": "7  Adding cohorts to the CDM",
    "section": "7.5 Cohort attributes",
    "text": "7.5 Cohort attributes\nWe can see that the attributes of the cohort were updated as we applied the inclusion criteria.\n\nsettings(cdm$covid) |&gt; \n  glimpse()\n\nRows: 1\nColumns: 8\n$ cohort_definition_id   &lt;int&gt; 1\n$ cohort_name            &lt;chr&gt; \"covid\"\n$ age_range              &lt;chr&gt; \"18_64\"\n$ sex                    &lt;chr&gt; \"Male\"\n$ min_prior_observation  &lt;dbl&gt; 0\n$ min_future_observation &lt;dbl&gt; 0\n$ cdm_version            &lt;chr&gt; \"5.3\"\n$ vocabulary_version     &lt;chr&gt; \"v5.0 22-JUN-22\"\n\n\n\ncohortCount(cdm$covid) |&gt; \n  glimpse()\n\nRows: 1\nColumns: 3\n$ cohort_definition_id &lt;int&gt; 1\n$ number_records       &lt;int&gt; 158\n$ number_subjects      &lt;int&gt; 158\n\n\n\nattrition(cdm$covid) |&gt; \n  glimpse()\n\nRows: 11\nColumns: 7\n$ cohort_definition_id &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n$ number_records       &lt;int&gt; 964, 964, 964, 964, 964, 793, 363, 171, 171, 171,…\n$ number_subjects      &lt;int&gt; 964, 964, 964, 964, 964, 793, 363, 171, 171, 171,…\n$ reason_id            &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11\n$ reason               &lt;chr&gt; \"Initial qualifying events\", \"Record start &lt;= rec…\n$ excluded_records     &lt;int&gt; 0, 0, 0, 0, 0, 171, 430, 192, 0, 0, 13\n$ excluded_subjects    &lt;int&gt; 0, 0, 0, 0, 0, 171, 430, 192, 0, 0, 13\n\n\nFor attrition, we can use CohortConstructor::summariseCohortAttrition() and then CohortConstructor::tableCohortAttrition() to better view the impact of applying the additional inclusion criteria.\n\nattrition_summary &lt;- summariseCohortAttrition(cdm$covid)\nplotCohortAttrition(attrition_summary)",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Adding cohorts to the CDM</span>"
    ]
  },
  {
    "objectID": "adding_features.html",
    "href": "adding_features.html",
    "title": "8  Identifying patient characteristics",
    "section": "",
    "text": "8.1 Adding specific demographics\nFor this chapter, we’ll again use our example COVID-19 dataset.\nAs part of an analysis we almost always have a need to identify certain characteristics related to the individuals in our data. These characteristics might be time-invariant (ie a characteristic that does not change as time passes and a person ages) or time-varying.1\nThe PatientProfiles package makes it easy for us to add demographic information to tables in the OMOP CDM. Like the CDMConnector package we’ve seen previously, the fact that the structure of the OMOP CDM is known allows the PatientProfiles package to abstract away some common data manipulations required to do research with patient-level data.2\nLet’s say we are interested in individuals’ age and sex at time of diagnosis with COVID-19. We can add these variables to the table like so (noting that because age is time-varying, we have to specify the variable with the date for which we want to calculate age relative to).\ncdm$condition_occurrence &lt;- cdm$condition_occurrence |&gt; \n  addSex() |&gt; \n  addAge(indexDate = \"condition_start_date\")\n\ncdm$condition_occurrence |&gt; \n  glimpse()\n\nRows: ??\nColumns: 18\nDatabase: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpAZLd3s\\file59e02feb5ed8.duckdb]\n$ condition_occurrence_id       &lt;int&gt; 1, 3, 8, 9, 12, 18, 19, 20, 21, 23, 24, …\n$ person_id                     &lt;int&gt; 2, 7, 16, 16, 25, 42, 42, 42, 44, 47, 47…\n$ condition_concept_id          &lt;int&gt; 381316, 381316, 381316, 313217, 381316, …\n$ condition_start_date          &lt;date&gt; 1986-09-08, 2021-04-07, 2020-02-11, 202…\n$ condition_start_datetime      &lt;dttm&gt; 1986-09-08, 2021-04-07, 2020-02-11, 202…\n$ condition_end_date            &lt;date&gt; 1986-09-08, 2021-04-07, 2020-02-11, 202…\n$ condition_end_datetime        &lt;dttm&gt; 1986-09-08, 2021-04-07, 2020-02-11, 202…\n$ condition_type_concept_id     &lt;int&gt; 38000175, 38000175, 38000175, 38000175, …\n$ condition_status_concept_id   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ stop_reason                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ provider_id                   &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ visit_occurrence_id           &lt;int&gt; 19, 67, 168, 171, 257, 439, 437, 435, 45…\n$ visit_detail_id               &lt;int&gt; 1000019, 1000067, 1000168, 1000171, 1000…\n$ condition_source_value        &lt;chr&gt; \"230690007\", \"230690007\", \"230690007\", \"…\n$ condition_source_concept_id   &lt;int&gt; 381316, 381316, 381316, 313217, 381316, …\n$ condition_status_source_value &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sex                           &lt;chr&gt; \"Female\", \"Male\", \"Female\", \"Female\", \"M…\n$ age                           &lt;int&gt; 57, 97, 75, 77, 55, 52, 5, 48, 35, 29, 2…\ncdm$condition_occurrence |&gt; \n  addSexQuery() |&gt; \n  dplyr::show_query()\n\nWarning: ! The following columns will be overwritten: sex\n\n\n&lt;SQL&gt;\nSELECT\n  condition_occurrence_id,\n  og_002_1735312355.person_id AS person_id,\n  condition_concept_id,\n  condition_start_date,\n  condition_start_datetime,\n  condition_end_date,\n  condition_end_datetime,\n  condition_type_concept_id,\n  condition_status_concept_id,\n  stop_reason,\n  provider_id,\n  visit_occurrence_id,\n  visit_detail_id,\n  condition_source_value,\n  condition_source_concept_id,\n  condition_status_source_value,\n  age,\n  RHS.sex AS sex\nFROM og_002_1735312355\nLEFT JOIN (\n  SELECT\n    person_id,\n    CASE\nWHEN (gender_concept_id = 8507.0) THEN 'Male'\nWHEN (gender_concept_id = 8532.0) THEN 'Female'\nELSE 'None'\nEND AS sex\n  FROM (\n    SELECT\n      LHS.person_id AS person_id,\n      gender_concept_id,\n      year_of_birth,\n      month_of_birth,\n      day_of_birth\n    FROM (\n      SELECT DISTINCT person_id\n      FROM og_002_1735312355\n    ) LHS\n    INNER JOIN main.person\n      ON (LHS.person_id = person.person_id)\n  ) q01\n) RHS\n  ON (og_002_1735312355.person_id = RHS.person_id)\nWe now have two variables added containing values for age and sex.\ncdm$condition_occurrence |&gt; \n  glimpse()\n\nRows: ??\nColumns: 18\nDatabase: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpAZLd3s\\file59e02feb5ed8.duckdb]\n$ condition_occurrence_id       &lt;int&gt; 1, 3, 8, 9, 12, 18, 19, 20, 21, 23, 24, …\n$ person_id                     &lt;int&gt; 2, 7, 16, 16, 25, 42, 42, 42, 44, 47, 47…\n$ condition_concept_id          &lt;int&gt; 381316, 381316, 381316, 313217, 381316, …\n$ condition_start_date          &lt;date&gt; 1986-09-08, 2021-04-07, 2020-02-11, 202…\n$ condition_start_datetime      &lt;dttm&gt; 1986-09-08, 2021-04-07, 2020-02-11, 202…\n$ condition_end_date            &lt;date&gt; 1986-09-08, 2021-04-07, 2020-02-11, 202…\n$ condition_end_datetime        &lt;dttm&gt; 1986-09-08, 2021-04-07, 2020-02-11, 202…\n$ condition_type_concept_id     &lt;int&gt; 38000175, 38000175, 38000175, 38000175, …\n$ condition_status_concept_id   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ stop_reason                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ provider_id                   &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ visit_occurrence_id           &lt;int&gt; 19, 67, 168, 171, 257, 439, 437, 435, 45…\n$ visit_detail_id               &lt;int&gt; 1000019, 1000067, 1000168, 1000171, 1000…\n$ condition_source_value        &lt;chr&gt; \"230690007\", \"230690007\", \"230690007\", \"…\n$ condition_source_concept_id   &lt;int&gt; 381316, 381316, 381316, 313217, 381316, …\n$ condition_status_source_value &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sex                           &lt;chr&gt; \"Female\", \"Male\", \"Female\", \"Female\", \"M…\n$ age                           &lt;int&gt; 57, 97, 75, 77, 55, 52, 5, 48, 35, 29, 2…\nAnd with these now added it is straightforward to calculate mean age at condition start date by sex or even plot the distribution of age at diagnosis by sex.\ncdm$condition_occurrence |&gt;\n  summarise(mean_age = mean(age, na.rm=TRUE), .by = \"sex\") |&gt; \n  collect()\n\n# A tibble: 2 × 2\n  sex    mean_age\n  &lt;chr&gt;     &lt;dbl&gt;\n1 Female     50.8\n2 Male       56.5\ncdm$condition_occurrence |&gt;\n  select(\"person_id\", \"age\", \"sex\") |&gt; \n  collect()  |&gt;\n  ggplot(aes(fill = sex)) +\n  facet_grid(sex ~ .) +\n  geom_histogram(aes(age), colour = \"black\", binwidth = 5) +\n  theme_bw() +\n  theme(legend.position = \"none\")",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Identifying patient characteristics</span>"
    ]
  },
  {
    "objectID": "adding_features.html#adding-multiple-demographics-simultaneously",
    "href": "adding_features.html#adding-multiple-demographics-simultaneously",
    "title": "8  Identifying patient characteristics",
    "section": "8.2 Adding multiple demographics simultaneously",
    "text": "8.2 Adding multiple demographics simultaneously\nWe’ve now seen individual functions from PatientProfiles to add age and sex, and the package has others to add other characteristics like days of prior observation in the database (rather unimaginatively named PatientProfiles::addPriorObservation()). In additional to these individuals functions, the package also provides a more general function to get all of these characteristics at the same time.3\n\ncdm$drug_exposure &lt;- cdm$drug_exposure |&gt; \n  addDemographics(indexDate = \"drug_exposure_start_date\")\n\ncdm$drug_exposure |&gt; \n  glimpse()\n\nRows: ??\nColumns: 27\nDatabase: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpAZLd3s\\file59e02feb5ed8.duckdb]\n$ drug_exposure_id             &lt;int&gt; 245761, 245762, 245763, 245765, 245766, 2…\n$ person_id                    &lt;int&gt; 7764, 7764, 7764, 7764, 7764, 7764, 7764,…\n$ drug_concept_id              &lt;int&gt; 40213227, 40213201, 40213198, 40213154, 4…\n$ drug_exposure_start_date     &lt;date&gt; 2015-02-08, 2010-01-10, 2010-01-10, 2016…\n$ drug_exposure_start_datetime &lt;dttm&gt; 2015-02-08 22:40:04, 2010-01-10 22:40:04…\n$ drug_exposure_end_date       &lt;date&gt; 2015-02-08, 2010-01-10, 2010-01-10, 2016…\n$ drug_exposure_end_datetime   &lt;dttm&gt; 2015-02-08 22:40:04, 2010-01-10 22:40:04…\n$ verbatim_end_date            &lt;date&gt; 2015-02-08, 2010-01-10, 2010-01-10, 2016…\n$ drug_type_concept_id         &lt;int&gt; 32869, 32869, 32869, 32869, 32869, 32869,…\n$ stop_reason                  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ refills                      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ quantity                     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ days_supply                  &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ sig                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ route_concept_id             &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ lot_number                   &lt;chr&gt; \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"…\n$ provider_id                  &lt;int&gt; 14656, 14656, 14656, 14656, 14656, 14656,…\n$ visit_occurrence_id          &lt;int&gt; 80896, 80891, 80891, 80895, 80896, 80894,…\n$ visit_detail_id              &lt;int&gt; 1080896, 1080891, 1080891, 1080895, 10808…\n$ drug_source_value            &lt;chr&gt; \"113\", \"33\", \"133\", \"140\", \"140\", \"140\", …\n$ drug_source_concept_id       &lt;int&gt; 40213227, 40213201, 40213198, 40213154, 4…\n$ route_source_value           &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ dose_unit_source_value       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ age                          &lt;int&gt; 71, 66, 66, 72, 71, 69, 67, 70, 64, 68, 6…\n$ sex                          &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"…\n$ prior_observation            &lt;int&gt; 2597, 742, 742, 2968, 2597, 1855, 1113, 2…\n$ future_observation           &lt;int&gt; 896, 2751, 2751, 525, 896, 1638, 2380, 12…\n\n\nWith these characteristics now all added, we can now calculate mean age, prior observation (how many days have passed since the individual’s most recent observation start date), and future observation (how many days until the individual’s nearest observation end date) at drug exposure start date by sex.\n\ncdm$drug_exposure |&gt;\n  summarise(mean_age = mean(age, na.rm=TRUE),\n            mean_prior_observation = mean(prior_observation, na.rm=TRUE),\n            mean_future_observation = mean(future_observation, na.rm=TRUE),\n            .by = \"sex\") |&gt; \n  collect()\n\n# A tibble: 2 × 4\n  sex    mean_age mean_prior_observation mean_future_observation\n  &lt;chr&gt;     &lt;dbl&gt;                  &lt;dbl&gt;                   &lt;dbl&gt;\n1 Male       43.0                  2455.                   1768.\n2 Female     39.4                  2096.                   1661.\n\n\n\n\n\n\n\n\nReturning a query from PatientProfiles rather than the result\n\n\n\n\n\nIn the above examples the functions from PatientProfiles will execute queries with the results written to a table in the database (either temporary if no name is provided or a permanent table if one is given). We might though instead want to to instead just get the underlying query back so that we have more control over how and when the query will be executed.\n\ncdm$visit_occurrence |&gt; \n  addSex() |&gt; \n  filter(sex == \"Male\") |&gt; \n  dplyr::show_query()\n\n&lt;SQL&gt;\nSELECT og_004_1735312358.*\nFROM og_004_1735312358\nWHERE (sex = 'Male')\n\n\n\ncdm$visit_occurrence |&gt; \n  addSex(name = \"my_new_table\") |&gt; \n  filter(sex == \"Male\") |&gt; \n  dplyr::show_query()\n\n&lt;SQL&gt;\nSELECT my_new_table.*\nFROM main.my_new_table\nWHERE (sex = 'Male')\n\n\n\ncdm$visit_occurrence |&gt; \n  addSexQuery() |&gt; \n  filter(sex == \"Male\") |&gt; \n  dplyr::show_query()\n\n&lt;SQL&gt;\nSELECT q01.*\nFROM (\n  SELECT visit_occurrence.*, sex\n  FROM main.visit_occurrence\n  LEFT JOIN (\n    SELECT\n      person_id,\n      CASE\nWHEN (gender_concept_id = 8507.0) THEN 'Male'\nWHEN (gender_concept_id = 8532.0) THEN 'Female'\nELSE 'None'\nEND AS sex\n    FROM (\n      SELECT\n        LHS.person_id AS person_id,\n        gender_concept_id,\n        year_of_birth,\n        month_of_birth,\n        day_of_birth\n      FROM (\n        SELECT DISTINCT person_id\n        FROM main.visit_occurrence\n      ) LHS\n      INNER JOIN main.person\n        ON (LHS.person_id = person.person_id)\n    ) q01\n  ) RHS\n    ON (visit_occurrence.person_id = RHS.person_id)\n) q01\nWHERE (sex = 'Male')",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Identifying patient characteristics</span>"
    ]
  },
  {
    "objectID": "adding_features.html#creating-categories",
    "href": "adding_features.html#creating-categories",
    "title": "8  Identifying patient characteristics",
    "section": "8.3 Creating categories",
    "text": "8.3 Creating categories\nWhen we add age, either via addAge or addDemographics, we can also add another variable containing age groups. These age groups are specified in a list of vectors, each of which contain the lower and upper bounds.\n\ncdm$visit_occurrence &lt;- cdm$visit_occurrence |&gt;\n  addAge(indexDate = \"visit_start_date\",\n    ageGroup = list(c(0,17), c(18, 64),\n                    c(65, Inf)))\n\ncdm$visit_occurrence |&gt; \n  # data quality issues with our synthetic data means we have \n  # some negative ages so will drop these\n  filter(age &gt;= 0) |&gt; \n  group_by(age_group) |&gt; \n  tally() |&gt; \n  collect() |&gt; \n  ggplot() + \n  geom_col(aes(x = age_group, y = n)) + \n  theme_bw()\n\n\n\n\n\n\n\n\nPatientProfiles also provides a more general function for adding categories. Can you guess it’s name? That’s right, we have PatientProfiles::addCategories() for this.\n\ncdm$condition_occurrence |&gt;\n  addPriorObservation(indexDate = \"condition_start_date\") |&gt;\n  addCategories(\n    variable = \"prior_observation\",\n    categories = list(\"prior_observation_group\" = list(\n      c(0, 364), c(365, Inf)  \n    ))\n  ) |&gt; \n  glimpse()\n\nRows: ??\nColumns: 20\nDatabase: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpAZLd3s\\file59e02feb5ed8.duckdb]\n$ condition_occurrence_id       &lt;int&gt; 1, 3, 8, 9, 12, 18, 19, 20, 21, 23, 24, …\n$ person_id                     &lt;int&gt; 2, 7, 16, 16, 25, 42, 42, 42, 44, 47, 47…\n$ condition_concept_id          &lt;int&gt; 381316, 381316, 381316, 313217, 381316, …\n$ condition_start_date          &lt;date&gt; 1986-09-08, 2021-04-07, 2020-02-11, 202…\n$ condition_start_datetime      &lt;dttm&gt; 1986-09-08, 2021-04-07, 2020-02-11, 202…\n$ condition_end_date            &lt;date&gt; 1986-09-08, 2021-04-07, 2020-02-11, 202…\n$ condition_end_datetime        &lt;dttm&gt; 1986-09-08, 2021-04-07, 2020-02-11, 202…\n$ condition_type_concept_id     &lt;int&gt; 38000175, 38000175, 38000175, 38000175, …\n$ condition_status_concept_id   &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ stop_reason                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ provider_id                   &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ visit_occurrence_id           &lt;int&gt; 19, 67, 168, 171, 257, 439, 437, 435, 45…\n$ visit_detail_id               &lt;int&gt; 1000019, 1000067, 1000168, 1000171, 1000…\n$ condition_source_value        &lt;chr&gt; \"230690007\", \"230690007\", \"230690007\", \"…\n$ condition_source_concept_id   &lt;int&gt; 381316, 381316, 381316, 313217, 381316, …\n$ condition_status_source_value &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sex                           &lt;chr&gt; \"Female\", \"Male\", \"Female\", \"Female\", \"M…\n$ age                           &lt;int&gt; 57, 97, 75, 77, 55, 52, 5, 48, 35, 29, 2…\n$ prior_observation             &lt;int&gt; 3437, 2842, 2366, 2968, 1904, 17003, 0, …\n$ prior_observation_group       &lt;chr&gt; \"365 or above\", \"365 or above\", \"365 or …",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Identifying patient characteristics</span>"
    ]
  },
  {
    "objectID": "adding_features.html#adding-custom-variables",
    "href": "adding_features.html#adding-custom-variables",
    "title": "8  Identifying patient characteristics",
    "section": "8.4 Adding custom variables",
    "text": "8.4 Adding custom variables\nWhile PatientProfiles provides a range of functions that can help add characteristics of interest, you may also want to add other features . Obviously we can’t cover here all possible custom characteristics you may wish to add. However, two common groups of custom features are those that are derived from other variables in the same table and others that are taken from other tables and joined to our particular table of interest.\nIn the first case where we want to add a new variable derived from other variables in our table we’ll typically be using dplyr::mutate(). For example, perhaps we just want to add a new variable to our observation period table containing the year of individuals’ observation period start date. This is rather straightforward.\n\ncdm$observation_period &lt;- cdm$observation_period |&gt; \n  mutate(observation_period_start_year = get_year(observation_period_start_date))\n\ncdm$observation_period |&gt; \n  glimpse()\n\nRows: ??\nColumns: 6\nDatabase: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpAZLd3s\\file59e02feb5ed8.duckdb]\n$ observation_period_id         &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…\n$ person_id                     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1…\n$ observation_period_start_date &lt;date&gt; 2014-05-09, 1977-04-11, 2014-04-19, 201…\n$ observation_period_end_date   &lt;date&gt; 2023-05-12, 1986-09-15, 2023-04-22, 202…\n$ period_type_concept_id        &lt;int&gt; 44814724, 44814724, 44814724, 44814724, …\n$ observation_period_start_year &lt;dbl&gt; 2014, 1977, 2014, 2014, 2013, 2013, 2013…\n\n\nThe second case is normally a more complex task where adding a new variable involves joining to some other table. This table may well have been created by some intermediate query that we wrote to derive the variable of interest. For example, lets say we want to add each number of condition occurrence records for each individual to the person table (remember that we saw how to calculate this in the previous chapter). For this we will need to do a join between the person and condition occurrence tables (as some people might not have any records in the condition occurrence table). Here we’ll save the create a table containing just the information we’re interested in and compute to a temporary table.\n\ncondition_summary &lt;- cdm$person |&gt; \n  select(\"person_id\") |&gt; \n  left_join(cdm$condition_occurrence |&gt; \n  group_by(person_id) |&gt; \n  count(name = \"condition_occurrence_records\"),\n  by=\"person_id\") |&gt; \n  select(\"person_id\", \"condition_occurrence_records\") |&gt; \n  mutate(condition_occurrence_records = if_else(\n    is.na(condition_occurrence_records), \n    0, condition_occurrence_records)) |&gt; \n  compute()\n\ncondition_summary |&gt; \n  glimpse()\n\nRows: ??\nColumns: 2\nDatabase: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpAZLd3s\\file59e02feb5ed8.duckdb]\n$ person_id                    &lt;int&gt; 2, 7, 16, 18, 25, 36, 42, 44, 47, 51, 52,…\n$ condition_occurrence_records &lt;dbl&gt; 1, 1, 2, 2, 1, 4, 3, 2, 5, 1, 3, 2, 1, 4,…\n\n\nWe can see what goes on behind the scenes by viewing the associated SQL.\n\ncdm$person |&gt; \n  select(\"person_id\") |&gt; \n  left_join(cdm$condition_occurrence |&gt; \n  group_by(person_id) |&gt; \n  count(name = \"condition_occurrence_records\"),\n  by=\"person_id\") |&gt; \n  select(\"person_id\", \"condition_occurrence_records\") |&gt; \n  mutate(condition_occurrence_records = if_else(\n    is.na(condition_occurrence_records), \n    0, condition_occurrence_records)) |&gt; \n  show_query()\n\n&lt;SQL&gt;\nSELECT\n  person_id,\n  CASE WHEN ((condition_occurrence_records IS NULL)) THEN 0.0 WHEN NOT ((condition_occurrence_records IS NULL)) THEN condition_occurrence_records END AS condition_occurrence_records\nFROM (\n  SELECT person.person_id AS person_id, condition_occurrence_records\n  FROM main.person\n  LEFT JOIN (\n    SELECT person_id, COUNT(*) AS condition_occurrence_records\n    FROM og_002_1735312355\n    GROUP BY person_id\n  ) RHS\n    ON (person.person_id = RHS.person_id)\n) q01\n\n\n\n\n\n\n\n\nTaking care with joins\n\n\n\n\n\nWhen adding variables through joins we need to pay particular attention to the dimensions of the resulting table. While sometimes we may want to have additional rows added as well as new columns, this is often not desired. If we, for example, have a table with one row per person then a left join to a table with multiple rows per person can then result in a table with multiple rows per person.\nExamples where to be careful include when joining to the observation period table, as individuals can have multiple observation periods, and when working with cohorts (which are the focus of the next chapter) as individuals can also enter the same study cohort multiple times.\nJust to underline how problematic joins can become if we don’t take care, here we join the condition occurrence table and the drug exposure table both of which have multiple records per person. Remember this is just with our small synthetic data, so when working with real patient data which is oftentimes much, much larger this would be extremely problematic (and would unlikely be needed to answer any research question). In other words, don’t try this at home!\n\ncdm$condition_occurrence |&gt; \n  tally()\n\n# Source:   SQL [?? x 1]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpAZLd3s\\file59e02feb5ed8.duckdb]\n      n\n  &lt;dbl&gt;\n1  9967\n\ncdm$drug_exposure |&gt; \n  tally()\n\n# Source:   SQL [?? x 1]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpAZLd3s\\file59e02feb5ed8.duckdb]\n       n\n   &lt;dbl&gt;\n1 337509\n\ncdm$condition_occurrence |&gt; \n  select(person_id, condition_start_date) |&gt; \n  left_join(cdm$drug_exposure |&gt; \n  select(person_id, drug_exposure_start_date), \n  by = \"person_id\") |&gt; \n  tally()\n\n# Source:   SQL [?? x 1]\n# Database: DuckDB v1.1.3 [eburn@Windows 10 x64:R 4.4.0/C:\\Users\\eburn\\AppData\\Local\\Temp\\RtmpAZLd3s\\file59e02feb5ed8.duckdb]\n       n\n   &lt;dbl&gt;\n1 410683",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Identifying patient characteristics</span>"
    ]
  },
  {
    "objectID": "adding_features.html#footnotes",
    "href": "adding_features.html#footnotes",
    "title": "8  Identifying patient characteristics",
    "section": "",
    "text": "In some datasets characteristics that could conceptually be considered as time-varying are encoded as time-invariant. One example for the latter is that in some cases an individual may be associated with a particular socioeconomic status or nationality that for the purposes of the data is treated as time-invariant.↩︎\nAlthough these manipulations can on the face of it seem quite simple, their implementation across different database platforms with different data granularity (for example whether day of birth has been filled in for all patients or not) presents challenges that the PatientProfiles package solves for us.↩︎\nThis function also provides a more time efficient method that getting the characteristics one by one. This is because these characteristics are all derived from the OMOP CDM person and observation period tables and so can be identified simultaneously.↩︎",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Identifying patient characteristics</span>"
    ]
  },
  {
    "objectID": "working_with_cohorts.html",
    "href": "working_with_cohorts.html",
    "title": "9  Working with cohorts",
    "section": "",
    "text": "9.1 Cohort intersections\nPatientProfiles::addCohortIntersect()",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Working with cohorts</span>"
    ]
  },
  {
    "objectID": "working_with_cohorts.html#intersection-between-two-cohorts",
    "href": "working_with_cohorts.html#intersection-between-two-cohorts",
    "title": "9  Working with cohorts",
    "section": "9.2 Intersection between two cohorts",
    "text": "9.2 Intersection between two cohorts",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Working with cohorts</span>"
    ]
  },
  {
    "objectID": "working_with_cohorts.html#set-up",
    "href": "working_with_cohorts.html#set-up",
    "title": "9  Working with cohorts",
    "section": "9.3 Set up",
    "text": "9.3 Set up\n\nlibrary(CDMConnector)\nlibrary(dplyr)\nlibrary(PatientProfiles)\n\n# For this example we will use GiBleed data set\nCDMConnector::downloadEunomiaData(datasetName = \"GiBleed\")        \ndb &lt;- DBI::dbConnect(duckdb::duckdb(), eunomia_dir())\n\ncdm &lt;- cdmFromCon(db, cdmSchema = \"main\", writeSchema = \"main\")\n\ncdm &lt;- cdm |&gt; \n  generate_concept_cohort_set(concept_set = list(\"gi_bleed\" = 192671), \n                            limit = \"all\", \n                            end = 30,\n                            name = \"gi_bleed\",\n                            overwrite = TRUE) |&gt; \n  generate_concept_cohort_set(concept_set = list(\"acetaminophen\" = c(1125315,\n                                                              1127078,\n                                                              1127433,\n                                                              40229134,\n                                                              40231925,\n                                                              40162522,\n                                                              19133768)), \n                              limit = \"all\", \n                            # end = \"event_end_date\",\n                            name = \"acetaminophen\",\n                            overwrite = TRUE)\n\n\n9.3.1 Flag\n\ncdm$gi_bleed &lt;- cdm$gi_bleed |&gt; \n  addCohortIntersectFlag(targetCohortTable = \"acetaminophen\",\n                         window = list(c(-Inf, -1), c(0,0), c(1, Inf)))\n\ncdm$gi_bleed |&gt; \n  summarise(acetaminophen_prior = sum(acetaminophen_minf_to_m1), \n            acetaminophen_index = sum(acetaminophen_0_to_0),\n            acetaminophen_post = sum(acetaminophen_1_to_inf)) |&gt; \n  collect()\n\n# A tibble: 1 × 3\n  acetaminophen_prior acetaminophen_index acetaminophen_post\n                &lt;dbl&gt;               &lt;dbl&gt;              &lt;dbl&gt;\n1                 467                 467                476\n\n\n\n\n9.3.2 Count\n\n\n9.3.3 Date and times",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Working with cohorts</span>"
    ]
  },
  {
    "objectID": "working_with_cohorts.html#intersection-between-a-cohort-and-tables-with-patient-data",
    "href": "working_with_cohorts.html#intersection-between-a-cohort-and-tables-with-patient-data",
    "title": "9  Working with cohorts",
    "section": "9.4 Intersection between a cohort and tables with patient data",
    "text": "9.4 Intersection between a cohort and tables with patient data",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Working with cohorts</span>"
    ]
  },
  {
    "objectID": "summarising_cohorts.html",
    "href": "summarising_cohorts.html",
    "title": "10  Summarising cohorts",
    "section": "",
    "text": "10.1 Summarising patient demographics\nPatientProfiles::summariseCharacteristics …..",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Summarising cohorts</span>"
    ]
  },
  {
    "objectID": "summarising_cohorts.html#large-scale-characterisation",
    "href": "summarising_cohorts.html#large-scale-characterisation",
    "title": "10  Summarising cohorts",
    "section": "10.2 Large scale characterisation",
    "text": "10.2 Large scale characterisation\nPatientProfiles::summariseLargeScaleCharacteristics …..\nTO ADD",
    "crumbs": [
      "Data analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Summarising cohorts</span>"
    ]
  }
]